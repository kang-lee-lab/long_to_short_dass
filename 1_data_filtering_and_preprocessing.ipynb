{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc08e79-101d-4c4f-8204-60ea018d1dee",
   "metadata": {},
   "source": [
    "# Data Filtering and Preprocessing\n",
    "\n",
    "This file takes the raw data for DASS and adds 5 new columns categorizing the data. Then, the data is filtered by certain conditions, and certain regions and unnecessary columns are dropped. \n",
    "\n",
    "# 1. Data Filtering\n",
    "\n",
    "Import the necessary libraries and define helper functions to categorize country, age, and DASS-42 anxiety score into either string or numeric values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c4c5e73-98c9-4615-ab68-feaa5b74f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pycountry_convert as pc\n",
    "\n",
    "data_folder = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b56af8-b099-4554-8d9f-7e3753ceb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_country(row):\n",
    "    # Encode country into three major regions (east, west, other)\n",
    "    country_code = row[\"country\"]\n",
    "    try:\n",
    "        if country_code and country_code != \"NONE\":\n",
    "            continent_name = pc.country_alpha2_to_continent_code(country_code)\n",
    "            if continent_name == \"AS\":\n",
    "                region_name = \"east\"\n",
    "            elif continent_name in [\"NA\", \"EU\", \"OC\"]:\n",
    "                region_name = \"west\"\n",
    "            else:\n",
    "                region_name = \"other\"\n",
    "        else:\n",
    "            region_name = \"\"\n",
    "    except:\n",
    "        region_name = \"\"\n",
    "    return region_name\n",
    "\n",
    "\n",
    "def encode_continent(row):\n",
    "    # Encode country into three major regions (east, west, other)\n",
    "    country_code = row[\"country\"]\n",
    "    try:\n",
    "        if country_code and country_code != \"NONE\":\n",
    "            continent_name = pc.country_alpha2_to_continent_code(country_code)\n",
    "        else:\n",
    "            continent_name = \"\"\n",
    "    except:\n",
    "        continent_name = \"\"\n",
    "    return continent_name\n",
    "\n",
    "\n",
    "def encode_age(row):\n",
    "    # Encode age into groups\n",
    "    age = int(row[\"age\"])\n",
    "    if age < 18:\n",
    "        agegroup = 0\n",
    "    elif age < 28:\n",
    "        agegroup = 1\n",
    "    elif age < 38:\n",
    "        agegroup = 2\n",
    "    elif age < 48:\n",
    "        agegroup = 3\n",
    "    elif age < 58:\n",
    "        agegroup = 4\n",
    "    elif age < 68:\n",
    "        agegroup = 5\n",
    "    else:\n",
    "        agegroup = 6\n",
    "    return agegroup\n",
    "\n",
    "\n",
    "def calc_anx(row):\n",
    "    # Calculate DASS-42 anxiety score\n",
    "    with open(os.path.join(data_folder, \"dass42_qcategories.json\"), \"r\") as f:\n",
    "        categories = json.load(f)\n",
    "    anxiety_questions = [key for key in categories if categories[key] == \"anxiety\"]\n",
    "\n",
    "    score = 0\n",
    "    for qnum in anxiety_questions:\n",
    "        score += int(row[\"Q{}A\".format(qnum)])\n",
    "    return score - len(anxiety_questions)\n",
    "\n",
    "\n",
    "def categorize(row):\n",
    "    # Classify as positive or negative (high or low) status based on threshold\n",
    "    with open(os.path.join(data_folder, \"dass42_scoring.json\"), \"r\") as f:\n",
    "        scoring = json.load(f)\n",
    "    threshold = scoring[\"anxiety_score\"][\"severe\"][\"min\"]  # moderate\n",
    "    return (1 if row[\"anxiety_score\"] >= threshold else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551efdbd-7660-44b3-bd9e-84b38edbddd1",
   "metadata": {},
   "source": [
    "Load the data and the helper functions will be called on the data to categorise the data into new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f5558-0ef1-4c4e-9d0f-2f18ae6d0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/data.csv\", sep='\\t')\n",
    "dataset[\"agegroup\"] = dataset.apply(lambda row: encode_age(row), axis=1)\n",
    "dataset[\"continent\"] = dataset.apply(lambda row: encode_continent(row), axis=1)\n",
    "dataset[\"region\"] = dataset.apply(lambda row: encode_country(row), axis=1)\n",
    "dataset[\"anxiety_score\"] = dataset.apply(lambda row: calc_anx(row), axis=1)\n",
    "dataset[\"anxiety_status\"] = dataset.apply(lambda row: categorize(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bbc0ad-5d1e-4887-b4e5-636035ad427a",
   "metadata": {},
   "source": [
    "Run the cells below to see an overview of the data before filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f68ba55-2371-4830-948b-dbe026986abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before filtering:\")\n",
    "print(dataset['gender'].value_counts())\n",
    "print(dataset['age'].value_counts())\n",
    "print(dataset['age'].mean(), dataset['age'].std())\n",
    "print(dataset['continent'].value_counts())\n",
    "print(dataset['region'].value_counts())\n",
    "print(dataset['agegroup'].value_counts())\n",
    "print(dataset['anxiety_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e97c8b-07f8-447c-a97e-08ae425b335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBreakdown by continent:\")\n",
    "df1 = dataset[dataset['continent'] == 'AS']\n",
    "print(df1['age'].mean(), df1['age'].std())\n",
    "print(df1['gender'].value_counts())\n",
    "print(df1['anxiety_status'].value_counts())\n",
    "\n",
    "df2 = dataset[dataset['continent'] == 'NA']\n",
    "print(df2['age'].mean(), df2['age'].std())\n",
    "print(df2['gender'].value_counts())\n",
    "print(df2['anxiety_status'].value_counts())\n",
    "\n",
    "df3 = dataset[dataset['continent'] == 'EU']\n",
    "print(df3['age'].mean(), df3['age'].std())\n",
    "print(df3['gender'].value_counts())\n",
    "print(df3['anxiety_status'].value_counts())\n",
    "\n",
    "df4 = dataset[dataset['continent'] == 'SA']\n",
    "print(df4['age'].mean(), df4['age'].std())\n",
    "print(df4['gender'].value_counts())\n",
    "print(df4['anxiety_status'].value_counts())\n",
    "\n",
    "df5 = dataset[dataset['continent'] == 'AF']\n",
    "print(df5['age'].mean(), df5['age'].std())\n",
    "print(df5['gender'].value_counts())\n",
    "print(df5['anxiety_status'].value_counts())\n",
    "\n",
    "df6 = dataset[dataset['continent'] == 'OC']\n",
    "print(df6['age'].mean(), df6['age'].std())\n",
    "print(df6['gender'].value_counts())\n",
    "print(df6['anxiety_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9d4e1-41de-4b4e-ad4c-60b9becdbbf6",
   "metadata": {},
   "source": [
    "Filter the data to keep data that contains: Males and Females, over 18, have a region.\n",
    "\n",
    "Then, remove data with countries that have strict data privacy laws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a876b9-0847-46ee-92d7-14a00a9e1ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data\n",
    "dataset = dataset.drop(dataset[(dataset['gender'] == 0) | (dataset['gender'] == 3)].index)  # Male and females only\n",
    "dataset = dataset[dataset['age'] >= 18]  # Adults only\n",
    "dataset = dataset[dataset['region'] != \"\"]  # Must have region\n",
    "\n",
    "# Remove data with countries that have strict data privacy laws (for public use only)\n",
    "dataset = dataset[dataset['continent'] != \"EU\"]\n",
    "dataset = dataset[dataset['country'] != \"CH\"]\n",
    "dataset = dataset[dataset['country'] != \"IN\"]\n",
    "dataset = dataset[dataset['country'] != \"JA\"]\n",
    "dataset = dataset[dataset['country'] != \"AU\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ff253-b483-430f-93e3-57fa429a2dc1",
   "metadata": {},
   "source": [
    "Run the cells below to see an overview of the data after filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd3b2b-fe0b-4bdb-883a-3d5c934c7363",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAfter filtering:\")\n",
    "print(dataset['gender'].value_counts())\n",
    "print(dataset['agegroup'].value_counts())\n",
    "print(dataset['age'].mean(), dataset['age'].std())\n",
    "print(dataset['continent'].value_counts())\n",
    "print(dataset['region'].value_counts())\n",
    "print(dataset['anxiety_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d4db98-ab3d-4f3b-b450-4b5596310607",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBreakdown by continent:\")\n",
    "df1 = dataset[dataset['continent'] == 'AS']\n",
    "print(df1['age'].mean(), df1['age'].std())\n",
    "print(df1['gender'].value_counts())\n",
    "print(df1['anxiety_status'].value_counts())\n",
    "\n",
    "df2 = dataset[dataset['continent'] == 'NA']\n",
    "print(df2['age'].mean(), df2['age'].std())\n",
    "print(df2['gender'].value_counts())\n",
    "print(df2['anxiety_status'].value_counts())\n",
    "\n",
    "df3 = dataset[dataset['continent'] == 'EU']\n",
    "print(df3['age'].mean(), df3['age'].std())\n",
    "print(df3['gender'].value_counts())\n",
    "print(df3['anxiety_status'].value_counts())\n",
    "\n",
    "df4 = dataset[dataset['continent'] == 'SA']\n",
    "print(df4['age'].mean(), df4['age'].std())\n",
    "print(df4['gender'].value_counts())\n",
    "print(df4['anxiety_status'].value_counts())\n",
    "\n",
    "df5 = dataset[dataset['continent'] == 'AF']\n",
    "print(df5['age'].mean(), df5['age'].std())\n",
    "print(df5['gender'].value_counts())\n",
    "print(df5['anxiety_status'].value_counts())\n",
    "\n",
    "df6 = dataset[dataset['continent'] == 'OC']\n",
    "print(df6['age'].mean(), df6['age'].std())\n",
    "print(df6['gender'].value_counts())\n",
    "print(df6['anxiety_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb2357-f4ff-4d70-b606-693dc62891f8",
   "metadata": {},
   "source": [
    "Keep the columns that are necessary for DASS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efcf92b-29c9-4b1f-8e0c-5ba653f9e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "to_drop = [\"source\", \"screensize\", \"uniquenetworklocation\", \n",
    "            \"education\", \"urban\", \"engnat\", \"hand\", \"religion\", \n",
    "            \"orientation\", \"race\", \"voted\", \"married\", \"major\",\n",
    "            \"introelapse\", \"testelapse\", \"surveyelapse\", \"familysize\"]\n",
    "dataset = dataset.drop(to_drop, axis=1)\n",
    "\n",
    "for col in dataset.columns:\n",
    "    if \"TIPI\" in col or \"VCL\" in col:\n",
    "        dataset = dataset.drop([col], axis=1)\n",
    "    elif col[0] == \"Q\" and (col[-1] == \"E\" or col[-1] == \"I\"):\n",
    "        dataset = dataset.drop([col], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44982ba-e961-416b-9c0e-3d22a1b70839",
   "metadata": {},
   "source": [
    "Save the filtered dataset under data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e65923-a2e1-4edb-ae83-7a0c25e2462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved filtered dataset\n",
    "dataset.to_csv(os.path.join(data_folder, \"data_filtered.csv\"), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be1989d-2abf-44d2-aba4-5e3aedcd7359",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing\n",
    "\n",
    "Import the necessary libraries and define constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e1ac44-c6df-48df-9fa2-73db54f25449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "data_folder = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b290ab-5cf5-4a13-9a1f-bb13b8cac632",
   "metadata": {},
   "source": [
    "Define the preprocess function which will rebalance the minority class, one-hot encoding categorical variables, and z-score normalizing the numerical features.\n",
    "\n",
    "Then, define the train_val_test_split function which will split and label the data into training, validation, and test datasets, which would be used for training the model, tuning model parameters, and evaluating the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14213448-dab6-4661-9e13-57880abff89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_df):\n",
    "    \"\"\"\n",
    "    Pre-processing: rebalance, one-hot encode, normalize\n",
    "    \"\"\"\n",
    "    # Separate majority and minority classes\n",
    "    df_majority = data_df[data_df[\"anxiety_status\"] == 1]\n",
    "    df_minority = data_df[data_df[\"anxiety_status\"] == 0]\n",
    "    \n",
    "    # Upsample minority class\n",
    "    data_minority = resample(df_minority, \n",
    "                            replace=True,                       # sample with replacement\n",
    "                            n_samples=len(df_majority.index),   # to match majority class\n",
    "                            random_state=123)                   # reproducible results\n",
    "\n",
    "    data_df = pd.concat([df_majority, data_minority])\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "\n",
    "    # Extract the label columns; separate features and labels\n",
    "    labels_df = data_df[[\"anxiety_status\"]].copy()\n",
    "    feats_df = data_df.drop([\"anxiety_score\", \"anxiety_status\"], axis=1)\n",
    "\n",
    "    # z-score normalization\n",
    "    def z_score_norm(row, col, mean, stdev):\n",
    "        z_score = (float(row[col]) - mean) / stdev\n",
    "        return float(z_score)\n",
    "\n",
    "    # One-hot encode gender and region\n",
    "    label_encoder = LabelEncoder()\n",
    "    oneh_encoder = OneHotEncoder()\n",
    "\n",
    "    # Gender\n",
    "    gender = label_encoder.fit_transform(feats_df[\"gender\"])\n",
    "    gender = pd.DataFrame(gender)\n",
    "    gender = pd.DataFrame(oneh_encoder.fit_transform(gender).toarray())\n",
    "    gender.columns = [\"gender_m\", \"gender_f\"]\n",
    "\n",
    "    # Region\n",
    "    region = label_encoder.fit_transform(feats_df[\"region\"])\n",
    "    region = pd.DataFrame(region)\n",
    "    region = pd.DataFrame(oneh_encoder.fit_transform(region).toarray())\n",
    "    region.columns = [\"region_other\", \"region_east\", \"region_west\"]\n",
    "\n",
    "    # Combine and remove original columns\n",
    "    feats_df = feats_df.drop([\"gender\", \"country\", \"region\", \"agegroup\", \"continent\"], axis=1)\n",
    "    feats_df = pd.concat([feats_df, gender, region], axis=1)\n",
    "\n",
    "    # One-hot encode question answers\n",
    "    for col in feats_df.columns:\n",
    "        if col[0] == \"Q\" and col[-1] == \"A\":\n",
    "            temp = label_encoder.fit_transform(feats_df[col])\n",
    "            temp = pd.DataFrame(temp)\n",
    "            temp = pd.DataFrame(oneh_encoder.fit_transform(temp).toarray())\n",
    "\n",
    "            col_names = []\n",
    "            for c in temp.columns:\n",
    "                col_names.append(\"{0}_{1}\".format(col, c))\n",
    "            temp.columns = col_names\n",
    "\n",
    "            feats_df = feats_df.drop([col], axis=1)\n",
    "            feats_df = pd.concat([feats_df, temp], axis=1)\n",
    "\n",
    "    # Normalize numerical columns (Use z-score)\n",
    "    mean = feats_df[\"age\"].mean()\n",
    "    stdev = feats_df[\"age\"].std()\n",
    "    feats_df[\"age_norm\"] = feats_df.apply(\n",
    "                    lambda row: z_score_norm(row, \"age\", mean, stdev), axis=1)\n",
    "    feats_df = feats_df.drop([\"age\"], axis=1)\n",
    "\n",
    "    return feats_df, labels_df\n",
    "\n",
    "\n",
    "def train_val_test_split(feats_df, labels_df, rand=0, save=False):\n",
    "    \"\"\"\n",
    "    Train / validation / test (holdout) dataset split\n",
    "    \"\"\"\n",
    "    feats_arr = np.array(feats_df)\n",
    "    labels_arr = np.array(labels_df)\n",
    "    traintest_feats, valid_feats, traintest_labels, valid_labels = \\\n",
    "        train_test_split(feats_arr, labels_arr, test_size=0.10, random_state=seed)\n",
    "    train_feats, holdout_feats, train_labels, holdout_labels = \\\n",
    "        train_test_split(traintest_feats, traintest_labels, test_size=0.1111, random_state=rand)\n",
    "\n",
    "    train_feats = train_feats.astype(float)\n",
    "    train_labels = train_labels.astype(float)\n",
    "    valid_feats = valid_feats.astype(float)\n",
    "    valid_labels = valid_labels.astype(float)\n",
    "    holdout_feats = holdout_feats.astype(float)\n",
    "    holdout_labels = holdout_labels.astype(float)\n",
    "\n",
    "    if save:\n",
    "        train_feats.to_csv(os.path.join(data_folder, \"train_feats.csv\"), index=None)\n",
    "        train_labels.to_csv(os.path.join(data_folder, \"train_labels.csv\"), index=None)\n",
    "        valid_feats.to_csv(os.path.join(data_folder, \"valid_feats.csv\"), index=None)\n",
    "        valid_labels.to_csv(os.path.join(data_folder, \"valid_labels.csv\"), index=None)\n",
    "        holdout_feats.to_csv(os.path.join(data_folder, \"holdout_feats.csv\"), index=None)\n",
    "        holdout_labels.to_csv(os.path.join(data_folder, \"holdout_labels.csv\"), index=None)\n",
    "\n",
    "    return train_feats, train_labels, valid_feats, valid_labels, holdout_feats, holdout_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e75254-73d1-449e-ad65-1857fafb283c",
   "metadata": {},
   "source": [
    "Preprocess the filtered data by calling the preprocess function, and save the preprocessed data in the data_folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93447e26-0463-405d-9eaf-cc2e64a0d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(data_folder, \"data_filtered_1000.csv\")) # Using the sample dataset. Change the file name accordingly if using another dataset. \n",
    "feats_df, labels_df = preprocess(data)\n",
    "\n",
    "feats_df.to_csv(os.path.join(data_folder, \"features.csv\"), index=None)\n",
    "labels_df.to_csv(os.path.join(data_folder, \"labels.csv\"), index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
