{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc08e79-101d-4c4f-8204-60ea018d1dee",
   "metadata": {},
   "source": [
    "# Data Filtering and Preprocessing\n",
    "\n",
    "This file takes the raw data for DASS and adds 5 new columns categorizing the data. Then, the data is filtered by certain conditions, and certain regions and unnecessary columns are dropped. \n",
    "\n",
    "# 1. Data Filtering\n",
    "\n",
    "Import the necessary libraries and define helper functions to categorize country, age, and DASS-42 anxiety score into either string or numeric values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c4c5e73-98c9-4615-ab68-feaa5b74f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pycountry_convert as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c84adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data folder\n",
    "data_folder = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11b56af8-b099-4554-8d9f-7e3753ceb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_country(row):\n",
    "    # Encode country into three major regions (east, west, other)\n",
    "    country_code = row[\"country\"]\n",
    "    try:\n",
    "        if country_code and country_code != \"NONE\":\n",
    "            continent_name = pc.country_alpha2_to_continent_code(country_code)\n",
    "            if continent_name == \"AS\":\n",
    "                region_name = \"east\"\n",
    "            elif continent_name in [\"NA\", \"EU\", \"OC\"]:\n",
    "                region_name = \"west\"\n",
    "            else:\n",
    "                region_name = \"other\"\n",
    "        else:\n",
    "            region_name = \"\"\n",
    "    except:\n",
    "        region_name = \"\"\n",
    "    return region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7aaf3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_continent(row):\n",
    "    # Encode country into three major regions (east, west, other)\n",
    "    country_code = row[\"country\"]\n",
    "    try:\n",
    "        if country_code and country_code != \"NONE\":\n",
    "            continent_name = pc.country_alpha2_to_continent_code(country_code)\n",
    "        else:\n",
    "            continent_name = \"\"\n",
    "    except:\n",
    "        continent_name = \"\"\n",
    "    return continent_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8aef2dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_age(row):\n",
    "    # Encode age into groups\n",
    "    age = int(row['age'])\n",
    "    if age < 18:\n",
    "        agegroup = 0\n",
    "    elif age < 28:\n",
    "        agegroup = 1\n",
    "    elif age < 38:\n",
    "        agegroup = 2\n",
    "    elif age < 48:\n",
    "        agegroup = 3\n",
    "    elif age < 58:\n",
    "        agegroup = 4\n",
    "    elif age < 68:\n",
    "        agegroup = 5\n",
    "    else:\n",
    "        agegroup = 6\n",
    "    return agegroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfc5ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_anx(row):\n",
    "    # Calculate DASS-42 anxiety score\n",
    "    with open(os.path.join(data_folder, \"dass42_qcategories.json\"), \"r\") as f:\n",
    "        categories = json.load(f)\n",
    "    anxiety_questions = [key for key in categories if categories[key] == \"anxiety\"]\n",
    "\n",
    "    score = 0\n",
    "    for qnum in anxiety_questions:\n",
    "        score += int(row[\"Q{}A\".format(qnum)])\n",
    "    return score - len(anxiety_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2fe9ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(row):\n",
    "    # Classify as positive or negative (high or low) status based on threshold\n",
    "    with open(os.path.join(data_folder, \"dass42_scoring.json\"), \"r\") as f:\n",
    "        scoring = json.load(f)\n",
    "    threshold = scoring[\"anxiety_score\"][\"severe\"][\"min\"]  # moderate\n",
    "    return (1 if row[\"anxiety_score\"] >= threshold else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551efdbd-7660-44b3-bd9e-84b38edbddd1",
   "metadata": {},
   "source": [
    "Load the data and the helper functions will be called on the data to categorise the data into new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a22f5558-0ef1-4c4e-9d0f-2f18ae6d0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataset = pd.read_csv(\"./DASS_data/data.csv\", delimiter='\\t', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6d4833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "dataset[\"agegroup\"] = dataset.apply(lambda row: encode_age(row), axis=1)\n",
    "dataset[\"continent\"] = dataset.apply(lambda row: encode_continent(row), axis=1)\n",
    "dataset[\"region\"] = dataset.apply(lambda row: encode_country(row), axis=1)\n",
    "dataset[\"anxiety_score\"] = dataset.apply(lambda row: calc_anx(row), axis=1)\n",
    "dataset[\"anxiety_status\"] = dataset.apply(lambda row: categorize(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bbc0ad-5d1e-4887-b4e5-636035ad427a",
   "metadata": {},
   "source": [
    "Run the cells below to see an overview of the data before filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f68ba55-2371-4830-948b-dbe026986abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering:\n",
      "gender\n",
      "2    30367\n",
      "1     8789\n",
      "3      552\n",
      "0       67\n",
      "Name: count, dtype: int64\n",
      "age\n",
      "20      3789\n",
      "21      3535\n",
      "19      3510\n",
      "18      3046\n",
      "22      3009\n",
      "        ... \n",
      "89         1\n",
      "1996       1\n",
      "223        1\n",
      "78         1\n",
      "99         1\n",
      "Name: count, Length: 79, dtype: int64\n",
      "23.612168447517284 21.581722299859113\n",
      "continent\n",
      "AS    24878\n",
      "NA     9472\n",
      "EU     3464\n",
      "OC      828\n",
      "        541\n",
      "SA      351\n",
      "AF      241\n",
      "Name: count, dtype: int64\n",
      "region\n",
      "east     24878\n",
      "west     13764\n",
      "other      592\n",
      "           541\n",
      "Name: count, dtype: int64\n",
      "agegroup\n",
      "1    25285\n",
      "0     7269\n",
      "2     4421\n",
      "3     1537\n",
      "4      869\n",
      "5      304\n",
      "6       90\n",
      "Name: count, dtype: int64\n",
      "anxiety_status\n",
      "1    20235\n",
      "0    19540\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data summary (before filtering)\n",
    "print(\"Before filtering:\")\n",
    "print(dataset['gender'].value_counts())\n",
    "print(dataset['age'].value_counts())\n",
    "print(dataset['age'].mean(), dataset['age'].std())\n",
    "print(dataset['continent'].value_counts())\n",
    "print(dataset['region'].value_counts())\n",
    "print(dataset['agegroup'].value_counts())\n",
    "print(dataset['anxiety_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3e97c8b-07f8-447c-a97e-08ae425b335b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Breakdown by continent:\n",
      "\n",
      "Continent: Asia\n",
      "22.80794276067208 25.62313281199424\n",
      "gender\n",
      "2    20624\n",
      "1     4170\n",
      "3       49\n",
      "0       35\n",
      "Name: count, dtype: int64\n",
      "anxiety_status\n",
      "1    13057\n",
      "0    11821\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Continent: North America\n",
      "24.8246410472973 12.45164961612597\n",
      "gender\n",
      "2    6267\n",
      "1    2814\n",
      "3     372\n",
      "0      19\n",
      "Name: count, dtype: int64\n",
      "anxiety_status\n",
      "0    4817\n",
      "1    4655\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Continent: Europe\n",
      "25.09959584295612 11.212522384606052\n",
      "gender\n",
      "2    2137\n",
      "1    1221\n",
      "3     101\n",
      "0       5\n",
      "Name: count, dtype: int64\n",
      "anxiety_status\n",
      "0    1852\n",
      "1    1612\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Continent: South America\n",
      "21.945868945868945 8.680679945384714\n",
      "gender\n",
      "2    185\n",
      "1    156\n",
      "3      9\n",
      "0      1\n",
      "Name: count, dtype: int64\n",
      "anxiety_status\n",
      "1    176\n",
      "0    175\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Continent: Africa\n",
      "25.42738589211618 10.057538477246814\n",
      "gender\n",
      "2    181\n",
      "1     55\n",
      "3      3\n",
      "0      2\n",
      "Name: count, dtype: int64\n",
      "anxiety_status\n",
      "1    124\n",
      "0    117\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Continent: Oceania\n",
      "27.568840579710145 13.146972933873796\n",
      "gender\n",
      "2    583\n",
      "1    229\n",
      "3     14\n",
      "0      2\n",
      "Name: count, dtype: int64\n",
      "anxiety_status\n",
      "0    484\n",
      "1    344\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data summary by continent (before filtering)\n",
    "print(\"\\nBreakdown by continent:\")\n",
    "\n",
    "print(\"\\nContinent: Asia\")\n",
    "df1 = dataset[dataset['continent'] == 'AS']\n",
    "print(df1['age'].mean(), df1['age'].std())\n",
    "print(df1['gender'].value_counts())\n",
    "print(df1['anxiety_status'].value_counts())\n",
    "\n",
    "print(\"\\nContinent: North America\")\n",
    "df2 = dataset[dataset['continent'] == 'NA']\n",
    "print(df2['age'].mean(), df2['age'].std())\n",
    "print(df2['gender'].value_counts())\n",
    "print(df2['anxiety_status'].value_counts())\n",
    "\n",
    "print(\"\\nContinent: Europe\")\n",
    "df3 = dataset[dataset['continent'] == 'EU']\n",
    "print(df3['age'].mean(), df3['age'].std())\n",
    "print(df3['gender'].value_counts())\n",
    "print(df3['anxiety_status'].value_counts())\n",
    "\n",
    "print(\"\\nContinent: South America\")\n",
    "df4 = dataset[dataset['continent'] == 'SA']\n",
    "print(df4['age'].mean(), df4['age'].std())\n",
    "print(df4['gender'].value_counts())\n",
    "print(df4['anxiety_status'].value_counts())\n",
    "\n",
    "print(\"\\nContinent: Africa\")\n",
    "df5 = dataset[dataset['continent'] == 'AF']\n",
    "print(df5['age'].mean(), df5['age'].std())\n",
    "print(df5['gender'].value_counts())\n",
    "print(df5['anxiety_status'].value_counts())\n",
    "\n",
    "print(\"\\nContinent: Oceania\")\n",
    "df6 = dataset[dataset['continent'] == 'OC']\n",
    "print(df6['age'].mean(), df6['age'].std())\n",
    "print(df6['gender'].value_counts())\n",
    "print(df6['anxiety_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0fdd0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 39775\n"
     ]
    }
   ],
   "source": [
    "num_samples = dataset.shape[0]\n",
    "print(\"Number of samples:\", num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9d4e1-41de-4b4e-ad4c-60b9becdbbf6",
   "metadata": {},
   "source": [
    "Filter the data to keep data that contains: Males and Females, over 18, have a region.\n",
    "\n",
    "Then, remove data with countries that have strict data privacy laws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26a876b9-0847-46ee-92d7-14a00a9e1ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data\n",
    "dataset = dataset.drop(dataset[(dataset['gender'] == 0) | (dataset['gender'] == 3)].index)  # Male and females only\n",
    "dataset = dataset[dataset['age'] >= 18]  # Adults only\n",
    "dataset = dataset[dataset['region'] != \"\"]  # Must have region\n",
    "\n",
    "# Remove data with countries that have strict data privacy laws (for public use only)\n",
    "dataset = dataset[dataset['continent'] != \"EU\"]\n",
    "dataset = dataset[dataset['country'] != \"CH\"]\n",
    "dataset = dataset[dataset['country'] != \"IN\"]\n",
    "dataset = dataset[dataset['country'] != \"JA\"]\n",
    "dataset = dataset[dataset['country'] != \"AU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8cbd3043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 28364\n"
     ]
    }
   ],
   "source": [
    "num_samples = dataset.shape[0]\n",
    "print(\"Number of samples:\", num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ff253-b483-430f-93e3-57fa429a2dc1",
   "metadata": {},
   "source": [
    "Run the cells below to see an overview of the data after filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62dd3b2b-fe0b-4bdb-883a-3d5c934c7363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering:\n",
      "gender\n",
      "2    22417\n",
      "1     5947\n",
      "Name: count, dtype: int64\n",
      "agegroup\n",
      "1    22615\n",
      "2     3704\n",
      "3     1131\n",
      "4      619\n",
      "5      229\n",
      "6       66\n",
      "Name: count, dtype: int64\n",
      "24.983077140036666 24.768503249097243\n",
      "continent\n",
      "AS    21748\n",
      "NA     6006\n",
      "SA      245\n",
      "AF      201\n",
      "OC      164\n",
      "Name: count, dtype: int64\n",
      "region\n",
      "east     21748\n",
      "west      6170\n",
      "other      446\n",
      "Name: count, dtype: int64\n",
      "anxiety_status\n",
      "0    14657\n",
      "1    13707\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data summary (after filtering)\n",
    "print(\"\\nAfter filtering:\")\n",
    "print(dataset['gender'].value_counts())\n",
    "print(dataset['agegroup'].value_counts())\n",
    "print(dataset['age'].mean(), dataset['age'].std())\n",
    "print(dataset['continent'].value_counts())\n",
    "print(dataset['region'].value_counts())\n",
    "print(dataset['anxiety_status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74d4db98-ab3d-4f3b-b450-4b5596310607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Breakdown by continent:\n",
      "\n",
      "Continent: Asia\n",
      "23.287206266318538 5.7345204677729775\n",
      "2    641\n",
      "1    125\n",
      "Name: gender, dtype: int64\n",
      "1    384\n",
      "0    382\n",
      "Name: anxiety_status, dtype: int64\n",
      "\n",
      "Continent: North America\n",
      "30.643192488262912 13.338284137107273\n",
      "2    134\n",
      "1     79\n",
      "Name: gender, dtype: int64\n",
      "0    144\n",
      "1     69\n",
      "Name: anxiety_status, dtype: int64\n",
      "\n",
      "Continent: Europe\n",
      "nan nan\n",
      "Series([], Name: gender, dtype: int64)\n",
      "Series([], Name: anxiety_status, dtype: int64)\n",
      "\n",
      "Continent: South America\n",
      "21.1875 3.331040878364199\n",
      "2    8\n",
      "1    8\n",
      "Name: gender, dtype: int64\n",
      "0    9\n",
      "1    7\n",
      "Name: anxiety_status, dtype: int64\n",
      "\n",
      "Continent: Africa\n",
      "33.0 nan\n",
      "2    1\n",
      "Name: gender, dtype: int64\n",
      "0    1\n",
      "Name: anxiety_status, dtype: int64\n",
      "\n",
      "Continent: Oceania\n",
      "40.0 15.033296378372908\n",
      "2    3\n",
      "1    1\n",
      "Name: gender, dtype: int64\n",
      "0    4\n",
      "Name: anxiety_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data summary by continent (after filtering)\n",
    "print(\"\\nBreakdown by continent:\")\n",
    "\n",
    "print(\"\\nContinent: Asia\")\n",
    "df1 = dataset[dataset['continent'] == 'AS']\n",
    "print(df1['age'].mean(), df1['age'].std())\n",
    "print(df1['gender'].value_counts())\n",
    "print(df1['anxiety_status'].value_counts())\n",
    "\n",
    "print(\"\\nContinent: North America\")\n",
    "df2 = dataset[dataset['continent'] == 'NA']\n",
    "print(df2['age'].mean(), df2['age'].std())\n",
    "print(df2['gender'].value_counts())\n",
    "print(df2['anxiety_status'].value_counts())\n",
    "\n",
    "print(\"\\nContinent: Europe\")\n",
    "df3 = dataset[dataset['continent'] == 'EU']\n",
    "print(df3['age'].mean(), df3['age'].std())\n",
    "print(df3['gender'].value_counts())\n",
    "print(df3['anxiety_status'].value_counts())\n",
    "\n",
    "print(\"\\nContinent: South America\")\n",
    "df4 = dataset[dataset['continent'] == 'SA']\n",
    "print(df4['age'].mean(), df4['age'].std())\n",
    "print(df4['gender'].value_counts())\n",
    "print(df4['anxiety_status'].value_counts())\n",
    "\n",
    "print(\"\\nContinent: Africa\")\n",
    "df5 = dataset[dataset['continent'] == 'AF']\n",
    "print(df5['age'].mean(), df5['age'].std())\n",
    "print(df5['gender'].value_counts())\n",
    "print(df5['anxiety_status'].value_counts())\n",
    "\n",
    "print(\"\\nContinent: Oceania\")\n",
    "df6 = dataset[dataset['continent'] == 'OC']\n",
    "print(df6['age'].mean(), df6['age'].std())\n",
    "print(df6['gender'].value_counts())\n",
    "print(df6['anxiety_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb2357-f4ff-4d70-b606-693dc62891f8",
   "metadata": {},
   "source": [
    "Keep the columns that are necessary for DASS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2efcf92b-29c9-4b1f-8e0c-5ba653f9e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "# to_drop = [\"source\", \"screensize\", \"uniquenetworklocation\", \n",
    "#             \"education\", \"urban\", \"engnat\", \"hand\", \"religion\", \n",
    "#             \"orientation\", \"race\", \"voted\", \"married\", \"major\",\n",
    "#             \"introelapse\", \"testelapse\", \"surveyelapse\", \"familysize\"]\n",
    "# dataset = dataset.drop(to_drop, axis=1)\n",
    "\n",
    "for col in dataset.columns:\n",
    "    if \"TIPI\" in col or \"VCL\" in col:\n",
    "        dataset = dataset.drop([col], axis=1)\n",
    "    elif col[0] == \"Q\" and (col[-1] == \"E\" or col[-1] == \"I\"):\n",
    "        dataset = dataset.drop([col], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44982ba-e961-416b-9c0e-3d22a1b70839",
   "metadata": {},
   "source": [
    "Save the filtered dataset under data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85e65923-a2e1-4edb-ae83-7a0c25e2462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved filtered dataset\n",
    "dataset.to_csv(os.path.join(data_folder, \"data_filtered.csv\"), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be1989d-2abf-44d2-aba4-5e3aedcd7359",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing\n",
    "\n",
    "Import the necessary libraries and define constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10e1ac44-c6df-48df-9fa2-73db54f25449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cef3893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data folder\n",
    "seed = 42\n",
    "data_folder = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b290ab-5cf5-4a13-9a1f-bb13b8cac632",
   "metadata": {},
   "source": [
    "Define the preprocess function which will rebalance the minority class, one-hot encoding categorical variables, and z-score normalizing the numerical features.\n",
    "\n",
    "Then, define the train_val_test_split function which will split and label the data into training, validation, and test datasets, which would be used for training the model, tuning model parameters, and evaluating the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14213448-dab6-4661-9e13-57880abff89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_df):\n",
    "    \"\"\"\n",
    "    Pre-processing: rebalance, one-hot encode, normalize\n",
    "    \"\"\"\n",
    "    # Separate majority and minority classes\n",
    "    df_majority = data_df[data_df[\"anxiety_status\"] == 1]\n",
    "    df_minority = data_df[data_df[\"anxiety_status\"] == 0]\n",
    "    \n",
    "    # Upsample minority class\n",
    "    data_minority = resample(df_minority, \n",
    "                            replace=True,                       # sample with replacement\n",
    "                            n_samples=len(df_majority.index),   # to match majority class\n",
    "                            random_state=123)                   # reproducible results\n",
    "\n",
    "    data_df = pd.concat([df_majority, data_minority])\n",
    "    data_df = data_df.reset_index(drop=True)\n",
    "\n",
    "    # Extract the label columns; separate features and labels\n",
    "    labels_df = data_df[[\"anxiety_status\"]].copy()\n",
    "    feats_df = data_df.drop([\"anxiety_score\", \"anxiety_status\"], axis=1)\n",
    "\n",
    "    # z-score normalization\n",
    "    def z_score_norm(row, col, mean, stdev):\n",
    "        z_score = (float(row[col]) - mean) / stdev\n",
    "        return float(z_score)\n",
    "\n",
    "    # One-hot encode gender and region\n",
    "    label_encoder = LabelEncoder()\n",
    "    oneh_encoder = OneHotEncoder()\n",
    "\n",
    "    # Gender\n",
    "    gender = label_encoder.fit_transform(feats_df[\"gender\"])\n",
    "    gender = pd.DataFrame(gender)\n",
    "    gender = pd.DataFrame(oneh_encoder.fit_transform(gender).toarray())\n",
    "    gender.columns = [\"gender_m\", \"gender_f\"]\n",
    "\n",
    "    # Region\n",
    "    region = label_encoder.fit_transform(feats_df[\"region\"])\n",
    "    region = pd.DataFrame(region)\n",
    "    region = pd.DataFrame(oneh_encoder.fit_transform(region).toarray())\n",
    "    region.columns = [\"region_other\", \"region_east\", \"region_west\"]\n",
    "\n",
    "    # Combine and remove original columns\n",
    "    feats_df = feats_df.drop([\"gender\", \"country\", \"region\", \"agegroup\", \"continent\"], axis=1)\n",
    "    feats_df = pd.concat([feats_df, gender, region], axis=1)\n",
    "\n",
    "    # One-hot encode question answers\n",
    "    for col in feats_df.columns:\n",
    "        if col[0] == \"Q\" and col[-1] == \"A\":\n",
    "            temp = label_encoder.fit_transform(feats_df[col])\n",
    "            temp = pd.DataFrame(temp)\n",
    "            temp = pd.DataFrame(oneh_encoder.fit_transform(temp).toarray())\n",
    "\n",
    "            col_names = []\n",
    "            for c in temp.columns:\n",
    "                col_names.append(\"{0}_{1}\".format(col, c))\n",
    "            temp.columns = col_names\n",
    "\n",
    "            feats_df = feats_df.drop([col], axis=1)\n",
    "            feats_df = pd.concat([feats_df, temp], axis=1)\n",
    "\n",
    "    # Normalize numerical columns (Use z-score)\n",
    "    mean = feats_df[\"age\"].mean()\n",
    "    stdev = feats_df[\"age\"].std()\n",
    "    feats_df[\"age_norm\"] = feats_df.apply(\n",
    "                    lambda row: z_score_norm(row, \"age\", mean, stdev), axis=1)\n",
    "    feats_df = feats_df.drop([\"age\"], axis=1)\n",
    "\n",
    "    return feats_df, labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "891ec365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(feats_df, labels_df, rand=0, save=False):\n",
    "    \"\"\"\n",
    "    Train / validation / test (holdout) dataset split\n",
    "    \"\"\"\n",
    "    feats_arr = np.array(feats_df)\n",
    "    labels_arr = np.array(labels_df)\n",
    "    traintest_feats, valid_feats, traintest_labels, valid_labels = \\\n",
    "        train_test_split(feats_arr, labels_arr, test_size=0.10, random_state=seed)\n",
    "    train_feats, holdout_feats, train_labels, holdout_labels = \\\n",
    "        train_test_split(traintest_feats, traintest_labels, test_size=0.1111, random_state=rand)\n",
    "\n",
    "    train_feats = train_feats.astype(float)\n",
    "    train_labels = train_labels.astype(float)\n",
    "    valid_feats = valid_feats.astype(float)\n",
    "    valid_labels = valid_labels.astype(float)\n",
    "    holdout_feats = holdout_feats.astype(float)\n",
    "    holdout_labels = holdout_labels.astype(float)\n",
    "\n",
    "    if save:\n",
    "        train_feats.to_csv(os.path.join(data_folder, \"train_feats.csv\"), index=None)\n",
    "        train_labels.to_csv(os.path.join(data_folder, \"train_labels.csv\"), index=None)\n",
    "        valid_feats.to_csv(os.path.join(data_folder, \"valid_feats.csv\"), index=None)\n",
    "        valid_labels.to_csv(os.path.join(data_folder, \"valid_labels.csv\"), index=None)\n",
    "        holdout_feats.to_csv(os.path.join(data_folder, \"holdout_feats.csv\"), index=None)\n",
    "        holdout_labels.to_csv(os.path.join(data_folder, \"holdout_labels.csv\"), index=None)\n",
    "\n",
    "    return train_feats, train_labels, valid_feats, valid_labels, holdout_feats, holdout_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e75254-73d1-449e-ad65-1857fafb283c",
   "metadata": {},
   "source": [
    "Preprocess the filtered data by calling the preprocess function, and save the preprocessed data in the data_folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93447e26-0463-405d-9eaf-cc2e64a0d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "data = pd.read_csv(os.path.join(data_folder, \"data_filtered_1000.csv\")) # Using the sample dataset. Change the file name accordingly if using another dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a89317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and labels, save as CSV\n",
    "feats_df, labels_df = preprocess(data)\n",
    "\n",
    "feats_df.to_csv(os.path.join(data_folder, \"features.csv\"), index=None)\n",
    "labels_df.to_csv(os.path.join(data_folder, \"labels.csv\"), index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
