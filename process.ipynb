{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pycountry_convert as pc\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data folder\n",
    "data_folder = \"./DASS_data\"\n",
    "dataset = pd.read_csv(\"./DASS_data/data.csv\", delimiter='\\t', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1A               0\n",
      "Q1I               0\n",
      "Q1E               0\n",
      "Q2A               0\n",
      "Q2I               0\n",
      "              ...  \n",
      "race              0\n",
      "voted             0\n",
      "married           0\n",
      "familysize        0\n",
      "major         11425\n",
      "Length: 172, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = dataset.isna().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multiple columns in-place\n",
    "dataset.drop([\"major\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q1A', 'Q2A', 'Q3A', 'Q4A', 'Q5A', 'Q6A', 'Q7A', 'Q8A', 'Q9A', 'Q10A', 'Q11A', 'Q12A', 'Q13A', 'Q14A', 'Q15A', 'Q16A', 'Q17A', 'Q18A', 'Q19A', 'Q20A', 'Q21A', 'Q22A', 'Q23A', 'Q24A', 'Q25A', 'Q26A', 'Q27A', 'Q28A', 'Q29A', 'Q30A', 'Q31A', 'Q32A', 'Q33A', 'Q34A', 'Q35A', 'Q36A', 'Q37A', 'Q38A', 'Q39A', 'Q40A', 'Q41A', 'Q42A']\n"
     ]
    }
   ],
   "source": [
    "# Define the questions contributing to each score\n",
    "depression_questions = ['Q3A', 'Q5A', 'Q10A', 'Q13A', 'Q16A', 'Q17A', 'Q21A', 'Q24A', 'Q26A', 'Q31A', 'Q34A', 'Q37A', 'Q38A', 'Q42A']\n",
    "anxiety_questions = ['Q2A', 'Q4A', 'Q7A', 'Q9A', 'Q15A', 'Q19A', 'Q20A', 'Q23A', 'Q25A', 'Q28A', 'Q30A', 'Q36A', 'Q40A', 'Q41A']\n",
    "stress_questions = ['Q1A', 'Q6A', 'Q8A', 'Q11A', 'Q12A', 'Q14A', 'Q18A', 'Q22A', 'Q27A', 'Q29A', 'Q32A', 'Q33A', 'Q35A', 'Q39A']\n",
    "\n",
    "# Identify columns that end with 'A'\n",
    "columns_to_update = [col for col in dataset.columns if col.endswith('A')]\n",
    "print(columns_to_update)\n",
    "\n",
    "# Add 1 to each of these columns\n",
    "for col in columns_to_update:\n",
    "    dataset[col] = dataset[col] - 1\n",
    "\n",
    "# Calculate the Depression, Anxiety, and Stress scores\n",
    "dataset['Depression_Score'] = dataset[depression_questions].sum(axis=1)\n",
    "dataset['Anxiety_Score'] = dataset[anxiety_questions].sum(axis=1)\n",
    "dataset['Stress_Score'] = dataset[stress_questions].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to categorize the scores\n",
    "def categorize_depression(score):\n",
    "    if score <= 9:\n",
    "        return 0\n",
    "    elif score <= 13:\n",
    "        return 1\n",
    "    elif score <= 20:\n",
    "        return 2\n",
    "    elif score <= 27:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "def categorize_anxiety(score):\n",
    "    if score <= 7:\n",
    "        return 0\n",
    "    elif score <= 9:\n",
    "        return 1\n",
    "    elif score <= 14:\n",
    "        return 2\n",
    "    elif score <= 19:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "def categorize_stress(score):\n",
    "    if score <= 14:\n",
    "        return 0\n",
    "    elif score <= 18:\n",
    "        return 1\n",
    "    elif score <= 25:\n",
    "        return 2\n",
    "    elif score <= 33:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the categorization functions\n",
    "dataset['Depression_Level'] = dataset['Depression_Score'].apply(categorize_depression)\n",
    "dataset['Anxiety_Level'] = dataset['Anxiety_Score'].apply(categorize_anxiety)\n",
    "dataset['Stress_Level'] = dataset['Stress_Score'].apply(categorize_stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "anxiety_data = dataset.drop(['Depression_Level', 'Stress_Level', 'Depression_Score', 'Stress_Score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n",
      "/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/530656904.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  anxiety_data = anxiety_data[dataset[col] <= cutoff_value]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Identify columns ending with 'E'\n",
    "time_columns = [col for col in anxiety_data.columns if col.endswith('E')]\n",
    "\n",
    "# Step 3: Filter out rows with extreme values in any of the time columns\n",
    "for col in time_columns:\n",
    "    cutoff_value = 100000\n",
    "    anxiety_data = anxiety_data[dataset[col] <= cutoff_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_country(row):\n",
    "    # Encode country into three major regions (east, west, other)\n",
    "    country_code = row[\"country\"]\n",
    "    try:\n",
    "        if country_code and country_code != \"NONE\":\n",
    "            continent_name = pc.country_alpha2_to_continent_code(country_code)\n",
    "            if continent_name == \"AS\":\n",
    "                region_name = \"east\"\n",
    "            elif continent_name in [\"NA\", \"EU\", \"OC\"]:\n",
    "                region_name = \"west\"\n",
    "            else:\n",
    "                region_name = \"other\"\n",
    "        else:\n",
    "            region_name = \"\"\n",
    "    except:\n",
    "        region_name = \"\"\n",
    "    return region_name\n",
    "    \n",
    "def encode_continent(row):\n",
    "    # Encode country into three major regions (east, west, other)\n",
    "    country_code = row[\"country\"]\n",
    "    try:\n",
    "        if country_code and country_code != \"NONE\":\n",
    "            continent_name = pc.country_alpha2_to_continent_code(country_code)\n",
    "        else:\n",
    "            continent_name = \"\"\n",
    "    except:\n",
    "        continent_name = \"\"\n",
    "    return continent_name\n",
    "\n",
    "def encode_age(row):\n",
    "    # Encode age into groups\n",
    "    age = int(row['age'])\n",
    "    if age < 18:\n",
    "        agegroup = 0\n",
    "    elif age < 28:\n",
    "        agegroup = 1\n",
    "    elif age < 38:\n",
    "        agegroup = 2\n",
    "    elif age < 48:\n",
    "        agegroup = 3\n",
    "    elif age < 58:\n",
    "        agegroup = 4\n",
    "    elif age < 68:\n",
    "        agegroup = 5\n",
    "    else:\n",
    "        agegroup = 6\n",
    "    return agegroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "anxiety_data[\"agegroup\"] = dataset.apply(lambda row: encode_age(row), axis=1)\n",
    "anxiety_data[\"continent\"] = dataset.apply(lambda row: encode_continent(row), axis=1)\n",
    "anxiety_data[\"region\"] = dataset.apply(lambda row: encode_country(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data\n",
    "anxiety_data.drop(anxiety_data[(anxiety_data['gender'] == 0) | (anxiety_data['gender'] == 3)].index, inplace=True)  # Male and females only\n",
    "anxiety_data[anxiety_data['age'] >= 18]  # Adults only\n",
    "anxiety_data = anxiety_data[anxiety_data['region'] != \"\"]  # Must have region\n",
    "anxiety_data = anxiety_data.dropna()\n",
    "\n",
    "# Remove data with countries that have strict data privacy laws (for public use only)\n",
    "# Define the list of countries to exclude\n",
    "countries_to_exclude = [\"CH\", \"IN\", \"JA\", \"AU\"]\n",
    "# Filter the dataset to exclude the specified countries and continent\n",
    "anxiety_data = anxiety_data[(anxiety_data['continent'] != \"EU\") & ~anxiety_data['country'].isin(countries_to_exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 31629\n"
     ]
    }
   ],
   "source": [
    "num_samples = anxiety_data.shape[0]\n",
    "print(\"Number of samples:\", num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering:\n",
      "gender\n",
      "2    25094\n",
      "1     6535\n",
      "Name: count, dtype: int64\n",
      "agegroup\n",
      "1    20888\n",
      "0     5434\n",
      "2     3393\n",
      "3     1043\n",
      "4      592\n",
      "5      216\n",
      "6       63\n",
      "Name: count, dtype: int64\n",
      "23.420689873217615 23.621835097052116\n",
      "continent\n",
      "AS    22357\n",
      "NA     8546\n",
      "SA      306\n",
      "AF      216\n",
      "OC      204\n",
      "Name: count, dtype: int64\n",
      "region\n",
      "east     22357\n",
      "west      8750\n",
      "other      522\n",
      "Name: count, dtype: int64\n",
      "Anxiety_Score\n",
      "10    1166\n",
      "13    1150\n",
      "7     1134\n",
      "6     1109\n",
      "12    1106\n",
      "8     1100\n",
      "9     1097\n",
      "14    1083\n",
      "11    1078\n",
      "16    1046\n",
      "5     1018\n",
      "4     1016\n",
      "3      999\n",
      "15     984\n",
      "17     963\n",
      "18     944\n",
      "22     922\n",
      "19     908\n",
      "20     901\n",
      "21     887\n",
      "2      856\n",
      "23     813\n",
      "24     796\n",
      "25     745\n",
      "1      739\n",
      "0      671\n",
      "26     660\n",
      "28     628\n",
      "27     624\n",
      "29     563\n",
      "30     529\n",
      "31     468\n",
      "32     465\n",
      "33     378\n",
      "34     356\n",
      "35     320\n",
      "36     294\n",
      "37     262\n",
      "38     214\n",
      "39     185\n",
      "42     184\n",
      "40     149\n",
      "41     119\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data summary (after filtering)\n",
    "print(\"\\nAfter filtering:\")\n",
    "print(anxiety_data['gender'].value_counts())\n",
    "print(anxiety_data['agegroup'].value_counts())\n",
    "print(anxiety_data['age'].mean(), anxiety_data['age'].std())\n",
    "print(anxiety_data['continent'].value_counts())\n",
    "print(anxiety_data['region'].value_counts())\n",
    "print(anxiety_data['Anxiety_Score'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Continent  Mean Age (years)  Standard deviation Age (years)  Males  \\\n",
      "0           Asia              23.6                            27.0   3896   \n",
      "1         Europe              28.5                            11.3    955   \n",
      "2  North America              29.9                            12.9   2016   \n",
      "3          Other              28.7                            11.6    350   \n",
      "\n",
      "   Females  \n",
      "0    18246  \n",
      "1     1543  \n",
      "2     3990  \n",
      "3      719  \n",
      "\\begin{table}\n",
      "\\caption{Demographic Information by Continent}\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "Continent & Mean Age (years) & Standard deviation Age (years) & Males & Females \\\\\n",
      "\\midrule\n",
      "Asia & 23.600000 & 27.000000 & 3896 & 18246 \\\\\n",
      "Europe & 28.500000 & 11.300000 & 955 & 1543 \\\\\n",
      "North America & 29.900000 & 12.900000 & 2016 & 3990 \\\\\n",
      "Other & 28.700000 & 11.600000 & 350 & 719 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the data based on your provided summary\n",
    "table_data = {\n",
    "    'Continent': ['Asia', 'Europe', 'North America', 'Other'],\n",
    "    'Mean Age (years)': [23.6, 28.5, 29.9, 28.7],\n",
    "    'Standard deviation Age (years)': [27.0, 11.3, 12.9, 11.6],\n",
    "    'Males': [3896, 955, 2016, 350],\n",
    "    'Females': [18246, 1543, 3990, 719]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(table_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Convert the DataFrame to LaTeX format\n",
    "latex_table = df.to_latex(index=False, caption=\"Demographic Information by Continent\")\n",
    "\n",
    "# Print the LaTeX table\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in anxiety_data.columns:\n",
    "    if \"TIPI\" in col or \"VCL\" in col:\n",
    "        anxiety_data = anxiety_data.drop([col], axis=1)\n",
    "    elif col[0] == \"Q\" and (col[-1] == \"E\" or col[-1] == \"I\"):\n",
    "        anxiety_data = anxiety_data.drop([col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data folder\n",
    "seed = 100\n",
    "data_folder = \"./DASS_data\"\n",
    "\n",
    "features_dataframe = anxiety_data.drop(['Anxiety_Level', 'Anxiety_Score'], axis=1)\n",
    "features_dataframe.to_csv(os.path.join(data_folder, \"original_features.csv\"), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Anxiety_Level\n",
       " 4    11462\n",
       " 0     7542\n",
       " 2     5583\n",
       " 3     4845\n",
       " 1     2197\n",
       " Name: count, dtype: int64,\n",
       " Anxiety_Level\n",
       " 4    0.362389\n",
       " 0    0.238452\n",
       " 2    0.176515\n",
       " 3    0.153182\n",
       " 1    0.069462\n",
       " Name: count, dtype: float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anxiety_score_counts = anxiety_data['Anxiety_Level'].value_counts()\n",
    "anxiety_score_proportions = anxiety_score_counts / len(anxiety_data)\n",
    "anxiety_score_counts, anxiety_score_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataframe):\n",
    "    \n",
    "    anxiety_level_0 = dataframe[dataframe['Anxiety_Level'] == 0]\n",
    "    anxiety_level_1 = dataframe[dataframe['Anxiety_Level'] == 1]\n",
    "    anxiety_level_2 = dataframe[dataframe['Anxiety_Level'] == 2]\n",
    "    anxiety_level_3 = dataframe[dataframe['Anxiety_Level'] == 3]\n",
    "    anxiety_level_4 = dataframe[dataframe['Anxiety_Level'] == 4]\n",
    "    \n",
    "    # Upsample the minority classes\n",
    "    anxiety_level_0_upsampled = resample(anxiety_level_0, replace=True, n_samples=len(anxiety_level_4.index), random_state=seed)\n",
    "    anxiety_level_1_upsampled = resample(anxiety_level_1, replace=True, n_samples=len(anxiety_level_4.index), random_state=seed)\n",
    "    anxiety_level_2_upsampled = resample(anxiety_level_2, replace=True, n_samples=len(anxiety_level_4.index), random_state=seed)\n",
    "    anxiety_level_3_upsampled = resample(anxiety_level_3, replace=True, n_samples=len(anxiety_level_4.index), random_state=seed)\n",
    "    \n",
    "    anxiety_data_upsampled = pd.concat([anxiety_level_0_upsampled, anxiety_level_1_upsampled, anxiety_level_2_upsampled, anxiety_level_3_upsampled, anxiety_level_4])\n",
    "    anxiety_data = anxiety_data_upsampled.reset_index(drop=True)\n",
    "    \n",
    "    labels_dataframe = anxiety_data[['Anxiety_Level']].copy()\n",
    "    features_dataframe = anxiety_data.drop(['Anxiety_Level', 'Anxiety_Score'], axis=1)\n",
    "    features_dataframe.to_csv(os.path.join(data_folder, \"original_features.csv\"), index=None)\n",
    "    \n",
    "    # z-score normalization\n",
    "    def z_score_norm(row, col, mean, stdev):\n",
    "        z_score = (float(row[col]) - mean) / stdev\n",
    "        return float(z_score)\n",
    "    \n",
    "    # One-hot encode gender and region\n",
    "    label_encoder = LabelEncoder()\n",
    "    onehot_encoder = OneHotEncoder()\n",
    "    \n",
    "    # Label encode the target\n",
    "    label_encoder = LabelEncoder()\n",
    "    dataframe['Anxiety_Level'] = label_encoder.fit_transform(dataframe['Anxiety_Level'])\n",
    "    \n",
    "    # Gender\n",
    "    gender = label_encoder.fit_transform(features_dataframe[\"gender\"])\n",
    "    gender = pd.DataFrame(gender)\n",
    "    gender = pd.DataFrame(onehot_encoder.fit_transform(gender).toarray())\n",
    "    gender.columns = [\"gender_m\", \"gender_f\"]\n",
    "    \n",
    "    # Region\n",
    "    region = label_encoder.fit_transform(features_dataframe[\"region\"])\n",
    "    region = pd.DataFrame(region)\n",
    "    region = pd.DataFrame(onehot_encoder.fit_transform(region).toarray())\n",
    "    region.columns = [\"region_other\", \"region_east\", \"region_west\"]\n",
    "    \n",
    "    # Combine and remove original columns\n",
    "    features_dataframe = features_dataframe.drop([\"gender\", \"country\", \"region\", \"agegroup\", \"continent\"], axis=1)\n",
    "    features_dataframe = pd.concat([features_dataframe, gender, region], axis=1)\n",
    "    \n",
    "    # One-hot encode question answers\n",
    "    for col in features_dataframe.columns:\n",
    "        if col[0] == \"Q\" and col[-1] == \"A\":\n",
    "            temp = label_encoder.fit_transform(features_dataframe[col])\n",
    "            temp = pd.DataFrame(temp)\n",
    "            temp = pd.DataFrame(onehot_encoder.fit_transform(temp).toarray())\n",
    "\n",
    "            col_names = []\n",
    "            for c in temp.columns:\n",
    "                col_names.append(\"{0}_{1}\".format(col, c))\n",
    "            temp.columns = col_names\n",
    "\n",
    "            features_dataframe = features_dataframe.drop([col], axis=1)\n",
    "            features_dataframe = pd.concat([features_dataframe, temp], axis=1)\n",
    "    \n",
    "    # Normalize numerical columns (Use z-score)\n",
    "    mean = features_dataframe[\"age\"].mean()\n",
    "    stdev = features_dataframe[\"age\"].std()\n",
    "    features_dataframe[\"age_norm\"] = features_dataframe.apply(\n",
    "                    lambda row: z_score_norm(row, \"age\", mean, stdev), axis=1)\n",
    "    features_dataframe = features_dataframe.drop([\"age\"], axis=1)\n",
    "    \n",
    "\n",
    "    return features_dataframe, labels_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and labels, save as CSV\n",
    "features_df, labels_df = preprocess(anxiety_data)\n",
    "# One hot coded. Save as CSV\n",
    "features_df.to_csv(os.path.join(data_folder, \"features.csv\"), index=None)\n",
    "labels_df.to_csv(os.path.join(data_folder, \"labels.csv\"), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Anxiety_Level\n",
       " 0    11462\n",
       " 1    11462\n",
       " 2    11462\n",
       " 3    11462\n",
       " 4    11462\n",
       " Name: count, dtype: int64,\n",
       " Anxiety_Level\n",
       " 0    0.2\n",
       " 1    0.2\n",
       " 2    0.2\n",
       " 3    0.2\n",
       " 4    0.2\n",
       " Name: count, dtype: float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anxiety_score_counts = labels_df['Anxiety_Level'].value_counts()\n",
    "anxiety_score_proportions = anxiety_score_counts / len(labels_df)\n",
    "anxiety_score_counts, anxiety_score_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q28A_0', 'Q30A_1', 'Q7A_0', 'Q36A_0', 'Q40A_3', 'Q4A_0', 'Q20A_3', 'Q20A_0', 'Q41A_0', 'Q9A_3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mrmr import mrmr_classif\n",
    "\n",
    "\n",
    "train_feats = pd.read_csv(os.path.join(data_folder, \"features.csv\"))\n",
    "train_feats = train_feats.drop([\"age_norm\", \"gender_m\", \"gender_f\", \"region_other\", \"region_east\", \"region_west\"], axis=1)  # Comment this line to include demographics\n",
    "labels = pd.read_csv(os.path.join(data_folder, \"labels.csv\"))\n",
    "\n",
    "labels = labels[\"Anxiety_Level\"]\n",
    "\n",
    "selected_features = mrmr_classif(X=train_feats, y=labels, K=10)\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q28A', 'Q20A', 'Q40A', 'Q7A', 'Q36A', 'Q9A', 'Q4A', 'Q41A', 'Q30A', 'Q25A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Not one-hot encoded dataset\n",
    "train_feats = anxiety_data # Using sample dataset. Change the file name accordingly if using another dataset.\n",
    "train_feats = train_feats.drop([\"country\",\"gender\",\"age\",\"agegroup\",\"continent\",\"region\",\"Anxiety_Score\", \"Anxiety_Level\"], axis=1)\n",
    "\n",
    "labels = anxiety_data[\"Anxiety_Level\"]\n",
    "\n",
    "# print(MRMR(train_feats.to_numpy(), labels.to_numpy().ravel(), show_top)) # The customized function approach\n",
    "selected_features = mrmr_classif(X=train_feats, y=labels, K=10) # The mrmr library approach\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57310, 42) (57310, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the dataset\n",
    "X = pd.read_csv(os.path.join(data_folder, \"original_features.csv\"))\n",
    "y = pd.read_csv(os.path.join(data_folder, \"labels.csv\"))\n",
    "for column in X.columns:\n",
    "    if \"A\" not in column:\n",
    "        X.drop([column], axis=1, inplace=True)\n",
    "\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45848, 42) (11462, 42) (45848, 1) (11462, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=1200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=1200)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=1200)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100,random_state=1200)\n",
    "model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45848, 42, 5)\n"
     ]
    }
   ],
   "source": [
    "# Create a SHAP explainer object\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values for the training set\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "print(shap_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 2 is out of bounds for array of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Aggregate SHAP values across classes and samples\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m shap_values_abs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(shap_values_abs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Ensure the resulting array is 1-dimensional\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/numpy/core/_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 2 is out of bounds for array of dimension 2"
     ]
    }
   ],
   "source": [
    "# Aggregate SHAP values across classes and samples\n",
    "shap_values_abs = np.abs(shap_values).sum(axis=2).mean(axis=0)\n",
    "print(shap_values_abs.shape)\n",
    "# Ensure the resulting array is 1-dimensional\n",
    "shap_values_abs = shap_values_abs.flatten()\n",
    "print(shap_values_abs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a DataFrame with feature names and their mean absolute SHAP values\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m shap_summary \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshap_value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mshap_values_abs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Sort the features by SHAP value in descending order\u001b[39;00m\n\u001b[1;32m      5\u001b[0m shap_summary \u001b[38;5;241m=\u001b[39m shap_summary\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshap_value\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with feature names and their mean absolute SHAP values\n",
    "shap_summary = pd.DataFrame({'feature': X_train.columns, 'shap_value': shap_values_abs})\n",
    "\n",
    "# Sort the features by SHAP value in descending order\n",
    "shap_summary = shap_summary.sort_values(by='shap_value', ascending=False)\n",
    "print(shap_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values for a single prediction (first instance of the test set)\n",
    "# shap_values_single = explainer.shap_values(X_test.iloc[0, :].values.reshape(1, -1))\n",
    "\n",
    "# # For multi-class models, shap_values_single will be a list of arrays\n",
    "# # Here, we choose the SHAP values for the specific class (e.g., class 0)\n",
    "# shap_values_single_class = shap_values_single[0][0]\n",
    "\n",
    "# # Create a waterfall plot for the first instance and specific class\n",
    "# shap.waterfall_plot(shap.Explanation(values=shap_values_single_class, \n",
    "#                                      base_values=explainer.expected_value[0], \n",
    "#                                      data=X_test.iloc[0, :], \n",
    "#                                      feature_names=X_test.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "features = pd.read_csv('DASS_data/original_features.csv')  # Update with the correct file path\n",
    "labels = pd.read_csv('DASS_data/labels.csv')      # Update with the correct file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the desired features\n",
    "selected_features = ['Q40A', 'Q28A', 'Q20A', 'Q36A', 'Q9A', 'Q2A', 'Q25A', 'Q30A', 'Q7A', 'Q4A']\n",
    "\n",
    "# Extract the selected features\n",
    "X = features[selected_features]\n",
    "y = labels['Anxiety_Level']  # Ensure 'label' column contains the multi-class labels (0-4)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.4669 - loss: 1.1882 - val_accuracy: 0.7388 - val_loss: 0.5831\n",
      "Epoch 2/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - accuracy: 0.6985 - loss: 0.6763 - val_accuracy: 0.7724 - val_loss: 0.5236\n",
      "Epoch 3/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - accuracy: 0.7243 - loss: 0.6342 - val_accuracy: 0.7802 - val_loss: 0.5065\n",
      "Epoch 4/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - accuracy: 0.7364 - loss: 0.6047 - val_accuracy: 0.7841 - val_loss: 0.4993\n",
      "Epoch 5/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.7437 - loss: 0.5861 - val_accuracy: 0.7906 - val_loss: 0.4868\n",
      "Epoch 6/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.7535 - loss: 0.5690 - val_accuracy: 0.7950 - val_loss: 0.4770\n",
      "Epoch 7/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.7522 - loss: 0.5663 - val_accuracy: 0.7955 - val_loss: 0.4793\n",
      "Epoch 8/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.7606 - loss: 0.5518 - val_accuracy: 0.7995 - val_loss: 0.4691\n",
      "Epoch 9/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.7647 - loss: 0.5464 - val_accuracy: 0.8007 - val_loss: 0.4705\n",
      "Epoch 10/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.7676 - loss: 0.5400 - val_accuracy: 0.8011 - val_loss: 0.4694\n",
      "Epoch 11/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - accuracy: 0.7702 - loss: 0.5327 - val_accuracy: 0.8044 - val_loss: 0.4626\n",
      "Epoch 12/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.7738 - loss: 0.5230 - val_accuracy: 0.8017 - val_loss: 0.4629\n",
      "Epoch 13/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - accuracy: 0.7717 - loss: 0.5239 - val_accuracy: 0.8020 - val_loss: 0.4657\n",
      "Epoch 14/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.7750 - loss: 0.5219 - val_accuracy: 0.8034 - val_loss: 0.4648\n",
      "Epoch 15/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.7777 - loss: 0.5139 - val_accuracy: 0.8014 - val_loss: 0.4660\n",
      "Epoch 16/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.7803 - loss: 0.5128 - val_accuracy: 0.8015 - val_loss: 0.4660\n",
      "Epoch 17/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.7791 - loss: 0.5096 - val_accuracy: 0.7985 - val_loss: 0.4666\n",
      "Epoch 18/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.7746 - loss: 0.5109 - val_accuracy: 0.8021 - val_loss: 0.4641\n",
      "Epoch 19/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - accuracy: 0.7811 - loss: 0.5059 - val_accuracy: 0.8015 - val_loss: 0.4704\n",
      "Epoch 20/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.7804 - loss: 0.5048 - val_accuracy: 0.7984 - val_loss: 0.4709\n",
      "Epoch 21/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.7838 - loss: 0.4986 - val_accuracy: 0.7984 - val_loss: 0.4730\n",
      "Epoch 22/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.7860 - loss: 0.4967 - val_accuracy: 0.7920 - val_loss: 0.4770\n",
      "Epoch 23/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.7807 - loss: 0.5039 - val_accuracy: 0.7885 - val_loss: 0.4795\n",
      "Epoch 24/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - accuracy: 0.7876 - loss: 0.4893 - val_accuracy: 0.7866 - val_loss: 0.4804\n",
      "Epoch 25/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - accuracy: 0.7826 - loss: 0.4954 - val_accuracy: 0.7883 - val_loss: 0.4788\n",
      "Epoch 26/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - accuracy: 0.7807 - loss: 0.5003 - val_accuracy: 0.7954 - val_loss: 0.4682\n",
      "Epoch 27/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.7809 - loss: 0.4979 - val_accuracy: 0.7983 - val_loss: 0.4696\n",
      "Epoch 28/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.7865 - loss: 0.4857 - val_accuracy: 0.7984 - val_loss: 0.4699\n",
      "Epoch 29/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 0.7871 - loss: 0.4925 - val_accuracy: 0.7879 - val_loss: 0.4763\n",
      "Epoch 30/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.7893 - loss: 0.4889 - val_accuracy: 0.7882 - val_loss: 0.4741\n",
      "Epoch 31/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - accuracy: 0.7817 - loss: 0.4963 - val_accuracy: 0.7895 - val_loss: 0.4746\n",
      "Epoch 32/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604us/step - accuracy: 0.7869 - loss: 0.4895 - val_accuracy: 0.7899 - val_loss: 0.4714\n",
      "Epoch 33/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.7921 - loss: 0.4843 - val_accuracy: 0.7938 - val_loss: 0.4678\n",
      "Epoch 34/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611us/step - accuracy: 0.7913 - loss: 0.4823 - val_accuracy: 0.7885 - val_loss: 0.4747\n",
      "Epoch 35/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.7885 - loss: 0.4861 - val_accuracy: 0.7848 - val_loss: 0.4751\n",
      "Epoch 36/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - accuracy: 0.7835 - loss: 0.4926 - val_accuracy: 0.7889 - val_loss: 0.4707\n",
      "Epoch 37/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - accuracy: 0.7860 - loss: 0.4873 - val_accuracy: 0.7900 - val_loss: 0.4712\n",
      "Epoch 38/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - accuracy: 0.7931 - loss: 0.4825 - val_accuracy: 0.7896 - val_loss: 0.4732\n",
      "Epoch 39/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - accuracy: 0.7884 - loss: 0.4800 - val_accuracy: 0.7817 - val_loss: 0.4826\n",
      "Epoch 40/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - accuracy: 0.7919 - loss: 0.4827 - val_accuracy: 0.7826 - val_loss: 0.4837\n",
      "Epoch 41/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.7947 - loss: 0.4757 - val_accuracy: 0.7891 - val_loss: 0.4733\n",
      "Epoch 42/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - accuracy: 0.7953 - loss: 0.4743 - val_accuracy: 0.7764 - val_loss: 0.5004\n",
      "Epoch 43/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.7904 - loss: 0.4811 - val_accuracy: 0.7761 - val_loss: 0.4960\n",
      "Epoch 44/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.7903 - loss: 0.4777 - val_accuracy: 0.7792 - val_loss: 0.4921\n",
      "Epoch 45/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.7912 - loss: 0.4784 - val_accuracy: 0.7778 - val_loss: 0.4973\n",
      "Epoch 46/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.7871 - loss: 0.4865 - val_accuracy: 0.7791 - val_loss: 0.4879\n",
      "Epoch 47/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.7910 - loss: 0.4718 - val_accuracy: 0.7793 - val_loss: 0.4975\n",
      "Epoch 48/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.7898 - loss: 0.4794 - val_accuracy: 0.7743 - val_loss: 0.4968\n",
      "Epoch 49/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.7925 - loss: 0.4739 - val_accuracy: 0.7830 - val_loss: 0.4843\n",
      "Epoch 50/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.7939 - loss: 0.4743 - val_accuracy: 0.7795 - val_loss: 0.4910\n",
      "Epoch 51/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.7944 - loss: 0.4704 - val_accuracy: 0.7797 - val_loss: 0.4949\n",
      "Epoch 52/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - accuracy: 0.7904 - loss: 0.4776 - val_accuracy: 0.7782 - val_loss: 0.4915\n",
      "Epoch 53/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step - accuracy: 0.7960 - loss: 0.4780 - val_accuracy: 0.7786 - val_loss: 0.4954\n",
      "Epoch 54/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.7898 - loss: 0.4764 - val_accuracy: 0.7652 - val_loss: 0.5174\n",
      "Epoch 55/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - accuracy: 0.7924 - loss: 0.4742 - val_accuracy: 0.7697 - val_loss: 0.5103\n",
      "Epoch 56/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - accuracy: 0.7922 - loss: 0.4711 - val_accuracy: 0.7764 - val_loss: 0.4999\n",
      "Epoch 57/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.7925 - loss: 0.4716 - val_accuracy: 0.7722 - val_loss: 0.5049\n",
      "Epoch 58/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.7950 - loss: 0.4709 - val_accuracy: 0.7585 - val_loss: 0.5291\n",
      "Epoch 59/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.7914 - loss: 0.4722 - val_accuracy: 0.7736 - val_loss: 0.5024\n",
      "Epoch 60/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.7969 - loss: 0.4676 - val_accuracy: 0.7883 - val_loss: 0.4716\n",
      "Epoch 61/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - accuracy: 0.7957 - loss: 0.4676 - val_accuracy: 0.7812 - val_loss: 0.4861\n",
      "Epoch 62/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.7979 - loss: 0.4625 - val_accuracy: 0.7788 - val_loss: 0.4881\n",
      "Epoch 63/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.7957 - loss: 0.4662 - val_accuracy: 0.7697 - val_loss: 0.5094\n",
      "Epoch 64/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.7927 - loss: 0.4714 - val_accuracy: 0.7743 - val_loss: 0.5020\n",
      "Epoch 65/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - accuracy: 0.7947 - loss: 0.4734 - val_accuracy: 0.7804 - val_loss: 0.4905\n",
      "Epoch 66/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.7935 - loss: 0.4720 - val_accuracy: 0.7623 - val_loss: 0.5173\n",
      "Epoch 67/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.7981 - loss: 0.4659 - val_accuracy: 0.7631 - val_loss: 0.5231\n",
      "Epoch 68/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613us/step - accuracy: 0.7916 - loss: 0.4749 - val_accuracy: 0.7851 - val_loss: 0.4777\n",
      "Epoch 69/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - accuracy: 0.7963 - loss: 0.4671 - val_accuracy: 0.7744 - val_loss: 0.5021\n",
      "Epoch 70/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.7934 - loss: 0.4675 - val_accuracy: 0.7784 - val_loss: 0.4902\n",
      "Epoch 71/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.7963 - loss: 0.4687 - val_accuracy: 0.7783 - val_loss: 0.4963\n",
      "Epoch 72/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - accuracy: 0.7957 - loss: 0.4686 - val_accuracy: 0.7600 - val_loss: 0.5245\n",
      "Epoch 73/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.7955 - loss: 0.4686 - val_accuracy: 0.7708 - val_loss: 0.5108\n",
      "Epoch 74/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.7958 - loss: 0.4678 - val_accuracy: 0.7783 - val_loss: 0.4893\n",
      "Epoch 75/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.7971 - loss: 0.4665 - val_accuracy: 0.7684 - val_loss: 0.5101\n",
      "Epoch 76/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.7952 - loss: 0.4651 - val_accuracy: 0.7740 - val_loss: 0.5000\n",
      "Epoch 77/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - accuracy: 0.7953 - loss: 0.4666 - val_accuracy: 0.7860 - val_loss: 0.4768\n",
      "Epoch 78/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - accuracy: 0.7971 - loss: 0.4635 - val_accuracy: 0.7752 - val_loss: 0.4928\n",
      "Epoch 79/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.7979 - loss: 0.4621 - val_accuracy: 0.7758 - val_loss: 0.4961\n",
      "Epoch 80/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.7950 - loss: 0.4667 - val_accuracy: 0.7734 - val_loss: 0.5034\n",
      "Epoch 81/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.7959 - loss: 0.4681 - val_accuracy: 0.7812 - val_loss: 0.4797\n",
      "Epoch 82/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.7976 - loss: 0.4642 - val_accuracy: 0.7550 - val_loss: 0.5296\n",
      "Epoch 83/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - accuracy: 0.7987 - loss: 0.4665 - val_accuracy: 0.7810 - val_loss: 0.4874\n",
      "Epoch 84/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.7953 - loss: 0.4631 - val_accuracy: 0.7731 - val_loss: 0.4997\n",
      "Epoch 85/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - accuracy: 0.7929 - loss: 0.4707 - val_accuracy: 0.7842 - val_loss: 0.4782\n",
      "Epoch 86/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.7947 - loss: 0.4697 - val_accuracy: 0.7752 - val_loss: 0.4928\n",
      "Epoch 87/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.7950 - loss: 0.4699 - val_accuracy: 0.7679 - val_loss: 0.5078\n",
      "Epoch 88/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - accuracy: 0.7968 - loss: 0.4665 - val_accuracy: 0.7755 - val_loss: 0.4936\n",
      "Epoch 89/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - accuracy: 0.7970 - loss: 0.4630 - val_accuracy: 0.7655 - val_loss: 0.5234\n",
      "Epoch 90/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.7981 - loss: 0.4619 - val_accuracy: 0.7652 - val_loss: 0.5181\n",
      "Epoch 91/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - accuracy: 0.7970 - loss: 0.4643 - val_accuracy: 0.7762 - val_loss: 0.4981\n",
      "Epoch 92/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628us/step - accuracy: 0.7979 - loss: 0.4620 - val_accuracy: 0.7769 - val_loss: 0.4988\n",
      "Epoch 93/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - accuracy: 0.7971 - loss: 0.4620 - val_accuracy: 0.7768 - val_loss: 0.4948\n",
      "Epoch 94/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.7968 - loss: 0.4636 - val_accuracy: 0.7709 - val_loss: 0.5060\n",
      "Epoch 95/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.7968 - loss: 0.4627 - val_accuracy: 0.7780 - val_loss: 0.4895\n",
      "Epoch 96/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - accuracy: 0.7985 - loss: 0.4612 - val_accuracy: 0.7727 - val_loss: 0.4979\n",
      "Epoch 97/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - accuracy: 0.7957 - loss: 0.4617 - val_accuracy: 0.7708 - val_loss: 0.4999\n",
      "Epoch 98/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.7953 - loss: 0.4641 - val_accuracy: 0.7732 - val_loss: 0.4991\n",
      "Epoch 99/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.8006 - loss: 0.4596 - val_accuracy: 0.7696 - val_loss: 0.5057\n",
      "Epoch 100/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - accuracy: 0.7996 - loss: 0.4575 - val_accuracy: 0.7685 - val_loss: 0.5073\n",
      "Epoch 101/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - accuracy: 0.7974 - loss: 0.4617 - val_accuracy: 0.7691 - val_loss: 0.5084\n",
      "Epoch 102/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - accuracy: 0.8008 - loss: 0.4595 - val_accuracy: 0.7661 - val_loss: 0.5155\n",
      "Epoch 103/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.7998 - loss: 0.4565 - val_accuracy: 0.7762 - val_loss: 0.4941\n",
      "Epoch 104/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.7987 - loss: 0.4612 - val_accuracy: 0.7650 - val_loss: 0.5160\n",
      "Epoch 105/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.8016 - loss: 0.4577 - val_accuracy: 0.7799 - val_loss: 0.4874\n",
      "Epoch 106/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.7982 - loss: 0.4593 - val_accuracy: 0.7625 - val_loss: 0.5232\n",
      "Epoch 107/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.8046 - loss: 0.4530 - val_accuracy: 0.7733 - val_loss: 0.5005\n",
      "Epoch 108/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.8000 - loss: 0.4570 - val_accuracy: 0.7685 - val_loss: 0.5171\n",
      "Epoch 109/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.8015 - loss: 0.4576 - val_accuracy: 0.7743 - val_loss: 0.5009\n",
      "Epoch 110/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.8002 - loss: 0.4577 - val_accuracy: 0.7672 - val_loss: 0.5114\n",
      "Epoch 111/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - accuracy: 0.7971 - loss: 0.4588 - val_accuracy: 0.7522 - val_loss: 0.5409\n",
      "Epoch 112/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.8016 - loss: 0.4564 - val_accuracy: 0.7738 - val_loss: 0.4972\n",
      "Epoch 113/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - accuracy: 0.7985 - loss: 0.4588 - val_accuracy: 0.7626 - val_loss: 0.5220\n",
      "Epoch 114/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step - accuracy: 0.7975 - loss: 0.4609 - val_accuracy: 0.7714 - val_loss: 0.5033\n",
      "Epoch 115/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.8042 - loss: 0.4489 - val_accuracy: 0.7624 - val_loss: 0.5148\n",
      "Epoch 116/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - accuracy: 0.8035 - loss: 0.4508 - val_accuracy: 0.7751 - val_loss: 0.4930\n",
      "Epoch 117/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.8000 - loss: 0.4506 - val_accuracy: 0.7787 - val_loss: 0.4821\n",
      "Epoch 118/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - accuracy: 0.8019 - loss: 0.4555 - val_accuracy: 0.7509 - val_loss: 0.5374\n",
      "Epoch 119/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step - accuracy: 0.7984 - loss: 0.4555 - val_accuracy: 0.7566 - val_loss: 0.5233\n",
      "Epoch 120/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.8011 - loss: 0.4588 - val_accuracy: 0.7706 - val_loss: 0.5083\n",
      "Epoch 121/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626us/step - accuracy: 0.7997 - loss: 0.4585 - val_accuracy: 0.7723 - val_loss: 0.5054\n",
      "Epoch 122/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.7991 - loss: 0.4594 - val_accuracy: 0.7759 - val_loss: 0.4953\n",
      "Epoch 123/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620us/step - accuracy: 0.8013 - loss: 0.4561 - val_accuracy: 0.7731 - val_loss: 0.5013\n",
      "Epoch 124/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.8011 - loss: 0.4536 - val_accuracy: 0.7708 - val_loss: 0.5072\n",
      "Epoch 125/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.8008 - loss: 0.4546 - val_accuracy: 0.7797 - val_loss: 0.4861\n",
      "Epoch 126/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - accuracy: 0.7974 - loss: 0.4635 - val_accuracy: 0.7775 - val_loss: 0.4954\n",
      "Epoch 127/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - accuracy: 0.8031 - loss: 0.4529 - val_accuracy: 0.7774 - val_loss: 0.4913\n",
      "Epoch 128/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.8031 - loss: 0.4540 - val_accuracy: 0.7621 - val_loss: 0.5254\n",
      "Epoch 129/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - accuracy: 0.8024 - loss: 0.4543 - val_accuracy: 0.7665 - val_loss: 0.5139\n",
      "Epoch 130/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.7986 - loss: 0.4567 - val_accuracy: 0.7730 - val_loss: 0.5057\n",
      "Epoch 131/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.8014 - loss: 0.4517 - val_accuracy: 0.7744 - val_loss: 0.5008\n",
      "Epoch 132/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.8042 - loss: 0.4504 - val_accuracy: 0.7610 - val_loss: 0.5218\n",
      "Epoch 133/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - accuracy: 0.8030 - loss: 0.4496 - val_accuracy: 0.7663 - val_loss: 0.5126\n",
      "Epoch 134/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8001 - loss: 0.4509 - val_accuracy: 0.7773 - val_loss: 0.4841\n",
      "Epoch 135/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.7980 - loss: 0.4617 - val_accuracy: 0.7609 - val_loss: 0.5329\n",
      "Epoch 136/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.8076 - loss: 0.4530 - val_accuracy: 0.7752 - val_loss: 0.4931\n",
      "Epoch 137/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.8007 - loss: 0.4539 - val_accuracy: 0.7731 - val_loss: 0.4985\n",
      "Epoch 138/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - accuracy: 0.8039 - loss: 0.4485 - val_accuracy: 0.7700 - val_loss: 0.5056\n",
      "Epoch 139/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.8004 - loss: 0.4584 - val_accuracy: 0.7682 - val_loss: 0.5146\n",
      "Epoch 140/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.8062 - loss: 0.4500 - val_accuracy: 0.7844 - val_loss: 0.4731\n",
      "Epoch 141/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.8075 - loss: 0.4467 - val_accuracy: 0.7827 - val_loss: 0.4812\n",
      "Epoch 142/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.8053 - loss: 0.4487 - val_accuracy: 0.7704 - val_loss: 0.5041\n",
      "Epoch 143/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.8023 - loss: 0.4520 - val_accuracy: 0.7638 - val_loss: 0.5207\n",
      "Epoch 144/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.7961 - loss: 0.4594 - val_accuracy: 0.7782 - val_loss: 0.4895\n",
      "Epoch 145/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - accuracy: 0.8055 - loss: 0.4460 - val_accuracy: 0.7679 - val_loss: 0.5067\n",
      "Epoch 146/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.8021 - loss: 0.4545 - val_accuracy: 0.7775 - val_loss: 0.4859\n",
      "Epoch 147/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.8024 - loss: 0.4539 - val_accuracy: 0.7711 - val_loss: 0.4989\n",
      "Epoch 148/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.8040 - loss: 0.4518 - val_accuracy: 0.7695 - val_loss: 0.5075\n",
      "Epoch 149/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.8019 - loss: 0.4551 - val_accuracy: 0.7719 - val_loss: 0.5031\n",
      "Epoch 150/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.8039 - loss: 0.4545 - val_accuracy: 0.7877 - val_loss: 0.4692\n",
      "Epoch 151/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.8023 - loss: 0.4518 - val_accuracy: 0.7816 - val_loss: 0.4795\n",
      "Epoch 152/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.8003 - loss: 0.4554 - val_accuracy: 0.7740 - val_loss: 0.4954\n",
      "Epoch 153/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.8051 - loss: 0.4478 - val_accuracy: 0.7721 - val_loss: 0.5000\n",
      "Epoch 154/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - accuracy: 0.8031 - loss: 0.4491 - val_accuracy: 0.7647 - val_loss: 0.5208\n",
      "Epoch 155/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.8025 - loss: 0.4539 - val_accuracy: 0.7627 - val_loss: 0.5178\n",
      "Epoch 156/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8041 - loss: 0.4503 - val_accuracy: 0.7676 - val_loss: 0.5088\n",
      "Epoch 157/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.8063 - loss: 0.4447 - val_accuracy: 0.7690 - val_loss: 0.5061\n",
      "Epoch 158/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.8044 - loss: 0.4476 - val_accuracy: 0.7626 - val_loss: 0.5205\n",
      "Epoch 159/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - accuracy: 0.8022 - loss: 0.4479 - val_accuracy: 0.7758 - val_loss: 0.4924\n",
      "Epoch 160/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.8041 - loss: 0.4495 - val_accuracy: 0.7751 - val_loss: 0.5018\n",
      "Epoch 161/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8008 - loss: 0.4524 - val_accuracy: 0.7718 - val_loss: 0.5041\n",
      "Epoch 162/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.8038 - loss: 0.4501 - val_accuracy: 0.7610 - val_loss: 0.5189\n",
      "Epoch 163/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.8024 - loss: 0.4475 - val_accuracy: 0.7737 - val_loss: 0.4978\n",
      "Epoch 164/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8068 - loss: 0.4422 - val_accuracy: 0.7768 - val_loss: 0.4956\n",
      "Epoch 165/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8038 - loss: 0.4462 - val_accuracy: 0.7734 - val_loss: 0.4963\n",
      "Epoch 166/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.8062 - loss: 0.4485 - val_accuracy: 0.7585 - val_loss: 0.5275\n",
      "Epoch 167/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.7992 - loss: 0.4537 - val_accuracy: 0.7738 - val_loss: 0.5012\n",
      "Epoch 168/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.7989 - loss: 0.4526 - val_accuracy: 0.7703 - val_loss: 0.5108\n",
      "Epoch 169/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.8022 - loss: 0.4512 - val_accuracy: 0.7677 - val_loss: 0.5099\n",
      "Epoch 170/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8054 - loss: 0.4464 - val_accuracy: 0.7756 - val_loss: 0.4962\n",
      "Epoch 171/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.8062 - loss: 0.4497 - val_accuracy: 0.7636 - val_loss: 0.5105\n",
      "Epoch 172/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.8049 - loss: 0.4448 - val_accuracy: 0.7808 - val_loss: 0.4870\n",
      "Epoch 173/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.8052 - loss: 0.4500 - val_accuracy: 0.7659 - val_loss: 0.5137\n",
      "Epoch 174/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.8065 - loss: 0.4451 - val_accuracy: 0.7723 - val_loss: 0.5038\n",
      "Epoch 175/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8004 - loss: 0.4535 - val_accuracy: 0.7656 - val_loss: 0.5200\n",
      "Epoch 176/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.8042 - loss: 0.4453 - val_accuracy: 0.7665 - val_loss: 0.5078\n",
      "Epoch 177/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.8031 - loss: 0.4511 - val_accuracy: 0.7673 - val_loss: 0.5104\n",
      "Epoch 178/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.8075 - loss: 0.4450 - val_accuracy: 0.7692 - val_loss: 0.5113\n",
      "Epoch 179/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.8053 - loss: 0.4438 - val_accuracy: 0.7716 - val_loss: 0.5028\n",
      "Epoch 180/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8042 - loss: 0.4474 - val_accuracy: 0.7722 - val_loss: 0.5013\n",
      "Epoch 181/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.8037 - loss: 0.4509 - val_accuracy: 0.7614 - val_loss: 0.5221\n",
      "Epoch 182/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.8076 - loss: 0.4429 - val_accuracy: 0.7836 - val_loss: 0.4854\n",
      "Epoch 183/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8042 - loss: 0.4496 - val_accuracy: 0.7756 - val_loss: 0.4919\n",
      "Epoch 184/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8093 - loss: 0.4414 - val_accuracy: 0.7668 - val_loss: 0.5089\n",
      "Epoch 185/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.8080 - loss: 0.4432 - val_accuracy: 0.7766 - val_loss: 0.4926\n",
      "Epoch 186/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.8048 - loss: 0.4461 - val_accuracy: 0.7668 - val_loss: 0.5134\n",
      "Epoch 187/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.8031 - loss: 0.4474 - val_accuracy: 0.7869 - val_loss: 0.4745\n",
      "Epoch 188/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.8058 - loss: 0.4444 - val_accuracy: 0.7720 - val_loss: 0.5041\n",
      "Epoch 189/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8062 - loss: 0.4449 - val_accuracy: 0.7712 - val_loss: 0.5003\n",
      "Epoch 190/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.8092 - loss: 0.4433 - val_accuracy: 0.7764 - val_loss: 0.4979\n",
      "Epoch 191/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.8023 - loss: 0.4482 - val_accuracy: 0.7766 - val_loss: 0.4957\n",
      "Epoch 192/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.8056 - loss: 0.4449 - val_accuracy: 0.7840 - val_loss: 0.4801\n",
      "Epoch 193/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8064 - loss: 0.4451 - val_accuracy: 0.7784 - val_loss: 0.4977\n",
      "Epoch 194/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.8049 - loss: 0.4472 - val_accuracy: 0.7730 - val_loss: 0.4972\n",
      "Epoch 195/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.8082 - loss: 0.4427 - val_accuracy: 0.7700 - val_loss: 0.5071\n",
      "Epoch 196/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.8035 - loss: 0.4493 - val_accuracy: 0.7677 - val_loss: 0.5141\n",
      "Epoch 197/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.8034 - loss: 0.4508 - val_accuracy: 0.7692 - val_loss: 0.5024\n",
      "Epoch 198/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.8026 - loss: 0.4446 - val_accuracy: 0.7634 - val_loss: 0.5177\n",
      "Epoch 199/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.8059 - loss: 0.4449 - val_accuracy: 0.7619 - val_loss: 0.5234\n",
      "Epoch 200/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8070 - loss: 0.4422 - val_accuracy: 0.7692 - val_loss: 0.5123\n",
      "Epoch 201/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.8048 - loss: 0.4459 - val_accuracy: 0.7630 - val_loss: 0.5248\n",
      "Epoch 202/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 0.8066 - loss: 0.4430 - val_accuracy: 0.7748 - val_loss: 0.4980\n",
      "Epoch 203/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.8076 - loss: 0.4459 - val_accuracy: 0.7784 - val_loss: 0.4929\n",
      "Epoch 204/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.8107 - loss: 0.4409 - val_accuracy: 0.7782 - val_loss: 0.4901\n",
      "Epoch 205/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.8075 - loss: 0.4428 - val_accuracy: 0.7720 - val_loss: 0.5064\n",
      "Epoch 206/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8058 - loss: 0.4433 - val_accuracy: 0.7773 - val_loss: 0.4933\n",
      "Epoch 207/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.8103 - loss: 0.4436 - val_accuracy: 0.7709 - val_loss: 0.5060\n",
      "Epoch 208/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.8097 - loss: 0.4365 - val_accuracy: 0.7869 - val_loss: 0.4792\n",
      "Epoch 209/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.8068 - loss: 0.4418 - val_accuracy: 0.7708 - val_loss: 0.5087\n",
      "Epoch 210/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.8062 - loss: 0.4479 - val_accuracy: 0.7784 - val_loss: 0.4891\n",
      "Epoch 211/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.8061 - loss: 0.4478 - val_accuracy: 0.7687 - val_loss: 0.5032\n",
      "Epoch 212/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.8068 - loss: 0.4425 - val_accuracy: 0.7707 - val_loss: 0.5040\n",
      "Epoch 213/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.8078 - loss: 0.4401 - val_accuracy: 0.7723 - val_loss: 0.5113\n",
      "Epoch 214/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.8046 - loss: 0.4429 - val_accuracy: 0.7830 - val_loss: 0.4882\n",
      "Epoch 215/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.8060 - loss: 0.4404 - val_accuracy: 0.7827 - val_loss: 0.4860\n",
      "Epoch 216/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.8054 - loss: 0.4481 - val_accuracy: 0.7772 - val_loss: 0.4992\n",
      "Epoch 217/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.8066 - loss: 0.4442 - val_accuracy: 0.7775 - val_loss: 0.4948\n",
      "Epoch 218/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.8058 - loss: 0.4428 - val_accuracy: 0.7768 - val_loss: 0.5009\n",
      "Epoch 219/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.8078 - loss: 0.4423 - val_accuracy: 0.7826 - val_loss: 0.4785\n",
      "Epoch 220/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.8095 - loss: 0.4377 - val_accuracy: 0.7711 - val_loss: 0.5111\n",
      "Epoch 221/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.8098 - loss: 0.4428 - val_accuracy: 0.7726 - val_loss: 0.5031\n",
      "Epoch 222/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.8078 - loss: 0.4386 - val_accuracy: 0.7817 - val_loss: 0.4873\n",
      "Epoch 223/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.8061 - loss: 0.4450 - val_accuracy: 0.7738 - val_loss: 0.5041\n",
      "Epoch 224/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.8067 - loss: 0.4423 - val_accuracy: 0.7740 - val_loss: 0.5114\n",
      "Epoch 225/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - accuracy: 0.8094 - loss: 0.4368 - val_accuracy: 0.7613 - val_loss: 0.5286\n",
      "Epoch 226/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.8037 - loss: 0.4505 - val_accuracy: 0.7755 - val_loss: 0.4902\n",
      "Epoch 227/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.8059 - loss: 0.4412 - val_accuracy: 0.7818 - val_loss: 0.4833\n",
      "Epoch 228/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - accuracy: 0.8084 - loss: 0.4402 - val_accuracy: 0.7877 - val_loss: 0.4765\n",
      "Epoch 229/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.8049 - loss: 0.4451 - val_accuracy: 0.7806 - val_loss: 0.4897\n",
      "Epoch 230/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.8097 - loss: 0.4396 - val_accuracy: 0.7815 - val_loss: 0.4873\n",
      "Epoch 231/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.8103 - loss: 0.4334 - val_accuracy: 0.7824 - val_loss: 0.4851\n",
      "Epoch 232/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.8110 - loss: 0.4392 - val_accuracy: 0.7744 - val_loss: 0.4957\n",
      "Epoch 233/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.8102 - loss: 0.4387 - val_accuracy: 0.7817 - val_loss: 0.4858\n",
      "Epoch 234/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.8072 - loss: 0.4427 - val_accuracy: 0.7718 - val_loss: 0.5057\n",
      "Epoch 235/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.8100 - loss: 0.4404 - val_accuracy: 0.7865 - val_loss: 0.4745\n",
      "Epoch 236/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.8080 - loss: 0.4456 - val_accuracy: 0.7754 - val_loss: 0.4948\n",
      "Epoch 237/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.8088 - loss: 0.4384 - val_accuracy: 0.7804 - val_loss: 0.4891\n",
      "Epoch 238/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.8088 - loss: 0.4416 - val_accuracy: 0.7672 - val_loss: 0.5143\n",
      "Epoch 239/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.8071 - loss: 0.4422 - val_accuracy: 0.7793 - val_loss: 0.4951\n",
      "Epoch 240/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.8122 - loss: 0.4374 - val_accuracy: 0.7750 - val_loss: 0.5012\n",
      "Epoch 241/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.8101 - loss: 0.4362 - val_accuracy: 0.7803 - val_loss: 0.4890\n",
      "Epoch 242/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - accuracy: 0.8077 - loss: 0.4425 - val_accuracy: 0.7739 - val_loss: 0.4969\n",
      "Epoch 243/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.8069 - loss: 0.4443 - val_accuracy: 0.7667 - val_loss: 0.5187\n",
      "Epoch 244/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.8090 - loss: 0.4419 - val_accuracy: 0.7839 - val_loss: 0.4826\n",
      "Epoch 245/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.8052 - loss: 0.4419 - val_accuracy: 0.7719 - val_loss: 0.5048\n",
      "Epoch 246/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.8095 - loss: 0.4393 - val_accuracy: 0.7800 - val_loss: 0.4873\n",
      "Epoch 247/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8076 - loss: 0.4357 - val_accuracy: 0.7733 - val_loss: 0.5088\n",
      "Epoch 248/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.8066 - loss: 0.4429 - val_accuracy: 0.7628 - val_loss: 0.5235\n",
      "Epoch 249/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.8070 - loss: 0.4449 - val_accuracy: 0.7839 - val_loss: 0.4827\n",
      "Epoch 250/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.8087 - loss: 0.4417 - val_accuracy: 0.7816 - val_loss: 0.4815\n",
      "Epoch 251/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.8051 - loss: 0.4487 - val_accuracy: 0.7848 - val_loss: 0.4817\n",
      "Epoch 252/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.8095 - loss: 0.4381 - val_accuracy: 0.7748 - val_loss: 0.4988\n",
      "Epoch 253/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.8081 - loss: 0.4413 - val_accuracy: 0.7851 - val_loss: 0.4805\n",
      "Epoch 254/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.8088 - loss: 0.4429 - val_accuracy: 0.7745 - val_loss: 0.5001\n",
      "Epoch 255/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.8073 - loss: 0.4373 - val_accuracy: 0.7783 - val_loss: 0.4859\n",
      "Epoch 256/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.8103 - loss: 0.4376 - val_accuracy: 0.7755 - val_loss: 0.4938\n",
      "Epoch 257/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8114 - loss: 0.4387 - val_accuracy: 0.7594 - val_loss: 0.5274\n",
      "Epoch 258/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.8087 - loss: 0.4400 - val_accuracy: 0.7655 - val_loss: 0.5115\n",
      "Epoch 259/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.8088 - loss: 0.4411 - val_accuracy: 0.7654 - val_loss: 0.5133\n",
      "Epoch 260/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.8059 - loss: 0.4436 - val_accuracy: 0.7773 - val_loss: 0.4936\n",
      "Epoch 261/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.8093 - loss: 0.4397 - val_accuracy: 0.7747 - val_loss: 0.4979\n",
      "Epoch 262/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.8059 - loss: 0.4442 - val_accuracy: 0.7766 - val_loss: 0.4995\n",
      "Epoch 263/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.8106 - loss: 0.4389 - val_accuracy: 0.7779 - val_loss: 0.4912\n",
      "Epoch 264/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.8097 - loss: 0.4349 - val_accuracy: 0.7685 - val_loss: 0.5131\n",
      "Epoch 265/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.8070 - loss: 0.4404 - val_accuracy: 0.7796 - val_loss: 0.4852\n",
      "Epoch 266/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - accuracy: 0.8116 - loss: 0.4346 - val_accuracy: 0.7796 - val_loss: 0.4901\n",
      "Epoch 267/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.8086 - loss: 0.4377 - val_accuracy: 0.7692 - val_loss: 0.5101\n",
      "Epoch 268/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.8050 - loss: 0.4413 - val_accuracy: 0.7744 - val_loss: 0.4999\n",
      "Epoch 269/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.8080 - loss: 0.4392 - val_accuracy: 0.7769 - val_loss: 0.4982\n",
      "Epoch 270/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8102 - loss: 0.4394 - val_accuracy: 0.7846 - val_loss: 0.4848\n",
      "Epoch 271/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.8043 - loss: 0.4442 - val_accuracy: 0.7766 - val_loss: 0.4919\n",
      "Epoch 272/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.8116 - loss: 0.4338 - val_accuracy: 0.7686 - val_loss: 0.5166\n",
      "Epoch 273/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.8084 - loss: 0.4391 - val_accuracy: 0.7715 - val_loss: 0.5052\n",
      "Epoch 274/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.8075 - loss: 0.4414 - val_accuracy: 0.7859 - val_loss: 0.4752\n",
      "Epoch 275/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.8131 - loss: 0.4325 - val_accuracy: 0.7644 - val_loss: 0.5201\n",
      "Epoch 276/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.8078 - loss: 0.4377 - val_accuracy: 0.7839 - val_loss: 0.4828\n",
      "Epoch 277/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.8102 - loss: 0.4343 - val_accuracy: 0.7697 - val_loss: 0.5072\n",
      "Epoch 278/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.8065 - loss: 0.4417 - val_accuracy: 0.7733 - val_loss: 0.5039\n",
      "Epoch 279/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.8070 - loss: 0.4382 - val_accuracy: 0.7704 - val_loss: 0.5040\n",
      "Epoch 280/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.8075 - loss: 0.4454 - val_accuracy: 0.7737 - val_loss: 0.4994\n",
      "Epoch 281/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - accuracy: 0.8102 - loss: 0.4332 - val_accuracy: 0.7782 - val_loss: 0.4954\n",
      "Epoch 282/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.8117 - loss: 0.4379 - val_accuracy: 0.7785 - val_loss: 0.4940\n",
      "Epoch 283/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.8100 - loss: 0.4386 - val_accuracy: 0.7731 - val_loss: 0.5019\n",
      "Epoch 284/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.8113 - loss: 0.4363 - val_accuracy: 0.7700 - val_loss: 0.5088\n",
      "Epoch 285/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.8090 - loss: 0.4393 - val_accuracy: 0.7815 - val_loss: 0.4824\n",
      "Epoch 286/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.8110 - loss: 0.4356 - val_accuracy: 0.7629 - val_loss: 0.5198\n",
      "Epoch 287/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.8100 - loss: 0.4363 - val_accuracy: 0.7778 - val_loss: 0.4977\n",
      "Epoch 288/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.8113 - loss: 0.4407 - val_accuracy: 0.7759 - val_loss: 0.4996\n",
      "Epoch 289/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.8080 - loss: 0.4430 - val_accuracy: 0.7676 - val_loss: 0.5093\n",
      "Epoch 290/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.8097 - loss: 0.4378 - val_accuracy: 0.7664 - val_loss: 0.5112\n",
      "Epoch 291/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.8074 - loss: 0.4402 - val_accuracy: 0.7900 - val_loss: 0.4764\n",
      "Epoch 292/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.8086 - loss: 0.4382 - val_accuracy: 0.7764 - val_loss: 0.4975\n",
      "Epoch 293/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.8078 - loss: 0.4394 - val_accuracy: 0.7683 - val_loss: 0.5142\n",
      "Epoch 294/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.8121 - loss: 0.4376 - val_accuracy: 0.7762 - val_loss: 0.5011\n",
      "Epoch 295/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.8110 - loss: 0.4393 - val_accuracy: 0.7762 - val_loss: 0.4984\n",
      "Epoch 296/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.8120 - loss: 0.4366 - val_accuracy: 0.7658 - val_loss: 0.5212\n",
      "Epoch 297/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.8065 - loss: 0.4361 - val_accuracy: 0.7674 - val_loss: 0.5182\n",
      "Epoch 298/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.8103 - loss: 0.4368 - val_accuracy: 0.7828 - val_loss: 0.4884\n",
      "Epoch 299/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.8084 - loss: 0.4364 - val_accuracy: 0.7724 - val_loss: 0.4980\n",
      "Epoch 300/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.8112 - loss: 0.4393 - val_accuracy: 0.7715 - val_loss: 0.5097\n",
      "Epoch 301/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.8099 - loss: 0.4374 - val_accuracy: 0.7879 - val_loss: 0.4782\n",
      "Epoch 302/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.8085 - loss: 0.4368 - val_accuracy: 0.7750 - val_loss: 0.5011\n",
      "Epoch 303/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.8055 - loss: 0.4335 - val_accuracy: 0.7854 - val_loss: 0.4813\n",
      "Epoch 304/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.8101 - loss: 0.4360 - val_accuracy: 0.7738 - val_loss: 0.5071\n",
      "Epoch 305/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.8126 - loss: 0.4346 - val_accuracy: 0.7889 - val_loss: 0.4747\n",
      "Epoch 306/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.8094 - loss: 0.4354 - val_accuracy: 0.7749 - val_loss: 0.5038\n",
      "Epoch 307/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.8093 - loss: 0.4398 - val_accuracy: 0.7909 - val_loss: 0.4733\n",
      "Epoch 308/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.8114 - loss: 0.4376 - val_accuracy: 0.7820 - val_loss: 0.4860\n",
      "Epoch 309/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.8110 - loss: 0.4333 - val_accuracy: 0.7687 - val_loss: 0.5121\n",
      "Epoch 310/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.8116 - loss: 0.4343 - val_accuracy: 0.7735 - val_loss: 0.5089\n",
      "Epoch 311/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.8126 - loss: 0.4305 - val_accuracy: 0.7745 - val_loss: 0.5001\n",
      "Epoch 312/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.8094 - loss: 0.4393 - val_accuracy: 0.7818 - val_loss: 0.4863\n",
      "Epoch 313/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.8139 - loss: 0.4307 - val_accuracy: 0.7831 - val_loss: 0.4843\n",
      "Epoch 314/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.8128 - loss: 0.4314 - val_accuracy: 0.7848 - val_loss: 0.4810\n",
      "Epoch 315/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.8122 - loss: 0.4340 - val_accuracy: 0.7774 - val_loss: 0.4916\n",
      "Epoch 316/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.8149 - loss: 0.4314 - val_accuracy: 0.7714 - val_loss: 0.5100\n",
      "Epoch 317/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.8164 - loss: 0.4282 - val_accuracy: 0.7767 - val_loss: 0.4994\n",
      "Epoch 318/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686us/step - accuracy: 0.8120 - loss: 0.4364 - val_accuracy: 0.7745 - val_loss: 0.5043\n",
      "Epoch 319/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.8139 - loss: 0.4298 - val_accuracy: 0.7851 - val_loss: 0.4865\n",
      "Epoch 320/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.8110 - loss: 0.4289 - val_accuracy: 0.7775 - val_loss: 0.4959\n",
      "Epoch 321/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.8098 - loss: 0.4372 - val_accuracy: 0.7797 - val_loss: 0.4914\n",
      "Epoch 322/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 0.8089 - loss: 0.4334 - val_accuracy: 0.7735 - val_loss: 0.5056\n",
      "Epoch 323/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.8151 - loss: 0.4291 - val_accuracy: 0.7762 - val_loss: 0.4993\n",
      "Epoch 324/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 0.8136 - loss: 0.4304 - val_accuracy: 0.7782 - val_loss: 0.5014\n",
      "Epoch 325/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.8166 - loss: 0.4323 - val_accuracy: 0.7814 - val_loss: 0.4944\n",
      "Epoch 326/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.8099 - loss: 0.4350 - val_accuracy: 0.7751 - val_loss: 0.4970\n",
      "Epoch 327/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 0.8140 - loss: 0.4290 - val_accuracy: 0.7783 - val_loss: 0.4944\n",
      "Epoch 328/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.8084 - loss: 0.4361 - val_accuracy: 0.7820 - val_loss: 0.4874\n",
      "Epoch 329/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8134 - loss: 0.4302 - val_accuracy: 0.7810 - val_loss: 0.4911\n",
      "Epoch 330/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.8142 - loss: 0.4319 - val_accuracy: 0.7764 - val_loss: 0.5016\n",
      "Epoch 331/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.8128 - loss: 0.4290 - val_accuracy: 0.7750 - val_loss: 0.5008\n",
      "Epoch 332/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - accuracy: 0.8075 - loss: 0.4384 - val_accuracy: 0.7780 - val_loss: 0.4940\n",
      "Epoch 333/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.8102 - loss: 0.4317 - val_accuracy: 0.7848 - val_loss: 0.4820\n",
      "Epoch 334/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.8120 - loss: 0.4336 - val_accuracy: 0.7864 - val_loss: 0.4804\n",
      "Epoch 335/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - accuracy: 0.8113 - loss: 0.4311 - val_accuracy: 0.7810 - val_loss: 0.4880\n",
      "Epoch 336/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.8110 - loss: 0.4321 - val_accuracy: 0.7846 - val_loss: 0.4859\n",
      "Epoch 337/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.8145 - loss: 0.4313 - val_accuracy: 0.7744 - val_loss: 0.4987\n",
      "Epoch 338/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.8134 - loss: 0.4320 - val_accuracy: 0.7796 - val_loss: 0.4954\n",
      "Epoch 339/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.8142 - loss: 0.4333 - val_accuracy: 0.7739 - val_loss: 0.5011\n",
      "Epoch 340/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.8154 - loss: 0.4304 - val_accuracy: 0.7774 - val_loss: 0.4933\n",
      "Epoch 341/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.8128 - loss: 0.4320 - val_accuracy: 0.7869 - val_loss: 0.4821\n",
      "Epoch 342/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.8139 - loss: 0.4257 - val_accuracy: 0.7811 - val_loss: 0.4940\n",
      "Epoch 343/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.8094 - loss: 0.4392 - val_accuracy: 0.7752 - val_loss: 0.4961\n",
      "Epoch 344/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.8128 - loss: 0.4330 - val_accuracy: 0.7787 - val_loss: 0.5022\n",
      "Epoch 345/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.8072 - loss: 0.4343 - val_accuracy: 0.7733 - val_loss: 0.5078\n",
      "Epoch 346/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.8134 - loss: 0.4312 - val_accuracy: 0.7858 - val_loss: 0.4843\n",
      "Epoch 347/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.8122 - loss: 0.4304 - val_accuracy: 0.7810 - val_loss: 0.4932\n",
      "Epoch 348/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.8124 - loss: 0.4270 - val_accuracy: 0.7738 - val_loss: 0.4992\n",
      "Epoch 349/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8105 - loss: 0.4341 - val_accuracy: 0.7827 - val_loss: 0.4896\n",
      "Epoch 350/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.8148 - loss: 0.4297 - val_accuracy: 0.7788 - val_loss: 0.4945\n",
      "Epoch 351/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - accuracy: 0.8102 - loss: 0.4291 - val_accuracy: 0.7805 - val_loss: 0.4888\n",
      "Epoch 352/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.8156 - loss: 0.4247 - val_accuracy: 0.7701 - val_loss: 0.5087\n",
      "Epoch 353/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.8153 - loss: 0.4276 - val_accuracy: 0.7764 - val_loss: 0.4992\n",
      "Epoch 354/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.8108 - loss: 0.4379 - val_accuracy: 0.7792 - val_loss: 0.5028\n",
      "Epoch 355/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - accuracy: 0.8186 - loss: 0.4259 - val_accuracy: 0.7713 - val_loss: 0.5080\n",
      "Epoch 356/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.8143 - loss: 0.4295 - val_accuracy: 0.7828 - val_loss: 0.4924\n",
      "Epoch 357/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.8134 - loss: 0.4301 - val_accuracy: 0.7830 - val_loss: 0.4833\n",
      "Epoch 358/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.8111 - loss: 0.4308 - val_accuracy: 0.7761 - val_loss: 0.5006\n",
      "Epoch 359/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8110 - loss: 0.4349 - val_accuracy: 0.7771 - val_loss: 0.4906\n",
      "Epoch 360/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.8130 - loss: 0.4325 - val_accuracy: 0.7715 - val_loss: 0.5093\n",
      "Epoch 361/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.8138 - loss: 0.4314 - val_accuracy: 0.7869 - val_loss: 0.4861\n",
      "Epoch 362/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.8078 - loss: 0.4348 - val_accuracy: 0.7882 - val_loss: 0.4857\n",
      "Epoch 363/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.8122 - loss: 0.4299 - val_accuracy: 0.7794 - val_loss: 0.4991\n",
      "Epoch 364/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8136 - loss: 0.4278 - val_accuracy: 0.7779 - val_loss: 0.4990\n",
      "Epoch 365/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.8136 - loss: 0.4299 - val_accuracy: 0.7759 - val_loss: 0.5004\n",
      "Epoch 366/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8143 - loss: 0.4252 - val_accuracy: 0.7761 - val_loss: 0.5057\n",
      "Epoch 367/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8137 - loss: 0.4281 - val_accuracy: 0.7711 - val_loss: 0.5146\n",
      "Epoch 368/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - accuracy: 0.8138 - loss: 0.4341 - val_accuracy: 0.7865 - val_loss: 0.4797\n",
      "Epoch 369/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 0.8083 - loss: 0.4343 - val_accuracy: 0.7726 - val_loss: 0.5049\n",
      "Epoch 370/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.8124 - loss: 0.4334 - val_accuracy: 0.7783 - val_loss: 0.4973\n",
      "Epoch 371/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 0.8114 - loss: 0.4333 - val_accuracy: 0.7649 - val_loss: 0.5163\n",
      "Epoch 372/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.8102 - loss: 0.4391 - val_accuracy: 0.7791 - val_loss: 0.4864\n",
      "Epoch 373/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - accuracy: 0.8103 - loss: 0.4378 - val_accuracy: 0.7755 - val_loss: 0.4998\n",
      "Epoch 374/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.8147 - loss: 0.4284 - val_accuracy: 0.7802 - val_loss: 0.4973\n",
      "Epoch 375/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.8098 - loss: 0.4340 - val_accuracy: 0.7828 - val_loss: 0.4937\n",
      "Epoch 376/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.8170 - loss: 0.4294 - val_accuracy: 0.7850 - val_loss: 0.4877\n",
      "Epoch 377/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.8177 - loss: 0.4255 - val_accuracy: 0.7796 - val_loss: 0.5038\n",
      "Epoch 378/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.8132 - loss: 0.4344 - val_accuracy: 0.7915 - val_loss: 0.4698\n",
      "Epoch 379/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.8142 - loss: 0.4276 - val_accuracy: 0.7870 - val_loss: 0.4799\n",
      "Epoch 380/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - accuracy: 0.8163 - loss: 0.4254 - val_accuracy: 0.7832 - val_loss: 0.4922\n",
      "Epoch 381/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - accuracy: 0.8134 - loss: 0.4265 - val_accuracy: 0.7757 - val_loss: 0.5095\n",
      "Epoch 382/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.8136 - loss: 0.4330 - val_accuracy: 0.7755 - val_loss: 0.5025\n",
      "Epoch 383/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8147 - loss: 0.4273 - val_accuracy: 0.7810 - val_loss: 0.4944\n",
      "Epoch 384/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999us/step - accuracy: 0.8101 - loss: 0.4368 - val_accuracy: 0.7712 - val_loss: 0.5055\n",
      "Epoch 385/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.8125 - loss: 0.4332 - val_accuracy: 0.7844 - val_loss: 0.4873\n",
      "Epoch 386/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 0.8133 - loss: 0.4311 - val_accuracy: 0.7818 - val_loss: 0.4881\n",
      "Epoch 387/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.8103 - loss: 0.4320 - val_accuracy: 0.7818 - val_loss: 0.4923\n",
      "Epoch 388/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.8114 - loss: 0.4344 - val_accuracy: 0.7854 - val_loss: 0.4867\n",
      "Epoch 389/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.8157 - loss: 0.4237 - val_accuracy: 0.7839 - val_loss: 0.4849\n",
      "Epoch 390/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.8129 - loss: 0.4284 - val_accuracy: 0.7793 - val_loss: 0.4976\n",
      "Epoch 391/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.8131 - loss: 0.4292 - val_accuracy: 0.7832 - val_loss: 0.4847\n",
      "Epoch 392/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.8161 - loss: 0.4246 - val_accuracy: 0.7866 - val_loss: 0.4813\n",
      "Epoch 393/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.8111 - loss: 0.4328 - val_accuracy: 0.7822 - val_loss: 0.4882\n",
      "Epoch 394/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.8146 - loss: 0.4300 - val_accuracy: 0.7779 - val_loss: 0.4943\n",
      "Epoch 395/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.8143 - loss: 0.4304 - val_accuracy: 0.7745 - val_loss: 0.5032\n",
      "Epoch 396/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.8113 - loss: 0.4334 - val_accuracy: 0.7930 - val_loss: 0.4726\n",
      "Epoch 397/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.8121 - loss: 0.4335 - val_accuracy: 0.7851 - val_loss: 0.4820\n",
      "Epoch 398/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.8180 - loss: 0.4262 - val_accuracy: 0.7816 - val_loss: 0.4932\n",
      "Epoch 399/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.8175 - loss: 0.4246 - val_accuracy: 0.7762 - val_loss: 0.4992\n",
      "Epoch 400/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8214 - loss: 0.4164 - val_accuracy: 0.7790 - val_loss: 0.4974\n",
      "Epoch 401/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.8151 - loss: 0.4256 - val_accuracy: 0.7800 - val_loss: 0.5002\n",
      "Epoch 402/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8179 - loss: 0.4212 - val_accuracy: 0.7739 - val_loss: 0.5091\n",
      "Epoch 403/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8165 - loss: 0.4265 - val_accuracy: 0.7856 - val_loss: 0.4793\n",
      "Epoch 404/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.8149 - loss: 0.4257 - val_accuracy: 0.7756 - val_loss: 0.4977\n",
      "Epoch 405/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8128 - loss: 0.4319 - val_accuracy: 0.7900 - val_loss: 0.4788\n",
      "Epoch 406/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8170 - loss: 0.4257 - val_accuracy: 0.7812 - val_loss: 0.4909\n",
      "Epoch 407/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.8127 - loss: 0.4310 - val_accuracy: 0.7795 - val_loss: 0.4964\n",
      "Epoch 408/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8138 - loss: 0.4297 - val_accuracy: 0.7778 - val_loss: 0.5032\n",
      "Epoch 409/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.8132 - loss: 0.4297 - val_accuracy: 0.7923 - val_loss: 0.4786\n",
      "Epoch 410/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8176 - loss: 0.4267 - val_accuracy: 0.7792 - val_loss: 0.4974\n",
      "Epoch 411/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.8138 - loss: 0.4279 - val_accuracy: 0.7819 - val_loss: 0.4907\n",
      "Epoch 412/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8178 - loss: 0.4209 - val_accuracy: 0.7884 - val_loss: 0.4810\n",
      "Epoch 413/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8153 - loss: 0.4271 - val_accuracy: 0.7806 - val_loss: 0.4977\n",
      "Epoch 414/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.8142 - loss: 0.4322 - val_accuracy: 0.7927 - val_loss: 0.4722\n",
      "Epoch 415/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.8154 - loss: 0.4256 - val_accuracy: 0.7787 - val_loss: 0.5039\n",
      "Epoch 416/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.8117 - loss: 0.4305 - val_accuracy: 0.7834 - val_loss: 0.4912\n",
      "Epoch 417/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.8147 - loss: 0.4288 - val_accuracy: 0.7706 - val_loss: 0.5149\n",
      "Epoch 418/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.8151 - loss: 0.4224 - val_accuracy: 0.7814 - val_loss: 0.4863\n",
      "Epoch 419/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.8149 - loss: 0.4293 - val_accuracy: 0.7863 - val_loss: 0.4860\n",
      "Epoch 420/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.8163 - loss: 0.4261 - val_accuracy: 0.7815 - val_loss: 0.4933\n",
      "Epoch 421/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8148 - loss: 0.4312 - val_accuracy: 0.7933 - val_loss: 0.4713\n",
      "Epoch 422/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - accuracy: 0.8169 - loss: 0.4288 - val_accuracy: 0.7845 - val_loss: 0.4887\n",
      "Epoch 423/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.8180 - loss: 0.4232 - val_accuracy: 0.7823 - val_loss: 0.4900\n",
      "Epoch 424/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.8137 - loss: 0.4314 - val_accuracy: 0.7879 - val_loss: 0.4818\n",
      "Epoch 425/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.8150 - loss: 0.4253 - val_accuracy: 0.7899 - val_loss: 0.4739\n",
      "Epoch 426/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.8180 - loss: 0.4250 - val_accuracy: 0.7921 - val_loss: 0.4711\n",
      "Epoch 427/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.8162 - loss: 0.4234 - val_accuracy: 0.7926 - val_loss: 0.4746\n",
      "Epoch 428/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.8140 - loss: 0.4275 - val_accuracy: 0.7864 - val_loss: 0.4822\n",
      "Epoch 429/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.8177 - loss: 0.4241 - val_accuracy: 0.7914 - val_loss: 0.4781\n",
      "Epoch 430/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.8125 - loss: 0.4317 - val_accuracy: 0.7871 - val_loss: 0.4778\n",
      "Epoch 431/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.8155 - loss: 0.4284 - val_accuracy: 0.7918 - val_loss: 0.4710\n",
      "Epoch 432/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.8175 - loss: 0.4267 - val_accuracy: 0.7840 - val_loss: 0.4902\n",
      "Epoch 433/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8166 - loss: 0.4233 - val_accuracy: 0.7882 - val_loss: 0.4816\n",
      "Epoch 434/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.8146 - loss: 0.4277 - val_accuracy: 0.7956 - val_loss: 0.4627\n",
      "Epoch 435/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.8126 - loss: 0.4251 - val_accuracy: 0.7914 - val_loss: 0.4729\n",
      "Epoch 436/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.8160 - loss: 0.4266 - val_accuracy: 0.7866 - val_loss: 0.4835\n",
      "Epoch 437/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.8135 - loss: 0.4312 - val_accuracy: 0.7939 - val_loss: 0.4703\n",
      "Epoch 438/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8107 - loss: 0.4283 - val_accuracy: 0.7916 - val_loss: 0.4749\n",
      "Epoch 439/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8154 - loss: 0.4266 - val_accuracy: 0.7883 - val_loss: 0.4787\n",
      "Epoch 440/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.8156 - loss: 0.4281 - val_accuracy: 0.7883 - val_loss: 0.4832\n",
      "Epoch 441/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.8182 - loss: 0.4205 - val_accuracy: 0.7919 - val_loss: 0.4732\n",
      "Epoch 442/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - accuracy: 0.8170 - loss: 0.4254 - val_accuracy: 0.7913 - val_loss: 0.4753\n",
      "Epoch 443/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.8142 - loss: 0.4259 - val_accuracy: 0.7939 - val_loss: 0.4744\n",
      "Epoch 444/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.8177 - loss: 0.4244 - val_accuracy: 0.7944 - val_loss: 0.4757\n",
      "Epoch 445/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 0.8179 - loss: 0.4172 - val_accuracy: 0.7872 - val_loss: 0.4890\n",
      "Epoch 446/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.8157 - loss: 0.4254 - val_accuracy: 0.7859 - val_loss: 0.4813\n",
      "Epoch 447/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.8186 - loss: 0.4212 - val_accuracy: 0.7907 - val_loss: 0.4769\n",
      "Epoch 448/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.8182 - loss: 0.4206 - val_accuracy: 0.7871 - val_loss: 0.4806\n",
      "Epoch 449/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.8153 - loss: 0.4297 - val_accuracy: 0.7872 - val_loss: 0.4866\n",
      "Epoch 450/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8166 - loss: 0.4289 - val_accuracy: 0.7877 - val_loss: 0.4838\n",
      "Epoch 451/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.8133 - loss: 0.4248 - val_accuracy: 0.7893 - val_loss: 0.4779\n",
      "Epoch 452/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.8166 - loss: 0.4256 - val_accuracy: 0.7937 - val_loss: 0.4672\n",
      "Epoch 453/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.8206 - loss: 0.4203 - val_accuracy: 0.7854 - val_loss: 0.4890\n",
      "Epoch 454/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.8187 - loss: 0.4177 - val_accuracy: 0.7912 - val_loss: 0.4831\n",
      "Epoch 455/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.8228 - loss: 0.4192 - val_accuracy: 0.7834 - val_loss: 0.4936\n",
      "Epoch 456/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.8121 - loss: 0.4340 - val_accuracy: 0.7918 - val_loss: 0.4720\n",
      "Epoch 457/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.8191 - loss: 0.4235 - val_accuracy: 0.7842 - val_loss: 0.4911\n",
      "Epoch 458/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - accuracy: 0.8162 - loss: 0.4277 - val_accuracy: 0.7808 - val_loss: 0.4983\n",
      "Epoch 459/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8163 - loss: 0.4248 - val_accuracy: 0.7888 - val_loss: 0.4831\n",
      "Epoch 460/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8174 - loss: 0.4255 - val_accuracy: 0.7963 - val_loss: 0.4655\n",
      "Epoch 461/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8173 - loss: 0.4194 - val_accuracy: 0.7846 - val_loss: 0.4854\n",
      "Epoch 462/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - accuracy: 0.8159 - loss: 0.4226 - val_accuracy: 0.7932 - val_loss: 0.4696\n",
      "Epoch 463/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 0.8153 - loss: 0.4267 - val_accuracy: 0.7945 - val_loss: 0.4684\n",
      "Epoch 464/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.8213 - loss: 0.4174 - val_accuracy: 0.7919 - val_loss: 0.4728\n",
      "Epoch 465/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.8177 - loss: 0.4214 - val_accuracy: 0.7871 - val_loss: 0.4855\n",
      "Epoch 466/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.8156 - loss: 0.4283 - val_accuracy: 0.7945 - val_loss: 0.4723\n",
      "Epoch 467/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8135 - loss: 0.4306 - val_accuracy: 0.7860 - val_loss: 0.4868\n",
      "Epoch 468/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.8176 - loss: 0.4251 - val_accuracy: 0.7916 - val_loss: 0.4724\n",
      "Epoch 469/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.8178 - loss: 0.4278 - val_accuracy: 0.7918 - val_loss: 0.4751\n",
      "Epoch 470/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.8210 - loss: 0.4208 - val_accuracy: 0.7875 - val_loss: 0.4823\n",
      "Epoch 471/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.8172 - loss: 0.4184 - val_accuracy: 0.7871 - val_loss: 0.4821\n",
      "Epoch 472/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8163 - loss: 0.4252 - val_accuracy: 0.7903 - val_loss: 0.4752\n",
      "Epoch 473/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.8135 - loss: 0.4300 - val_accuracy: 0.7850 - val_loss: 0.4902\n",
      "Epoch 474/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.8121 - loss: 0.4263 - val_accuracy: 0.7840 - val_loss: 0.4909\n",
      "Epoch 475/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.8203 - loss: 0.4259 - val_accuracy: 0.7819 - val_loss: 0.4947\n",
      "Epoch 476/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.8219 - loss: 0.4163 - val_accuracy: 0.7888 - val_loss: 0.4864\n",
      "Epoch 477/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8182 - loss: 0.4237 - val_accuracy: 0.7857 - val_loss: 0.4877\n",
      "Epoch 478/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.8155 - loss: 0.4234 - val_accuracy: 0.7891 - val_loss: 0.4802\n",
      "Epoch 479/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.8174 - loss: 0.4235 - val_accuracy: 0.7924 - val_loss: 0.4782\n",
      "Epoch 480/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8185 - loss: 0.4186 - val_accuracy: 0.7935 - val_loss: 0.4756\n",
      "Epoch 481/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.8192 - loss: 0.4177 - val_accuracy: 0.7887 - val_loss: 0.4835\n",
      "Epoch 482/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8156 - loss: 0.4290 - val_accuracy: 0.7899 - val_loss: 0.4817\n",
      "Epoch 483/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.8159 - loss: 0.4251 - val_accuracy: 0.7971 - val_loss: 0.4649\n",
      "Epoch 484/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8178 - loss: 0.4222 - val_accuracy: 0.7892 - val_loss: 0.4802\n",
      "Epoch 485/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.8159 - loss: 0.4246 - val_accuracy: 0.7816 - val_loss: 0.4953\n",
      "Epoch 486/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 0.8161 - loss: 0.4285 - val_accuracy: 0.7887 - val_loss: 0.4777\n",
      "Epoch 487/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.8180 - loss: 0.4239 - val_accuracy: 0.7960 - val_loss: 0.4626\n",
      "Epoch 488/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8175 - loss: 0.4264 - val_accuracy: 0.7938 - val_loss: 0.4702\n",
      "Epoch 489/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.8144 - loss: 0.4243 - val_accuracy: 0.7883 - val_loss: 0.4815\n",
      "Epoch 490/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8160 - loss: 0.4223 - val_accuracy: 0.7903 - val_loss: 0.4790\n",
      "Epoch 491/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8201 - loss: 0.4184 - val_accuracy: 0.7935 - val_loss: 0.4754\n",
      "Epoch 492/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8170 - loss: 0.4242 - val_accuracy: 0.7911 - val_loss: 0.4782\n",
      "Epoch 493/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.8176 - loss: 0.4235 - val_accuracy: 0.7834 - val_loss: 0.4901\n",
      "Epoch 494/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8163 - loss: 0.4263 - val_accuracy: 0.7966 - val_loss: 0.4669\n",
      "Epoch 495/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.8167 - loss: 0.4211 - val_accuracy: 0.7931 - val_loss: 0.4782\n",
      "Epoch 496/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 0.8159 - loss: 0.4223 - val_accuracy: 0.7918 - val_loss: 0.4725\n",
      "Epoch 497/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.8208 - loss: 0.4188 - val_accuracy: 0.7957 - val_loss: 0.4654\n",
      "Epoch 498/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8179 - loss: 0.4179 - val_accuracy: 0.7851 - val_loss: 0.4870\n",
      "Epoch 499/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.8183 - loss: 0.4198 - val_accuracy: 0.7808 - val_loss: 0.4938\n",
      "Epoch 500/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8205 - loss: 0.4225 - val_accuracy: 0.7876 - val_loss: 0.4800\n",
      "Epoch 501/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.8165 - loss: 0.4219 - val_accuracy: 0.7870 - val_loss: 0.4829\n",
      "Epoch 502/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.8162 - loss: 0.4203 - val_accuracy: 0.7935 - val_loss: 0.4726\n",
      "Epoch 503/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.8188 - loss: 0.4223 - val_accuracy: 0.7863 - val_loss: 0.4865\n",
      "Epoch 504/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8155 - loss: 0.4220 - val_accuracy: 0.7781 - val_loss: 0.5022\n",
      "Epoch 505/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.8161 - loss: 0.4260 - val_accuracy: 0.7783 - val_loss: 0.5013\n",
      "Epoch 506/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.8157 - loss: 0.4267 - val_accuracy: 0.7906 - val_loss: 0.4751\n",
      "Epoch 507/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.8171 - loss: 0.4222 - val_accuracy: 0.7937 - val_loss: 0.4705\n",
      "Epoch 508/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.8149 - loss: 0.4212 - val_accuracy: 0.7978 - val_loss: 0.4635\n",
      "Epoch 509/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.8169 - loss: 0.4200 - val_accuracy: 0.7960 - val_loss: 0.4613\n",
      "Epoch 510/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.8147 - loss: 0.4262 - val_accuracy: 0.7944 - val_loss: 0.4678\n",
      "Epoch 511/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.8167 - loss: 0.4234 - val_accuracy: 0.7889 - val_loss: 0.4766\n",
      "Epoch 512/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.8150 - loss: 0.4287 - val_accuracy: 0.7942 - val_loss: 0.4686\n",
      "Epoch 513/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.8204 - loss: 0.4204 - val_accuracy: 0.7907 - val_loss: 0.4777\n",
      "Epoch 514/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.8194 - loss: 0.4186 - val_accuracy: 0.7888 - val_loss: 0.4781\n",
      "Epoch 515/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.8198 - loss: 0.4186 - val_accuracy: 0.7839 - val_loss: 0.4886\n",
      "Epoch 516/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644us/step - accuracy: 0.8167 - loss: 0.4245 - val_accuracy: 0.7867 - val_loss: 0.4836\n",
      "Epoch 517/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.8181 - loss: 0.4186 - val_accuracy: 0.7903 - val_loss: 0.4831\n",
      "Epoch 518/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.8163 - loss: 0.4274 - val_accuracy: 0.7990 - val_loss: 0.4570\n",
      "Epoch 519/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.8171 - loss: 0.4269 - val_accuracy: 0.7883 - val_loss: 0.4814\n",
      "Epoch 520/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.8145 - loss: 0.4281 - val_accuracy: 0.7967 - val_loss: 0.4645\n",
      "Epoch 521/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.8168 - loss: 0.4234 - val_accuracy: 0.7924 - val_loss: 0.4744\n",
      "Epoch 522/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.8169 - loss: 0.4226 - val_accuracy: 0.7876 - val_loss: 0.4900\n",
      "Epoch 523/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 0.8189 - loss: 0.4204 - val_accuracy: 0.7924 - val_loss: 0.4709\n",
      "Epoch 524/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.8186 - loss: 0.4279 - val_accuracy: 0.7892 - val_loss: 0.4837\n",
      "Epoch 525/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.8169 - loss: 0.4217 - val_accuracy: 0.7917 - val_loss: 0.4720\n",
      "Epoch 526/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.8180 - loss: 0.4187 - val_accuracy: 0.7880 - val_loss: 0.4767\n",
      "Epoch 527/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8142 - loss: 0.4245 - val_accuracy: 0.7904 - val_loss: 0.4764\n",
      "Epoch 528/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.8159 - loss: 0.4250 - val_accuracy: 0.7956 - val_loss: 0.4663\n",
      "Epoch 529/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8180 - loss: 0.4213 - val_accuracy: 0.7928 - val_loss: 0.4670\n",
      "Epoch 530/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.8177 - loss: 0.4208 - val_accuracy: 0.7943 - val_loss: 0.4699\n",
      "Epoch 531/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.8194 - loss: 0.4203 - val_accuracy: 0.7839 - val_loss: 0.4861\n",
      "Epoch 532/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.8162 - loss: 0.4208 - val_accuracy: 0.7854 - val_loss: 0.4833\n",
      "Epoch 533/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.8201 - loss: 0.4217 - val_accuracy: 0.7932 - val_loss: 0.4653\n",
      "Epoch 534/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - accuracy: 0.8178 - loss: 0.4196 - val_accuracy: 0.7864 - val_loss: 0.4840\n",
      "Epoch 535/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8188 - loss: 0.4223 - val_accuracy: 0.7923 - val_loss: 0.4676\n",
      "Epoch 536/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.8194 - loss: 0.4178 - val_accuracy: 0.7865 - val_loss: 0.4834\n",
      "Epoch 537/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8158 - loss: 0.4227 - val_accuracy: 0.7879 - val_loss: 0.4805\n",
      "Epoch 538/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.8154 - loss: 0.4239 - val_accuracy: 0.7889 - val_loss: 0.4827\n",
      "Epoch 539/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.8202 - loss: 0.4176 - val_accuracy: 0.7896 - val_loss: 0.4803\n",
      "Epoch 540/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.8208 - loss: 0.4156 - val_accuracy: 0.7913 - val_loss: 0.4777\n",
      "Epoch 541/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.8130 - loss: 0.4294 - val_accuracy: 0.7894 - val_loss: 0.4729\n",
      "Epoch 542/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.8165 - loss: 0.4228 - val_accuracy: 0.7829 - val_loss: 0.4926\n",
      "Epoch 543/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.8167 - loss: 0.4217 - val_accuracy: 0.7823 - val_loss: 0.4904\n",
      "Epoch 544/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.8184 - loss: 0.4248 - val_accuracy: 0.7853 - val_loss: 0.4867\n",
      "Epoch 545/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.8182 - loss: 0.4212 - val_accuracy: 0.7950 - val_loss: 0.4689\n",
      "Epoch 546/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.8163 - loss: 0.4248 - val_accuracy: 0.7928 - val_loss: 0.4753\n",
      "Epoch 547/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - accuracy: 0.8187 - loss: 0.4195 - val_accuracy: 0.7863 - val_loss: 0.4830\n",
      "Epoch 548/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.8171 - loss: 0.4170 - val_accuracy: 0.7872 - val_loss: 0.4828\n",
      "Epoch 549/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.8179 - loss: 0.4183 - val_accuracy: 0.7906 - val_loss: 0.4787\n",
      "Epoch 550/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8193 - loss: 0.4206 - val_accuracy: 0.7866 - val_loss: 0.4804\n",
      "Epoch 551/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.8212 - loss: 0.4187 - val_accuracy: 0.7881 - val_loss: 0.4788\n",
      "Epoch 552/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.8143 - loss: 0.4239 - val_accuracy: 0.7860 - val_loss: 0.4835\n",
      "Epoch 553/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643us/step - accuracy: 0.8170 - loss: 0.4212 - val_accuracy: 0.7901 - val_loss: 0.4750\n",
      "Epoch 554/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.8208 - loss: 0.4182 - val_accuracy: 0.7833 - val_loss: 0.4927\n",
      "Epoch 555/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.8203 - loss: 0.4176 - val_accuracy: 0.7821 - val_loss: 0.4989\n",
      "Epoch 556/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8199 - loss: 0.4199 - val_accuracy: 0.7908 - val_loss: 0.4799\n",
      "Epoch 557/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.8144 - loss: 0.4263 - val_accuracy: 0.7854 - val_loss: 0.4886\n",
      "Epoch 558/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.8158 - loss: 0.4221 - val_accuracy: 0.7912 - val_loss: 0.4782\n",
      "Epoch 559/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.8172 - loss: 0.4197 - val_accuracy: 0.7823 - val_loss: 0.4945\n",
      "Epoch 560/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.8199 - loss: 0.4186 - val_accuracy: 0.7888 - val_loss: 0.4840\n",
      "Epoch 561/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - accuracy: 0.8172 - loss: 0.4191 - val_accuracy: 0.7909 - val_loss: 0.4741\n",
      "Epoch 562/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.8225 - loss: 0.4105 - val_accuracy: 0.7926 - val_loss: 0.4737\n",
      "Epoch 563/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.8203 - loss: 0.4173 - val_accuracy: 0.7964 - val_loss: 0.4663\n",
      "Epoch 564/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.8212 - loss: 0.4149 - val_accuracy: 0.7945 - val_loss: 0.4701\n",
      "Epoch 565/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.8218 - loss: 0.4137 - val_accuracy: 0.7950 - val_loss: 0.4699\n",
      "Epoch 566/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - accuracy: 0.8211 - loss: 0.4146 - val_accuracy: 0.7925 - val_loss: 0.4717\n",
      "Epoch 567/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.8172 - loss: 0.4234 - val_accuracy: 0.7979 - val_loss: 0.4627\n",
      "Epoch 568/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.8153 - loss: 0.4233 - val_accuracy: 0.7961 - val_loss: 0.4668\n",
      "Epoch 569/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.8172 - loss: 0.4214 - val_accuracy: 0.7944 - val_loss: 0.4697\n",
      "Epoch 570/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.8185 - loss: 0.4227 - val_accuracy: 0.7942 - val_loss: 0.4695\n",
      "Epoch 571/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.8187 - loss: 0.4228 - val_accuracy: 0.7878 - val_loss: 0.4810\n",
      "Epoch 572/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - accuracy: 0.8179 - loss: 0.4199 - val_accuracy: 0.7959 - val_loss: 0.4652\n",
      "Epoch 573/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.8147 - loss: 0.4256 - val_accuracy: 0.7872 - val_loss: 0.4798\n",
      "Epoch 574/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.8191 - loss: 0.4214 - val_accuracy: 0.7981 - val_loss: 0.4613\n",
      "Epoch 575/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.8185 - loss: 0.4218 - val_accuracy: 0.7874 - val_loss: 0.4804\n",
      "Epoch 576/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.8194 - loss: 0.4238 - val_accuracy: 0.7869 - val_loss: 0.4864\n",
      "Epoch 577/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.8162 - loss: 0.4232 - val_accuracy: 0.7949 - val_loss: 0.4655\n",
      "Epoch 578/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.8229 - loss: 0.4134 - val_accuracy: 0.7917 - val_loss: 0.4755\n",
      "Epoch 579/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.8223 - loss: 0.4134 - val_accuracy: 0.7911 - val_loss: 0.4703\n",
      "Epoch 580/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.8190 - loss: 0.4154 - val_accuracy: 0.7891 - val_loss: 0.4776\n",
      "Epoch 581/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.8145 - loss: 0.4272 - val_accuracy: 0.7884 - val_loss: 0.4809\n",
      "Epoch 582/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.8163 - loss: 0.4244 - val_accuracy: 0.7908 - val_loss: 0.4737\n",
      "Epoch 583/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.8161 - loss: 0.4175 - val_accuracy: 0.7936 - val_loss: 0.4675\n",
      "Epoch 584/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.8188 - loss: 0.4209 - val_accuracy: 0.7956 - val_loss: 0.4640\n",
      "Epoch 585/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8192 - loss: 0.4205 - val_accuracy: 0.7880 - val_loss: 0.4801\n",
      "Epoch 586/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.8170 - loss: 0.4221 - val_accuracy: 0.7986 - val_loss: 0.4605\n",
      "Epoch 587/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.8151 - loss: 0.4199 - val_accuracy: 0.8003 - val_loss: 0.4543\n",
      "Epoch 588/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.8140 - loss: 0.4261 - val_accuracy: 0.7929 - val_loss: 0.4766\n",
      "Epoch 589/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.8182 - loss: 0.4191 - val_accuracy: 0.7913 - val_loss: 0.4775\n",
      "Epoch 590/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8203 - loss: 0.4191 - val_accuracy: 0.7984 - val_loss: 0.4666\n",
      "Epoch 591/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.8166 - loss: 0.4207 - val_accuracy: 0.7951 - val_loss: 0.4745\n",
      "Epoch 592/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.8217 - loss: 0.4178 - val_accuracy: 0.7990 - val_loss: 0.4625\n",
      "Epoch 593/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.8191 - loss: 0.4194 - val_accuracy: 0.7961 - val_loss: 0.4731\n",
      "Epoch 594/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.8205 - loss: 0.4167 - val_accuracy: 0.7943 - val_loss: 0.4656\n",
      "Epoch 595/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.8191 - loss: 0.4144 - val_accuracy: 0.7953 - val_loss: 0.4619\n",
      "Epoch 596/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8163 - loss: 0.4253 - val_accuracy: 0.7924 - val_loss: 0.4737\n",
      "Epoch 597/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - accuracy: 0.8162 - loss: 0.4211 - val_accuracy: 0.7975 - val_loss: 0.4640\n",
      "Epoch 598/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8178 - loss: 0.4215 - val_accuracy: 0.7950 - val_loss: 0.4702\n",
      "Epoch 599/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.8171 - loss: 0.4172 - val_accuracy: 0.7919 - val_loss: 0.4718\n",
      "Epoch 600/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.8186 - loss: 0.4164 - val_accuracy: 0.7911 - val_loss: 0.4798\n",
      "Epoch 601/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 0.8216 - loss: 0.4186 - val_accuracy: 0.7892 - val_loss: 0.4885\n",
      "Epoch 602/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - accuracy: 0.8213 - loss: 0.4140 - val_accuracy: 0.7854 - val_loss: 0.4928\n",
      "Epoch 603/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.8178 - loss: 0.4188 - val_accuracy: 0.7846 - val_loss: 0.4972\n",
      "Epoch 604/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.8174 - loss: 0.4169 - val_accuracy: 0.7932 - val_loss: 0.4727\n",
      "Epoch 605/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.8215 - loss: 0.4158 - val_accuracy: 0.7899 - val_loss: 0.4780\n",
      "Epoch 606/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.8160 - loss: 0.4201 - val_accuracy: 0.7949 - val_loss: 0.4693\n",
      "Epoch 607/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.8181 - loss: 0.4196 - val_accuracy: 0.7862 - val_loss: 0.4849\n",
      "Epoch 608/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - accuracy: 0.8175 - loss: 0.4184 - val_accuracy: 0.7963 - val_loss: 0.4607\n",
      "Epoch 609/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.8193 - loss: 0.4157 - val_accuracy: 0.7974 - val_loss: 0.4622\n",
      "Epoch 610/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8144 - loss: 0.4247 - val_accuracy: 0.7950 - val_loss: 0.4665\n",
      "Epoch 611/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.8171 - loss: 0.4215 - val_accuracy: 0.7841 - val_loss: 0.4963\n",
      "Epoch 612/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.8175 - loss: 0.4186 - val_accuracy: 0.7954 - val_loss: 0.4669\n",
      "Epoch 613/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.8200 - loss: 0.4227 - val_accuracy: 0.7952 - val_loss: 0.4658\n",
      "Epoch 614/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.8204 - loss: 0.4154 - val_accuracy: 0.7941 - val_loss: 0.4701\n",
      "Epoch 615/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.8200 - loss: 0.4178 - val_accuracy: 0.7885 - val_loss: 0.4778\n",
      "Epoch 616/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.8204 - loss: 0.4172 - val_accuracy: 0.7880 - val_loss: 0.4781\n",
      "Epoch 617/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.8243 - loss: 0.4076 - val_accuracy: 0.7914 - val_loss: 0.4702\n",
      "Epoch 618/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.8201 - loss: 0.4187 - val_accuracy: 0.7896 - val_loss: 0.4743\n",
      "Epoch 619/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.8172 - loss: 0.4228 - val_accuracy: 0.7880 - val_loss: 0.4779\n",
      "Epoch 620/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - accuracy: 0.8206 - loss: 0.4190 - val_accuracy: 0.7836 - val_loss: 0.4956\n",
      "Epoch 621/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.8165 - loss: 0.4247 - val_accuracy: 0.7847 - val_loss: 0.4853\n",
      "Epoch 622/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8198 - loss: 0.4148 - val_accuracy: 0.7921 - val_loss: 0.4768\n",
      "Epoch 623/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672us/step - accuracy: 0.8145 - loss: 0.4241 - val_accuracy: 0.7911 - val_loss: 0.4715\n",
      "Epoch 624/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.8187 - loss: 0.4210 - val_accuracy: 0.7897 - val_loss: 0.4769\n",
      "Epoch 625/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.8230 - loss: 0.4124 - val_accuracy: 0.7843 - val_loss: 0.4892\n",
      "Epoch 626/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.8169 - loss: 0.4248 - val_accuracy: 0.7859 - val_loss: 0.4847\n",
      "Epoch 627/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.8185 - loss: 0.4215 - val_accuracy: 0.7964 - val_loss: 0.4623\n",
      "Epoch 628/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.8233 - loss: 0.4185 - val_accuracy: 0.7923 - val_loss: 0.4734\n",
      "Epoch 629/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.8197 - loss: 0.4225 - val_accuracy: 0.7985 - val_loss: 0.4614\n",
      "Epoch 630/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.8182 - loss: 0.4202 - val_accuracy: 0.7936 - val_loss: 0.4738\n",
      "Epoch 631/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.8168 - loss: 0.4218 - val_accuracy: 0.7911 - val_loss: 0.4747\n",
      "Epoch 632/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.8183 - loss: 0.4215 - val_accuracy: 0.7952 - val_loss: 0.4675\n",
      "Epoch 633/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.8174 - loss: 0.4216 - val_accuracy: 0.7890 - val_loss: 0.4788\n",
      "Epoch 634/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - accuracy: 0.8239 - loss: 0.4157 - val_accuracy: 0.7912 - val_loss: 0.4774\n",
      "Epoch 635/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.8232 - loss: 0.4114 - val_accuracy: 0.7967 - val_loss: 0.4637\n",
      "Epoch 636/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8222 - loss: 0.4167 - val_accuracy: 0.7933 - val_loss: 0.4710\n",
      "Epoch 637/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.8211 - loss: 0.4125 - val_accuracy: 0.7967 - val_loss: 0.4632\n",
      "Epoch 638/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.8216 - loss: 0.4178 - val_accuracy: 0.7938 - val_loss: 0.4738\n",
      "Epoch 639/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.8183 - loss: 0.4213 - val_accuracy: 0.7954 - val_loss: 0.4686\n",
      "Epoch 640/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.8208 - loss: 0.4150 - val_accuracy: 0.7874 - val_loss: 0.4801\n",
      "Epoch 641/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.8215 - loss: 0.4154 - val_accuracy: 0.7893 - val_loss: 0.4823\n",
      "Epoch 642/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.8167 - loss: 0.4190 - val_accuracy: 0.7937 - val_loss: 0.4693\n",
      "Epoch 643/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.8162 - loss: 0.4239 - val_accuracy: 0.7930 - val_loss: 0.4712\n",
      "Epoch 644/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.8214 - loss: 0.4168 - val_accuracy: 0.7957 - val_loss: 0.4689\n",
      "Epoch 645/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step - accuracy: 0.8177 - loss: 0.4185 - val_accuracy: 0.7897 - val_loss: 0.4786\n",
      "Epoch 646/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8197 - loss: 0.4160 - val_accuracy: 0.7858 - val_loss: 0.4838\n",
      "Epoch 647/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.8199 - loss: 0.4147 - val_accuracy: 0.7905 - val_loss: 0.4725\n",
      "Epoch 648/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.8204 - loss: 0.4185 - val_accuracy: 0.7900 - val_loss: 0.4798\n",
      "Epoch 649/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8180 - loss: 0.4212 - val_accuracy: 0.7953 - val_loss: 0.4677\n",
      "Epoch 650/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.8176 - loss: 0.4236 - val_accuracy: 0.7930 - val_loss: 0.4722\n",
      "Epoch 651/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.8249 - loss: 0.4104 - val_accuracy: 0.7909 - val_loss: 0.4750\n",
      "Epoch 652/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.8208 - loss: 0.4201 - val_accuracy: 0.7869 - val_loss: 0.4875\n",
      "Epoch 653/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.8211 - loss: 0.4167 - val_accuracy: 0.7920 - val_loss: 0.4756\n",
      "Epoch 654/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.8178 - loss: 0.4215 - val_accuracy: 0.7955 - val_loss: 0.4691\n",
      "Epoch 655/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.8209 - loss: 0.4209 - val_accuracy: 0.7914 - val_loss: 0.4772\n",
      "Epoch 656/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.8191 - loss: 0.4169 - val_accuracy: 0.7987 - val_loss: 0.4613\n",
      "Epoch 657/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.8274 - loss: 0.4083 - val_accuracy: 0.7879 - val_loss: 0.4853\n",
      "Epoch 658/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 0.8178 - loss: 0.4207 - val_accuracy: 0.7919 - val_loss: 0.4772\n",
      "Epoch 659/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.8193 - loss: 0.4173 - val_accuracy: 0.7940 - val_loss: 0.4648\n",
      "Epoch 660/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.8184 - loss: 0.4182 - val_accuracy: 0.7882 - val_loss: 0.4841\n",
      "Epoch 661/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.8174 - loss: 0.4201 - val_accuracy: 0.7860 - val_loss: 0.4848\n",
      "Epoch 662/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8178 - loss: 0.4161 - val_accuracy: 0.7895 - val_loss: 0.4776\n",
      "Epoch 663/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.8186 - loss: 0.4162 - val_accuracy: 0.7951 - val_loss: 0.4648\n",
      "Epoch 664/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.8201 - loss: 0.4155 - val_accuracy: 0.7904 - val_loss: 0.4770\n",
      "Epoch 665/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8212 - loss: 0.4172 - val_accuracy: 0.7943 - val_loss: 0.4648\n",
      "Epoch 666/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.8202 - loss: 0.4164 - val_accuracy: 0.7955 - val_loss: 0.4663\n",
      "Epoch 667/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.8186 - loss: 0.4194 - val_accuracy: 0.7944 - val_loss: 0.4671\n",
      "Epoch 668/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.8178 - loss: 0.4185 - val_accuracy: 0.7874 - val_loss: 0.4866\n",
      "Epoch 669/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 0.8221 - loss: 0.4141 - val_accuracy: 0.7978 - val_loss: 0.4648\n",
      "Epoch 670/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.8221 - loss: 0.4154 - val_accuracy: 0.7948 - val_loss: 0.4698\n",
      "Epoch 671/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.8201 - loss: 0.4177 - val_accuracy: 0.7899 - val_loss: 0.4798\n",
      "Epoch 672/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.8222 - loss: 0.4111 - val_accuracy: 0.7944 - val_loss: 0.4707\n",
      "Epoch 673/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8212 - loss: 0.4185 - val_accuracy: 0.7976 - val_loss: 0.4589\n",
      "Epoch 674/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.8196 - loss: 0.4185 - val_accuracy: 0.7876 - val_loss: 0.4809\n",
      "Epoch 675/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8230 - loss: 0.4144 - val_accuracy: 0.8024 - val_loss: 0.4505\n",
      "Epoch 676/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.8174 - loss: 0.4205 - val_accuracy: 0.7985 - val_loss: 0.4581\n",
      "Epoch 677/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8192 - loss: 0.4180 - val_accuracy: 0.7930 - val_loss: 0.4654\n",
      "Epoch 678/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - accuracy: 0.8212 - loss: 0.4140 - val_accuracy: 0.7935 - val_loss: 0.4709\n",
      "Epoch 679/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.8205 - loss: 0.4147 - val_accuracy: 0.7963 - val_loss: 0.4637\n",
      "Epoch 680/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8224 - loss: 0.4126 - val_accuracy: 0.7943 - val_loss: 0.4680\n",
      "Epoch 681/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.8184 - loss: 0.4190 - val_accuracy: 0.7942 - val_loss: 0.4649\n",
      "Epoch 682/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.8191 - loss: 0.4180 - val_accuracy: 0.7995 - val_loss: 0.4536\n",
      "Epoch 683/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.8214 - loss: 0.4205 - val_accuracy: 0.7907 - val_loss: 0.4776\n",
      "Epoch 684/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.8207 - loss: 0.4190 - val_accuracy: 0.7960 - val_loss: 0.4645\n",
      "Epoch 685/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.8183 - loss: 0.4192 - val_accuracy: 0.7930 - val_loss: 0.4730\n",
      "Epoch 686/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.8194 - loss: 0.4113 - val_accuracy: 0.8007 - val_loss: 0.4526\n",
      "Epoch 687/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.8192 - loss: 0.4188 - val_accuracy: 0.7918 - val_loss: 0.4724\n",
      "Epoch 688/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.8223 - loss: 0.4142 - val_accuracy: 0.7976 - val_loss: 0.4612\n",
      "Epoch 689/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.8215 - loss: 0.4126 - val_accuracy: 0.7933 - val_loss: 0.4711\n",
      "Epoch 690/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.8156 - loss: 0.4219 - val_accuracy: 0.7999 - val_loss: 0.4532\n",
      "Epoch 691/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.8222 - loss: 0.4135 - val_accuracy: 0.7954 - val_loss: 0.4602\n",
      "Epoch 692/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.8213 - loss: 0.4139 - val_accuracy: 0.7977 - val_loss: 0.4670\n",
      "Epoch 693/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8165 - loss: 0.4206 - val_accuracy: 0.7972 - val_loss: 0.4573\n",
      "Epoch 694/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.8215 - loss: 0.4141 - val_accuracy: 0.7929 - val_loss: 0.4698\n",
      "Epoch 695/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.8217 - loss: 0.4154 - val_accuracy: 0.7984 - val_loss: 0.4600\n",
      "Epoch 696/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.8193 - loss: 0.4163 - val_accuracy: 0.7951 - val_loss: 0.4617\n",
      "Epoch 697/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - accuracy: 0.8171 - loss: 0.4209 - val_accuracy: 0.7868 - val_loss: 0.4745\n",
      "Epoch 698/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step - accuracy: 0.8204 - loss: 0.4144 - val_accuracy: 0.7913 - val_loss: 0.4756\n",
      "Epoch 699/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.8159 - loss: 0.4200 - val_accuracy: 0.7907 - val_loss: 0.4751\n",
      "Epoch 700/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8186 - loss: 0.4160 - val_accuracy: 0.7939 - val_loss: 0.4680\n",
      "Epoch 701/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.8165 - loss: 0.4230 - val_accuracy: 0.7920 - val_loss: 0.4747\n",
      "Epoch 702/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8232 - loss: 0.4134 - val_accuracy: 0.7974 - val_loss: 0.4664\n",
      "Epoch 703/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.8190 - loss: 0.4160 - val_accuracy: 0.7889 - val_loss: 0.4747\n",
      "Epoch 704/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.8238 - loss: 0.4146 - val_accuracy: 0.7980 - val_loss: 0.4612\n",
      "Epoch 705/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8227 - loss: 0.4129 - val_accuracy: 0.7977 - val_loss: 0.4582\n",
      "Epoch 706/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.8177 - loss: 0.4228 - val_accuracy: 0.7917 - val_loss: 0.4721\n",
      "Epoch 707/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638us/step - accuracy: 0.8212 - loss: 0.4101 - val_accuracy: 0.7879 - val_loss: 0.4780\n",
      "Epoch 708/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.8219 - loss: 0.4187 - val_accuracy: 0.7925 - val_loss: 0.4730\n",
      "Epoch 709/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.8210 - loss: 0.4142 - val_accuracy: 0.7976 - val_loss: 0.4608\n",
      "Epoch 710/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.8182 - loss: 0.4145 - val_accuracy: 0.7973 - val_loss: 0.4606\n",
      "Epoch 711/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8206 - loss: 0.4161 - val_accuracy: 0.7966 - val_loss: 0.4648\n",
      "Epoch 712/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.8173 - loss: 0.4178 - val_accuracy: 0.7923 - val_loss: 0.4695\n",
      "Epoch 713/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.8211 - loss: 0.4167 - val_accuracy: 0.7944 - val_loss: 0.4722\n",
      "Epoch 714/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8228 - loss: 0.4140 - val_accuracy: 0.7943 - val_loss: 0.4657\n",
      "Epoch 715/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.8204 - loss: 0.4136 - val_accuracy: 0.7892 - val_loss: 0.4759\n",
      "Epoch 716/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.8198 - loss: 0.4163 - val_accuracy: 0.7909 - val_loss: 0.4752\n",
      "Epoch 717/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.8250 - loss: 0.4086 - val_accuracy: 0.7884 - val_loss: 0.4858\n",
      "Epoch 718/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8237 - loss: 0.4132 - val_accuracy: 0.7937 - val_loss: 0.4688\n",
      "Epoch 719/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.8207 - loss: 0.4119 - val_accuracy: 0.7962 - val_loss: 0.4634\n",
      "Epoch 720/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 0.8226 - loss: 0.4160 - val_accuracy: 0.7928 - val_loss: 0.4702\n",
      "Epoch 721/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8227 - loss: 0.4125 - val_accuracy: 0.8005 - val_loss: 0.4566\n",
      "Epoch 722/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 639us/step - accuracy: 0.8198 - loss: 0.4212 - val_accuracy: 0.7974 - val_loss: 0.4603\n",
      "Epoch 723/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.8206 - loss: 0.4157 - val_accuracy: 0.7979 - val_loss: 0.4584\n",
      "Epoch 724/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.8207 - loss: 0.4146 - val_accuracy: 0.8029 - val_loss: 0.4518\n",
      "Epoch 725/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.8184 - loss: 0.4181 - val_accuracy: 0.8014 - val_loss: 0.4524\n",
      "Epoch 726/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.8209 - loss: 0.4202 - val_accuracy: 0.8007 - val_loss: 0.4593\n",
      "Epoch 727/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 0.8202 - loss: 0.4152 - val_accuracy: 0.7975 - val_loss: 0.4610\n",
      "Epoch 728/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.8187 - loss: 0.4204 - val_accuracy: 0.8000 - val_loss: 0.4578\n",
      "Epoch 729/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.8232 - loss: 0.4135 - val_accuracy: 0.8004 - val_loss: 0.4559\n",
      "Epoch 730/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8271 - loss: 0.4061 - val_accuracy: 0.7931 - val_loss: 0.4703\n",
      "Epoch 731/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.8228 - loss: 0.4135 - val_accuracy: 0.7897 - val_loss: 0.4776\n",
      "Epoch 732/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8264 - loss: 0.4098 - val_accuracy: 0.7957 - val_loss: 0.4647\n",
      "Epoch 733/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.8197 - loss: 0.4182 - val_accuracy: 0.7945 - val_loss: 0.4697\n",
      "Epoch 734/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.8209 - loss: 0.4146 - val_accuracy: 0.8004 - val_loss: 0.4550\n",
      "Epoch 735/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.8188 - loss: 0.4173 - val_accuracy: 0.7909 - val_loss: 0.4783\n",
      "Epoch 736/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.8250 - loss: 0.4068 - val_accuracy: 0.7903 - val_loss: 0.4760\n",
      "Epoch 737/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734us/step - accuracy: 0.8210 - loss: 0.4142 - val_accuracy: 0.7907 - val_loss: 0.4772\n",
      "Epoch 738/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8229 - loss: 0.4132 - val_accuracy: 0.7939 - val_loss: 0.4715\n",
      "Epoch 739/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.8160 - loss: 0.4219 - val_accuracy: 0.7976 - val_loss: 0.4600\n",
      "Epoch 740/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8207 - loss: 0.4175 - val_accuracy: 0.7963 - val_loss: 0.4600\n",
      "Epoch 741/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.8212 - loss: 0.4123 - val_accuracy: 0.7897 - val_loss: 0.4746\n",
      "Epoch 742/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8205 - loss: 0.4130 - val_accuracy: 0.7915 - val_loss: 0.4698\n",
      "Epoch 743/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.8210 - loss: 0.4171 - val_accuracy: 0.7907 - val_loss: 0.4700\n",
      "Epoch 744/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.8232 - loss: 0.4144 - val_accuracy: 0.7938 - val_loss: 0.4671\n",
      "Epoch 745/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.8195 - loss: 0.4169 - val_accuracy: 0.7972 - val_loss: 0.4592\n",
      "Epoch 746/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.8195 - loss: 0.4162 - val_accuracy: 0.7967 - val_loss: 0.4606\n",
      "Epoch 747/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.8190 - loss: 0.4213 - val_accuracy: 0.7892 - val_loss: 0.4760\n",
      "Epoch 748/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.8224 - loss: 0.4137 - val_accuracy: 0.7918 - val_loss: 0.4726\n",
      "Epoch 749/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8215 - loss: 0.4134 - val_accuracy: 0.8001 - val_loss: 0.4569\n",
      "Epoch 750/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - accuracy: 0.8248 - loss: 0.4135 - val_accuracy: 0.7942 - val_loss: 0.4726\n",
      "Epoch 751/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.8188 - loss: 0.4163 - val_accuracy: 0.7956 - val_loss: 0.4689\n",
      "Epoch 752/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.8212 - loss: 0.4133 - val_accuracy: 0.7914 - val_loss: 0.4749\n",
      "Epoch 753/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 0.8161 - loss: 0.4188 - val_accuracy: 0.7921 - val_loss: 0.4726\n",
      "Epoch 754/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8212 - loss: 0.4137 - val_accuracy: 0.7912 - val_loss: 0.4728\n",
      "Epoch 755/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.8220 - loss: 0.4161 - val_accuracy: 0.7931 - val_loss: 0.4718\n",
      "Epoch 756/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step - accuracy: 0.8218 - loss: 0.4165 - val_accuracy: 0.7995 - val_loss: 0.4553\n",
      "Epoch 757/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.8217 - loss: 0.4160 - val_accuracy: 0.7975 - val_loss: 0.4629\n",
      "Epoch 758/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.8185 - loss: 0.4146 - val_accuracy: 0.7952 - val_loss: 0.4647\n",
      "Epoch 759/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.8273 - loss: 0.4091 - val_accuracy: 0.7967 - val_loss: 0.4633\n",
      "Epoch 760/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8234 - loss: 0.4131 - val_accuracy: 0.7980 - val_loss: 0.4574\n",
      "Epoch 761/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.8226 - loss: 0.4169 - val_accuracy: 0.7953 - val_loss: 0.4635\n",
      "Epoch 762/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 0.8232 - loss: 0.4103 - val_accuracy: 0.7965 - val_loss: 0.4646\n",
      "Epoch 763/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.8207 - loss: 0.4138 - val_accuracy: 0.7924 - val_loss: 0.4720\n",
      "Epoch 764/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.8222 - loss: 0.4152 - val_accuracy: 0.8002 - val_loss: 0.4575\n",
      "Epoch 765/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.8232 - loss: 0.4132 - val_accuracy: 0.7925 - val_loss: 0.4702\n",
      "Epoch 766/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.8241 - loss: 0.4114 - val_accuracy: 0.7925 - val_loss: 0.4662\n",
      "Epoch 767/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8239 - loss: 0.4111 - val_accuracy: 0.7949 - val_loss: 0.4621\n",
      "Epoch 768/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8233 - loss: 0.4095 - val_accuracy: 0.7995 - val_loss: 0.4559\n",
      "Epoch 769/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.8199 - loss: 0.4111 - val_accuracy: 0.7896 - val_loss: 0.4748\n",
      "Epoch 770/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8217 - loss: 0.4162 - val_accuracy: 0.7988 - val_loss: 0.4606\n",
      "Epoch 771/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.8191 - loss: 0.4175 - val_accuracy: 0.7955 - val_loss: 0.4593\n",
      "Epoch 772/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - accuracy: 0.8231 - loss: 0.4141 - val_accuracy: 0.7949 - val_loss: 0.4639\n",
      "Epoch 773/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8171 - loss: 0.4166 - val_accuracy: 0.7992 - val_loss: 0.4567\n",
      "Epoch 774/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8207 - loss: 0.4165 - val_accuracy: 0.7986 - val_loss: 0.4609\n",
      "Epoch 775/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.8228 - loss: 0.4106 - val_accuracy: 0.7985 - val_loss: 0.4589\n",
      "Epoch 776/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.8234 - loss: 0.4092 - val_accuracy: 0.7950 - val_loss: 0.4608\n",
      "Epoch 777/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.8180 - loss: 0.4157 - val_accuracy: 0.7915 - val_loss: 0.4705\n",
      "Epoch 778/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.8202 - loss: 0.4128 - val_accuracy: 0.8000 - val_loss: 0.4518\n",
      "Epoch 779/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.8225 - loss: 0.4141 - val_accuracy: 0.7927 - val_loss: 0.4703\n",
      "Epoch 780/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.8226 - loss: 0.4175 - val_accuracy: 0.7943 - val_loss: 0.4698\n",
      "Epoch 781/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8198 - loss: 0.4141 - val_accuracy: 0.7991 - val_loss: 0.4592\n",
      "Epoch 782/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 0.8256 - loss: 0.4118 - val_accuracy: 0.7973 - val_loss: 0.4596\n",
      "Epoch 783/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.8190 - loss: 0.4123 - val_accuracy: 0.7964 - val_loss: 0.4632\n",
      "Epoch 784/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.8207 - loss: 0.4146 - val_accuracy: 0.7980 - val_loss: 0.4564\n",
      "Epoch 785/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.8212 - loss: 0.4137 - val_accuracy: 0.7937 - val_loss: 0.4704\n",
      "Epoch 786/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8209 - loss: 0.4180 - val_accuracy: 0.7977 - val_loss: 0.4613\n",
      "Epoch 787/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8253 - loss: 0.4067 - val_accuracy: 0.8027 - val_loss: 0.4553\n",
      "Epoch 788/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.8201 - loss: 0.4152 - val_accuracy: 0.8000 - val_loss: 0.4554\n",
      "Epoch 789/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 0.8240 - loss: 0.4145 - val_accuracy: 0.7920 - val_loss: 0.4697\n",
      "Epoch 790/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.8216 - loss: 0.4089 - val_accuracy: 0.7983 - val_loss: 0.4591\n",
      "Epoch 791/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8214 - loss: 0.4149 - val_accuracy: 0.8003 - val_loss: 0.4571\n",
      "Epoch 792/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.8212 - loss: 0.4119 - val_accuracy: 0.7985 - val_loss: 0.4633\n",
      "Epoch 793/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8242 - loss: 0.4086 - val_accuracy: 0.7999 - val_loss: 0.4517\n",
      "Epoch 794/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.8233 - loss: 0.4146 - val_accuracy: 0.7948 - val_loss: 0.4655\n",
      "Epoch 795/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.8231 - loss: 0.4120 - val_accuracy: 0.7949 - val_loss: 0.4654\n",
      "Epoch 796/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.8204 - loss: 0.4206 - val_accuracy: 0.7972 - val_loss: 0.4583\n",
      "Epoch 797/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.8164 - loss: 0.4218 - val_accuracy: 0.7913 - val_loss: 0.4673\n",
      "Epoch 798/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.8250 - loss: 0.4065 - val_accuracy: 0.7918 - val_loss: 0.4758\n",
      "Epoch 799/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.8273 - loss: 0.4062 - val_accuracy: 0.7983 - val_loss: 0.4613\n",
      "Epoch 800/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.8195 - loss: 0.4200 - val_accuracy: 0.7990 - val_loss: 0.4609\n",
      "Epoch 801/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.8229 - loss: 0.4141 - val_accuracy: 0.8008 - val_loss: 0.4583\n",
      "Epoch 802/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.8217 - loss: 0.4091 - val_accuracy: 0.7945 - val_loss: 0.4667\n",
      "Epoch 803/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 0.8179 - loss: 0.4223 - val_accuracy: 0.7965 - val_loss: 0.4649\n",
      "Epoch 804/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 747us/step - accuracy: 0.8206 - loss: 0.4169 - val_accuracy: 0.7965 - val_loss: 0.4644\n",
      "Epoch 805/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8217 - loss: 0.4168 - val_accuracy: 0.7966 - val_loss: 0.4615\n",
      "Epoch 806/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - accuracy: 0.8221 - loss: 0.4131 - val_accuracy: 0.7953 - val_loss: 0.4628\n",
      "Epoch 807/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.8229 - loss: 0.4145 - val_accuracy: 0.7959 - val_loss: 0.4663\n",
      "Epoch 808/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - accuracy: 0.8243 - loss: 0.4118 - val_accuracy: 0.7916 - val_loss: 0.4749\n",
      "Epoch 809/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step - accuracy: 0.8205 - loss: 0.4142 - val_accuracy: 0.7967 - val_loss: 0.4607\n",
      "Epoch 810/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8214 - loss: 0.4136 - val_accuracy: 0.7995 - val_loss: 0.4603\n",
      "Epoch 811/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.8207 - loss: 0.4142 - val_accuracy: 0.7991 - val_loss: 0.4615\n",
      "Epoch 812/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.8249 - loss: 0.4106 - val_accuracy: 0.8028 - val_loss: 0.4524\n",
      "Epoch 813/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.8201 - loss: 0.4199 - val_accuracy: 0.7921 - val_loss: 0.4703\n",
      "Epoch 814/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.8214 - loss: 0.4176 - val_accuracy: 0.7978 - val_loss: 0.4593\n",
      "Epoch 815/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756us/step - accuracy: 0.8215 - loss: 0.4132 - val_accuracy: 0.7947 - val_loss: 0.4637\n",
      "Epoch 816/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8216 - loss: 0.4090 - val_accuracy: 0.8001 - val_loss: 0.4539\n",
      "Epoch 817/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8220 - loss: 0.4134 - val_accuracy: 0.7930 - val_loss: 0.4693\n",
      "Epoch 818/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 0.8241 - loss: 0.4101 - val_accuracy: 0.7945 - val_loss: 0.4665\n",
      "Epoch 819/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.8248 - loss: 0.4102 - val_accuracy: 0.7989 - val_loss: 0.4614\n",
      "Epoch 820/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.8254 - loss: 0.4041 - val_accuracy: 0.7948 - val_loss: 0.4665\n",
      "Epoch 821/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8261 - loss: 0.4079 - val_accuracy: 0.7924 - val_loss: 0.4663\n",
      "Epoch 822/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8221 - loss: 0.4139 - val_accuracy: 0.7895 - val_loss: 0.4767\n",
      "Epoch 823/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.8210 - loss: 0.4170 - val_accuracy: 0.7990 - val_loss: 0.4617\n",
      "Epoch 824/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723us/step - accuracy: 0.8201 - loss: 0.4145 - val_accuracy: 0.7931 - val_loss: 0.4671\n",
      "Epoch 825/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8236 - loss: 0.4113 - val_accuracy: 0.7895 - val_loss: 0.4766\n",
      "Epoch 826/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.8207 - loss: 0.4115 - val_accuracy: 0.7996 - val_loss: 0.4571\n",
      "Epoch 827/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.8225 - loss: 0.4124 - val_accuracy: 0.7897 - val_loss: 0.4765\n",
      "Epoch 828/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - accuracy: 0.8193 - loss: 0.4162 - val_accuracy: 0.7988 - val_loss: 0.4549\n",
      "Epoch 829/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.8199 - loss: 0.4174 - val_accuracy: 0.7954 - val_loss: 0.4588\n",
      "Epoch 830/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8205 - loss: 0.4139 - val_accuracy: 0.7927 - val_loss: 0.4667\n",
      "Epoch 831/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8237 - loss: 0.4121 - val_accuracy: 0.7952 - val_loss: 0.4649\n",
      "Epoch 832/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.8291 - loss: 0.4054 - val_accuracy: 0.7932 - val_loss: 0.4696\n",
      "Epoch 833/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.8209 - loss: 0.4190 - val_accuracy: 0.7999 - val_loss: 0.4544\n",
      "Epoch 834/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - accuracy: 0.8247 - loss: 0.4094 - val_accuracy: 0.7952 - val_loss: 0.4638\n",
      "Epoch 835/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 794us/step - accuracy: 0.8176 - loss: 0.4193 - val_accuracy: 0.7997 - val_loss: 0.4565\n",
      "Epoch 836/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.8178 - loss: 0.4156 - val_accuracy: 0.7983 - val_loss: 0.4596\n",
      "Epoch 837/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 0.8203 - loss: 0.4165 - val_accuracy: 0.7980 - val_loss: 0.4629\n",
      "Epoch 838/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681us/step - accuracy: 0.8204 - loss: 0.4158 - val_accuracy: 0.8011 - val_loss: 0.4567\n",
      "Epoch 839/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.8232 - loss: 0.4115 - val_accuracy: 0.8045 - val_loss: 0.4519\n",
      "Epoch 840/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.8222 - loss: 0.4106 - val_accuracy: 0.8011 - val_loss: 0.4578\n",
      "Epoch 841/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.8248 - loss: 0.4066 - val_accuracy: 0.7945 - val_loss: 0.4669\n",
      "Epoch 842/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.8242 - loss: 0.4103 - val_accuracy: 0.7987 - val_loss: 0.4612\n",
      "Epoch 843/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8270 - loss: 0.4087 - val_accuracy: 0.7977 - val_loss: 0.4641\n",
      "Epoch 844/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.8196 - loss: 0.4172 - val_accuracy: 0.8046 - val_loss: 0.4484\n",
      "Epoch 845/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8247 - loss: 0.4058 - val_accuracy: 0.8028 - val_loss: 0.4528\n",
      "Epoch 846/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.8210 - loss: 0.4154 - val_accuracy: 0.8010 - val_loss: 0.4536\n",
      "Epoch 847/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.8229 - loss: 0.4092 - val_accuracy: 0.7918 - val_loss: 0.4748\n",
      "Epoch 848/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.8154 - loss: 0.4203 - val_accuracy: 0.7939 - val_loss: 0.4767\n",
      "Epoch 849/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.8227 - loss: 0.4070 - val_accuracy: 0.7936 - val_loss: 0.4649\n",
      "Epoch 850/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - accuracy: 0.8191 - loss: 0.4159 - val_accuracy: 0.7968 - val_loss: 0.4616\n",
      "Epoch 851/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.8227 - loss: 0.4096 - val_accuracy: 0.7974 - val_loss: 0.4659\n",
      "Epoch 852/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.8242 - loss: 0.4122 - val_accuracy: 0.7991 - val_loss: 0.4564\n",
      "Epoch 853/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.8193 - loss: 0.4170 - val_accuracy: 0.7884 - val_loss: 0.4784\n",
      "Epoch 854/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8225 - loss: 0.4141 - val_accuracy: 0.7977 - val_loss: 0.4611\n",
      "Epoch 855/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.8251 - loss: 0.4098 - val_accuracy: 0.7981 - val_loss: 0.4624\n",
      "Epoch 856/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.8210 - loss: 0.4154 - val_accuracy: 0.7915 - val_loss: 0.4721\n",
      "Epoch 857/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.8190 - loss: 0.4145 - val_accuracy: 0.7950 - val_loss: 0.4691\n",
      "Epoch 858/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.8247 - loss: 0.4093 - val_accuracy: 0.7919 - val_loss: 0.4719\n",
      "Epoch 859/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8209 - loss: 0.4144 - val_accuracy: 0.7939 - val_loss: 0.4687\n",
      "Epoch 860/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 0.8262 - loss: 0.4095 - val_accuracy: 0.7988 - val_loss: 0.4573\n",
      "Epoch 861/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.8262 - loss: 0.4088 - val_accuracy: 0.7962 - val_loss: 0.4606\n",
      "Epoch 862/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.8271 - loss: 0.4021 - val_accuracy: 0.7968 - val_loss: 0.4634\n",
      "Epoch 863/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.8205 - loss: 0.4146 - val_accuracy: 0.8058 - val_loss: 0.4437\n",
      "Epoch 864/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8210 - loss: 0.4108 - val_accuracy: 0.7961 - val_loss: 0.4646\n",
      "Epoch 865/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.8213 - loss: 0.4119 - val_accuracy: 0.7912 - val_loss: 0.4751\n",
      "Epoch 866/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.8234 - loss: 0.4077 - val_accuracy: 0.8019 - val_loss: 0.4547\n",
      "Epoch 867/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.8257 - loss: 0.4075 - val_accuracy: 0.7943 - val_loss: 0.4641\n",
      "Epoch 868/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.8175 - loss: 0.4210 - val_accuracy: 0.8014 - val_loss: 0.4531\n",
      "Epoch 869/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.8228 - loss: 0.4177 - val_accuracy: 0.7968 - val_loss: 0.4639\n",
      "Epoch 870/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.8242 - loss: 0.4128 - val_accuracy: 0.7995 - val_loss: 0.4582\n",
      "Epoch 871/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671us/step - accuracy: 0.8212 - loss: 0.4170 - val_accuracy: 0.7944 - val_loss: 0.4636\n",
      "Epoch 872/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.8221 - loss: 0.4117 - val_accuracy: 0.7969 - val_loss: 0.4582\n",
      "Epoch 873/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8239 - loss: 0.4125 - val_accuracy: 0.7977 - val_loss: 0.4601\n",
      "Epoch 874/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.8248 - loss: 0.4078 - val_accuracy: 0.7983 - val_loss: 0.4629\n",
      "Epoch 875/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.8246 - loss: 0.4135 - val_accuracy: 0.7951 - val_loss: 0.4678\n",
      "Epoch 876/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.8212 - loss: 0.4195 - val_accuracy: 0.7964 - val_loss: 0.4621\n",
      "Epoch 877/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.8231 - loss: 0.4094 - val_accuracy: 0.7969 - val_loss: 0.4575\n",
      "Epoch 878/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.8211 - loss: 0.4128 - val_accuracy: 0.7943 - val_loss: 0.4657\n",
      "Epoch 879/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.8232 - loss: 0.4098 - val_accuracy: 0.7919 - val_loss: 0.4733\n",
      "Epoch 880/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.8258 - loss: 0.4068 - val_accuracy: 0.7945 - val_loss: 0.4679\n",
      "Epoch 881/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.8259 - loss: 0.4083 - val_accuracy: 0.7916 - val_loss: 0.4743\n",
      "Epoch 882/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8188 - loss: 0.4160 - val_accuracy: 0.8026 - val_loss: 0.4465\n",
      "Epoch 883/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.8232 - loss: 0.4140 - val_accuracy: 0.7938 - val_loss: 0.4644\n",
      "Epoch 884/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.8217 - loss: 0.4119 - val_accuracy: 0.7939 - val_loss: 0.4650\n",
      "Epoch 885/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8237 - loss: 0.4123 - val_accuracy: 0.7989 - val_loss: 0.4535\n",
      "Epoch 886/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.8205 - loss: 0.4170 - val_accuracy: 0.8016 - val_loss: 0.4480\n",
      "Epoch 887/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8233 - loss: 0.4139 - val_accuracy: 0.7925 - val_loss: 0.4651\n",
      "Epoch 888/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.8256 - loss: 0.4089 - val_accuracy: 0.7979 - val_loss: 0.4586\n",
      "Epoch 889/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.8229 - loss: 0.4118 - val_accuracy: 0.7961 - val_loss: 0.4597\n",
      "Epoch 890/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8237 - loss: 0.4107 - val_accuracy: 0.7962 - val_loss: 0.4605\n",
      "Epoch 891/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.8235 - loss: 0.4074 - val_accuracy: 0.7930 - val_loss: 0.4709\n",
      "Epoch 892/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.8255 - loss: 0.4125 - val_accuracy: 0.7988 - val_loss: 0.4593\n",
      "Epoch 893/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.8269 - loss: 0.4052 - val_accuracy: 0.8044 - val_loss: 0.4479\n",
      "Epoch 894/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.8241 - loss: 0.4049 - val_accuracy: 0.8021 - val_loss: 0.4521\n",
      "Epoch 895/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.8204 - loss: 0.4134 - val_accuracy: 0.7950 - val_loss: 0.4585\n",
      "Epoch 896/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.8213 - loss: 0.4169 - val_accuracy: 0.7987 - val_loss: 0.4566\n",
      "Epoch 897/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8256 - loss: 0.4057 - val_accuracy: 0.7991 - val_loss: 0.4592\n",
      "Epoch 898/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.8208 - loss: 0.4138 - val_accuracy: 0.7975 - val_loss: 0.4618\n",
      "Epoch 899/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.8224 - loss: 0.4159 - val_accuracy: 0.8021 - val_loss: 0.4493\n",
      "Epoch 900/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 0.8219 - loss: 0.4115 - val_accuracy: 0.7991 - val_loss: 0.4602\n",
      "Epoch 901/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.8234 - loss: 0.4096 - val_accuracy: 0.7947 - val_loss: 0.4628\n",
      "Epoch 902/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.8240 - loss: 0.4119 - val_accuracy: 0.8020 - val_loss: 0.4528\n",
      "Epoch 903/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.8200 - loss: 0.4168 - val_accuracy: 0.7975 - val_loss: 0.4677\n",
      "Epoch 904/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.8198 - loss: 0.4164 - val_accuracy: 0.7960 - val_loss: 0.4643\n",
      "Epoch 905/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 0.8261 - loss: 0.4082 - val_accuracy: 0.7997 - val_loss: 0.4594\n",
      "Epoch 906/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.8214 - loss: 0.4104 - val_accuracy: 0.8015 - val_loss: 0.4569\n",
      "Epoch 907/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 0.8239 - loss: 0.4091 - val_accuracy: 0.8005 - val_loss: 0.4550\n",
      "Epoch 908/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 0.8224 - loss: 0.4080 - val_accuracy: 0.7971 - val_loss: 0.4630\n",
      "Epoch 909/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.8222 - loss: 0.4124 - val_accuracy: 0.7991 - val_loss: 0.4591\n",
      "Epoch 910/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - accuracy: 0.8223 - loss: 0.4127 - val_accuracy: 0.7997 - val_loss: 0.4587\n",
      "Epoch 911/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.8253 - loss: 0.4069 - val_accuracy: 0.8036 - val_loss: 0.4499\n",
      "Epoch 912/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.8207 - loss: 0.4137 - val_accuracy: 0.7978 - val_loss: 0.4630\n",
      "Epoch 913/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.8204 - loss: 0.4125 - val_accuracy: 0.7911 - val_loss: 0.4762\n",
      "Epoch 914/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.8234 - loss: 0.4164 - val_accuracy: 0.7965 - val_loss: 0.4627\n",
      "Epoch 915/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.8227 - loss: 0.4109 - val_accuracy: 0.7977 - val_loss: 0.4619\n",
      "Epoch 916/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.8184 - loss: 0.4160 - val_accuracy: 0.7932 - val_loss: 0.4720\n",
      "Epoch 917/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.8241 - loss: 0.4127 - val_accuracy: 0.8012 - val_loss: 0.4535\n",
      "Epoch 918/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.8247 - loss: 0.4042 - val_accuracy: 0.7991 - val_loss: 0.4591\n",
      "Epoch 919/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.8234 - loss: 0.4111 - val_accuracy: 0.8033 - val_loss: 0.4494\n",
      "Epoch 920/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8220 - loss: 0.4106 - val_accuracy: 0.7975 - val_loss: 0.4623\n",
      "Epoch 921/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8228 - loss: 0.4110 - val_accuracy: 0.8016 - val_loss: 0.4605\n",
      "Epoch 922/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.8205 - loss: 0.4165 - val_accuracy: 0.8008 - val_loss: 0.4549\n",
      "Epoch 923/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.8207 - loss: 0.4105 - val_accuracy: 0.8000 - val_loss: 0.4607\n",
      "Epoch 924/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.8247 - loss: 0.4102 - val_accuracy: 0.8037 - val_loss: 0.4467\n",
      "Epoch 925/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.8224 - loss: 0.4098 - val_accuracy: 0.7992 - val_loss: 0.4553\n",
      "Epoch 926/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.8227 - loss: 0.4125 - val_accuracy: 0.7983 - val_loss: 0.4572\n",
      "Epoch 927/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.8232 - loss: 0.4095 - val_accuracy: 0.8033 - val_loss: 0.4496\n",
      "Epoch 928/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 0.8261 - loss: 0.4097 - val_accuracy: 0.8016 - val_loss: 0.4513\n",
      "Epoch 929/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.8251 - loss: 0.4073 - val_accuracy: 0.8005 - val_loss: 0.4558\n",
      "Epoch 930/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.8225 - loss: 0.4104 - val_accuracy: 0.8010 - val_loss: 0.4532\n",
      "Epoch 931/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.8244 - loss: 0.4081 - val_accuracy: 0.8033 - val_loss: 0.4504\n",
      "Epoch 932/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.8251 - loss: 0.4057 - val_accuracy: 0.7984 - val_loss: 0.4645\n",
      "Epoch 933/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8237 - loss: 0.4152 - val_accuracy: 0.8010 - val_loss: 0.4575\n",
      "Epoch 934/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.8212 - loss: 0.4125 - val_accuracy: 0.7984 - val_loss: 0.4592\n",
      "Epoch 935/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8249 - loss: 0.4107 - val_accuracy: 0.7927 - val_loss: 0.4683\n",
      "Epoch 936/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.8228 - loss: 0.4095 - val_accuracy: 0.7988 - val_loss: 0.4595\n",
      "Epoch 937/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.8240 - loss: 0.4090 - val_accuracy: 0.8017 - val_loss: 0.4517\n",
      "Epoch 938/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.8215 - loss: 0.4054 - val_accuracy: 0.8001 - val_loss: 0.4555\n",
      "Epoch 939/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step - accuracy: 0.8245 - loss: 0.4074 - val_accuracy: 0.7965 - val_loss: 0.4658\n",
      "Epoch 940/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.8212 - loss: 0.4148 - val_accuracy: 0.8022 - val_loss: 0.4505\n",
      "Epoch 941/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.8270 - loss: 0.4043 - val_accuracy: 0.7972 - val_loss: 0.4630\n",
      "Epoch 942/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.8222 - loss: 0.4069 - val_accuracy: 0.7974 - val_loss: 0.4616\n",
      "Epoch 943/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.8277 - loss: 0.4023 - val_accuracy: 0.7980 - val_loss: 0.4604\n",
      "Epoch 944/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - accuracy: 0.8248 - loss: 0.4095 - val_accuracy: 0.7973 - val_loss: 0.4646\n",
      "Epoch 945/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.8234 - loss: 0.4112 - val_accuracy: 0.8012 - val_loss: 0.4527\n",
      "Epoch 946/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.8217 - loss: 0.4177 - val_accuracy: 0.8002 - val_loss: 0.4545\n",
      "Epoch 947/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.8228 - loss: 0.4105 - val_accuracy: 0.8011 - val_loss: 0.4536\n",
      "Epoch 948/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.8221 - loss: 0.4087 - val_accuracy: 0.7975 - val_loss: 0.4657\n",
      "Epoch 949/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8256 - loss: 0.4047 - val_accuracy: 0.8010 - val_loss: 0.4609\n",
      "Epoch 950/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 0.8242 - loss: 0.4100 - val_accuracy: 0.7962 - val_loss: 0.4629\n",
      "Epoch 951/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.8208 - loss: 0.4185 - val_accuracy: 0.7920 - val_loss: 0.4747\n",
      "Epoch 952/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8253 - loss: 0.4085 - val_accuracy: 0.7945 - val_loss: 0.4696\n",
      "Epoch 953/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.8244 - loss: 0.4107 - val_accuracy: 0.7957 - val_loss: 0.4657\n",
      "Epoch 954/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.8243 - loss: 0.4098 - val_accuracy: 0.7955 - val_loss: 0.4612\n",
      "Epoch 955/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step - accuracy: 0.8226 - loss: 0.4131 - val_accuracy: 0.7985 - val_loss: 0.4578\n",
      "Epoch 956/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8239 - loss: 0.4107 - val_accuracy: 0.7957 - val_loss: 0.4626\n",
      "Epoch 957/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.8240 - loss: 0.4113 - val_accuracy: 0.7974 - val_loss: 0.4605\n",
      "Epoch 958/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 0.8203 - loss: 0.4156 - val_accuracy: 0.8039 - val_loss: 0.4497\n",
      "Epoch 959/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8261 - loss: 0.4087 - val_accuracy: 0.7913 - val_loss: 0.4768\n",
      "Epoch 960/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8237 - loss: 0.4121 - val_accuracy: 0.7953 - val_loss: 0.4622\n",
      "Epoch 961/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.8203 - loss: 0.4152 - val_accuracy: 0.8019 - val_loss: 0.4519\n",
      "Epoch 962/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.8246 - loss: 0.4093 - val_accuracy: 0.8003 - val_loss: 0.4590\n",
      "Epoch 963/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.8199 - loss: 0.4175 - val_accuracy: 0.7981 - val_loss: 0.4609\n",
      "Epoch 964/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8241 - loss: 0.4071 - val_accuracy: 0.7988 - val_loss: 0.4582\n",
      "Epoch 965/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.8203 - loss: 0.4070 - val_accuracy: 0.7927 - val_loss: 0.4666\n",
      "Epoch 966/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.8234 - loss: 0.4114 - val_accuracy: 0.8069 - val_loss: 0.4444\n",
      "Epoch 967/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8260 - loss: 0.4061 - val_accuracy: 0.7985 - val_loss: 0.4558\n",
      "Epoch 968/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8251 - loss: 0.4117 - val_accuracy: 0.7952 - val_loss: 0.4647\n",
      "Epoch 969/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8247 - loss: 0.4066 - val_accuracy: 0.7996 - val_loss: 0.4577\n",
      "Epoch 970/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8218 - loss: 0.4127 - val_accuracy: 0.8039 - val_loss: 0.4425\n",
      "Epoch 971/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8200 - loss: 0.4147 - val_accuracy: 0.7953 - val_loss: 0.4594\n",
      "Epoch 972/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.8264 - loss: 0.4052 - val_accuracy: 0.7932 - val_loss: 0.4689\n",
      "Epoch 973/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.8264 - loss: 0.4078 - val_accuracy: 0.7916 - val_loss: 0.4759\n",
      "Epoch 974/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.8196 - loss: 0.4146 - val_accuracy: 0.8023 - val_loss: 0.4523\n",
      "Epoch 975/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.8228 - loss: 0.4099 - val_accuracy: 0.8021 - val_loss: 0.4579\n",
      "Epoch 976/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.8239 - loss: 0.4084 - val_accuracy: 0.7945 - val_loss: 0.4697\n",
      "Epoch 977/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step - accuracy: 0.8229 - loss: 0.4092 - val_accuracy: 0.7967 - val_loss: 0.4630\n",
      "Epoch 978/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.8274 - loss: 0.4077 - val_accuracy: 0.7932 - val_loss: 0.4714\n",
      "Epoch 979/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.8256 - loss: 0.4121 - val_accuracy: 0.8001 - val_loss: 0.4595\n",
      "Epoch 980/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8256 - loss: 0.4042 - val_accuracy: 0.7940 - val_loss: 0.4674\n",
      "Epoch 981/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.8260 - loss: 0.4062 - val_accuracy: 0.8035 - val_loss: 0.4433\n",
      "Epoch 982/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.8209 - loss: 0.4123 - val_accuracy: 0.7923 - val_loss: 0.4677\n",
      "Epoch 983/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.8239 - loss: 0.4068 - val_accuracy: 0.7996 - val_loss: 0.4569\n",
      "Epoch 984/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.8247 - loss: 0.4071 - val_accuracy: 0.7949 - val_loss: 0.4654\n",
      "Epoch 985/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step - accuracy: 0.8224 - loss: 0.4123 - val_accuracy: 0.7963 - val_loss: 0.4631\n",
      "Epoch 986/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.8198 - loss: 0.4153 - val_accuracy: 0.7988 - val_loss: 0.4627\n",
      "Epoch 987/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.8224 - loss: 0.4124 - val_accuracy: 0.7920 - val_loss: 0.4700\n",
      "Epoch 988/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.8260 - loss: 0.4081 - val_accuracy: 0.7989 - val_loss: 0.4568\n",
      "Epoch 989/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.8190 - loss: 0.4165 - val_accuracy: 0.7919 - val_loss: 0.4717\n",
      "Epoch 990/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.8217 - loss: 0.4105 - val_accuracy: 0.7933 - val_loss: 0.4700\n",
      "Epoch 991/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8249 - loss: 0.4083 - val_accuracy: 0.7999 - val_loss: 0.4565\n",
      "Epoch 992/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.8237 - loss: 0.4099 - val_accuracy: 0.7943 - val_loss: 0.4654\n",
      "Epoch 993/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.8214 - loss: 0.4143 - val_accuracy: 0.7960 - val_loss: 0.4656\n",
      "Epoch 994/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8254 - loss: 0.4068 - val_accuracy: 0.8045 - val_loss: 0.4505\n",
      "Epoch 995/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - accuracy: 0.8244 - loss: 0.4072 - val_accuracy: 0.7964 - val_loss: 0.4602\n",
      "Epoch 996/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.8232 - loss: 0.4094 - val_accuracy: 0.8034 - val_loss: 0.4494\n",
      "Epoch 997/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8241 - loss: 0.4140 - val_accuracy: 0.7981 - val_loss: 0.4605\n",
      "Epoch 998/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.8238 - loss: 0.4104 - val_accuracy: 0.8022 - val_loss: 0.4533\n",
      "Epoch 999/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.8261 - loss: 0.4041 - val_accuracy: 0.7961 - val_loss: 0.4677\n",
      "Epoch 1000/1000\n",
      "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.8232 - loss: 0.4075 - val_accuracy: 0.7947 - val_loss: 0.4646\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network\n",
    "model = Sequential([\n",
    "    Dense(128, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(5, activation='softmax')  # 5 output units for the 5 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss=SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m X_val, X_test, y_val, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_temp, y_temp, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Converting data to Torch tensor\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      7\u001b[0m train_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_train\u001b[38;5;241m.\u001b[39mto_numpy(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m      8\u001b[0m val_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_val\u001b[38;5;241m.\u001b[39mto_numpy(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Splitting data to train val test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=5)\n",
    "# Converting data to Torch tensor\n",
    "train_input = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "train_label = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "val_input = torch.tensor(X_val.to_numpy(), dtype=torch.float32)\n",
    "val_label = torch.tensor(y_val.to_numpy(), dtype=torch.long)\n",
    "test_input = torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
    "test_label = torch.tensor(y_test.to_numpy(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train_input': train_input,\n",
    "    'train_label': train_label,\n",
    "    'val_input': val_input,\n",
    "    'val_label': val_label,\n",
    "    'test_input': test_input,\n",
    "    'test_label': test_label\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan import KAN\n",
    "\n",
    "kan_model = KAN([10, 7, 5], grid=10, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuctions for getting accuracy scores while training\n",
    "def train_acc():\n",
    "    preds = torch.argmax(kan_model(dataset['train_input']), dim=1)\n",
    "    return torch.mean((preds == dataset['train_label']).float())\n",
    "\n",
    "def test_acc():\n",
    "    preds = torch.argmax(kan_model(dataset['test_input']), dim=1)\n",
    "    return torch.mean((preds == dataset['test_label']).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# KAN model training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m kan_model\u001b[38;5;241m.\u001b[39mtrain({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_input\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtrain_input\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_label\u001b[39m\u001b[38;5;124m'\u001b[39m: train_label, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_input\u001b[39m\u001b[38;5;124m'\u001b[39m: val_input, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_label\u001b[39m\u001b[38;5;124m'\u001b[39m: val_label},\n\u001b[1;32m      3\u001b[0m                       metrics\u001b[38;5;241m=\u001b[39m(train_acc, test_acc),\n\u001b[1;32m      4\u001b[0m                       opt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLBFGS\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, loss_fn\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_input' is not defined"
     ]
    }
   ],
   "source": [
    "# KAN model training\n",
    "results = kan_model.train({'train_input': train_input, 'train_label': train_label, 'test_input': val_input, 'test_label': val_label},\n",
    "                      metrics=(train_acc, test_acc),\n",
    "                      opt=\"LBFGS\", steps=100, loss_fn=torch.nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ACC: 0.7963207617718174\n",
      "Val ACC: 0.7978129362494183\n",
      "Test ACC: 0.7948121437710829\n"
     ]
    }
   ],
   "source": [
    "# Predictions of train val and test datasets\n",
    "test_preds = torch.argmax(kan_model.forward(test_input).detach(),dim=1)\n",
    "test_labels = test_label\n",
    "\n",
    "train_preds = torch.argmax(kan_model.forward(train_input).detach(),dim=1)\n",
    "train_labels = train_label\n",
    "\n",
    "val_preds = torch.argmax(kan_model.forward(val_input).detach(),dim=1)\n",
    "val_labels = val_label\n",
    "\n",
    "\n",
    "# Evaluate metrics\n",
    "\n",
    "print(\"Train ACC:\", accuracy_score(train_labels.numpy(), train_preds.numpy()))\n",
    "\n",
    "print(\"Val ACC:\", accuracy_score(val_labels.numpy(), val_preds.numpy()))\n",
    "\n",
    "print(\"Test ACC:\", accuracy_score(test_labels.numpy(), test_preds.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAHUCAYAAADWedKvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACZoUlEQVR4nOzdd1iT19sH8G9CSFhhiyAI7lVntVatFhe2jmpb66gdDjq0y1pbW+v42VrX27paRxfaulq1tm7FUfcGrYoDRREQBGWHQELGef8AUiMgJAYB+/1c17liTp5x58kdfO6cJycSAAJERERERET0QKSVHQAREREREdGjgMUVERERERGRDbC4IiIiIiIisgEWV0RERERERDbA4oqIiIiIiMgGWFwRERERERHZAIsrIiIiIiIiG2BxRUREREREZAMsroiIiIiIiGyAxRURVQohRLlacHDwA+3nf//7H4QQVq0bHBxskxiquuXLlyM2NrbUx729vaHVavHbb7+VuoxSqYRarcamTZvKvd/hw4dDCIGgoKByr/P+++9DCIHz58+Xex2qXvbt21fs9Z04cSIGDBhQSRGVHcd/5W8FEZWNxRURVYoOHTqYtW3btiE3N7dY/+nTpx9oPz///DM6dOhg1bqnT5+2SQzVXWpqKjZv3oznn38e7u7uJS4zdOhQODk5ISwsrEJjGTVqFACgefPmaN++fYXui6qOzz//HM8//3xlh1FqHPxbQURFZJUdABH9N504ccLs/p07d2A0Gov138vR0RF5eXnl3k9iYiISExOtilGlUpUZz39FWFgYXnrpJbzyyitYvHhxscdHjRqF5ORkbNu2rcJiaNu2LVq3bo2tW7eiX79+CA0NxcmTJytsfw/C0jz9r3FwcIBGo6nUGKRSKWQyGfLz8x94W/xbQURFOHJFRFVW0eVBXbp0wZEjR6BWq7Fs2TIAwODBgxEeHo6kpCTk5ubi4sWLmDVrFpycnMy2UdJlgbGxsdiyZQueeeYZREZGIjc3F5cuXcLIkSPNlivpUp/ly5dDpVKhfv362LZtG1QqFeLj4/HNN99ALpebre/v74/169cjOzsbGRkZWLVqFdq1awchBIYPH37f5+7t7Y3FixfjwoULUKlUSElJwd69e9G5c2ez5YKCgiCEwPjx4zFu3Dhcv34dKpUKR48exZNPPllsu8OHD8fly5eh0Whw8eJFvPbaa/eNo0h4eDgSEhKKHSMAaNKkCTp06IAVK1bAYDCgZ8+e2LhxIxISEpCXl4erV6/i+++/h5eXV7n2VZrQ0FAAwGeffYYjR45g6NChcHR0LLZcrVq18MMPPyA+Ph5arRaJiYlYv349fHx8TMu4ubnhm2++wbVr16DRaJCSkoJt27ahcePGAEq/zKvoeN/9+hXlRPPmzREeHo7s7Gzs3bsXACw6Fo0bN8aaNWuQnJwMjUaDuLg4/Prrr5DL5QgKCoJOp8Nnn31WbL0uXbpACIGXXnrpvsevdu3aWLlyJVJSUkyv/0cffQSJRAIAkMlkSElJwYoVK4qt6+bmhtzcXMydO9fUp1Qq8fXXX+P69evQarW4efMm5s+fX+w9KITAd999h7fffhsXL16EVqstM//vXd/FxQUjRowwXS68b98+0+M1a9bE999/j4SEBGi1Wly/fh1Tp06FnZ2daZmi1+2TTz7BpEmTTDF369YNCoUC33zzDc6cOYPMzEykpaXh6NGj6N+/f7njKC1fnnvuORw9ehRqtRrZ2dnYtWtXsZH0or9RzZo1w5o1a5CZmYnk5GSEhYXB1dXVbNmXXnoJx48fR2ZmJtRqNa5du1bho8VEZBmOXBFRlebn54dVq1bh//7v//D555/DaDQCABo2bIjt27djwYIFUKvVaNKkCT799FO0b98ePXr0KHO7rVq1wty5czF79mykpKTgjTfewLJlyxATE4NDhw7dd117e3ts3rwZYWFhmDt3Lp5++mlMmTIFWVlZmD59OgDAyckJ+/btg6enJz799FPExMTg2Wefxdq1a8v1vD09PQEAX3zxBZKTk+Hi4oIXXngB+/fvR48ePXDgwAGz5d99911cvnwZH374IQBg+vTp2L59O+rWrYvs7GwABYXVL7/8go0bN2L8+PFwc3PDtGnToFAoTMe1NEII/PLLL5gyZQpatmyJc+fOmR4rKriKCt/69evj2LFj+Pnnn5GVlYU6dergo48+wuHDh9GiRQvo9fpyHYO7OTg44OWXX8bJkydx4cIFLFu2DGFhYRg0aJBZMVCrVi2cOnUK9vb2mDlzJs6dOwcvLy8888wz8PDwwO3bt+Hi4oLDhw+jTp06mDNnDk6cOAEXFxc8/fTT8PPzQ3R0tMXxyeVybN68GT/88ANmz54NmUxm0bFo2bIlDh8+jNTUVEydOhVXr16Fn58f+vfvD7lcjri4OGzevBmjR4/G//3f/5m9Xu+99x4SExPx119/lRqft7c3jh49CrlcjilTpuDGjRvo168f5s6di/r16+Pdd9+FXq/HqlWrMHr0aLz77rtQqVSm9V9++WU4Ojpi+fLlAApG5g4cOICAgADTcX7sscfw5ZdfokWLFujZs6fZ/p9//nl06dIFX375JZKTk3H79u1yH9sOHTrg77//xr59+0zvr6KcrlmzJk6ePAmj0Ygvv/wS165dQ8eOHTF58mTUqVPHdBlpkQ8++ABXrlzBxx9/jOzsbFy9ehUKhQKenp745ptvkJiYCLlcjp49e+LPP//EyJEjsXLlyjLjKMnLL7+MNWvWIDw8HC+//DIUCgUmTJhgeg8fOXLEbPkNGzZg7dq1CAsLQ4sWLTBr1iwA/36o0KFDB6xduxZr167FtGnToNFoEBQUhO7du5f7WBLRwyHY2NjYKrstX75cqFQqs759+/YJIYTo1q1bmevb2dmJLl26CCGEaNGihan/f//7nxAFQ1emFhsbK3Jzc0Xt2rVNfQqFQqSmpoqlS5ea+oKDg4UQQgQHB5vFKYQQL730ktk2t27dKi5dumS6P2bMGCGEEM8884zZckuXLhVCCDF8+HCLjo9UKhV2dnZi9+7dYsOGDab+oKAgIYQQZ8+eFVKp1NTfrl07IYQQQ4YMEQCERCIRN2/eFBEREWbbDQwMFFqtVsTGxpYZQ506dYTBYBALFiwwO+5JSUni0KFD931tateuLYQQ4rnnnjP1Dx8+XAghRFBQUJn7fvXVV4UQQrz11lsCgHB2dhbZ2dniwIEDZsv9/PPPQqvViiZNmpS6rcmTJwshhOjRo0epy5T02t99vO9+/YpyYsSIEeXK05KOxZ49e0R6errw9vYuM6YBAwaY+vz8/ER+fr6YMmXKffc7c+ZMIYQQTzzxhFn/4sWLhcFgEA0bNhQARPPmzYUQQrzxxhtmyx0/flycOnXKdP/TTz8Ver1etG3b1my5F198UQghxLPPPmvqE0KIjIwM4e7uXq5c37dvnzh//rxZn0qlEsuXLy+27NKlS0V2drbZexmA+Oijj4QQQjRt2tTsdbt69aqQyWTleq/99NNPIjIyslxx3JsvRe+3s2fPColEYlrO2dlZJCcni8OHD5v6iv5Gffzxx2bbXLRokcjNzS32nFxdXct1HNnY2Cqn8bJAIqrS0tPTzS4BKlK3bl2sXr0at27dgsFggF6vx8GDBwEATZs2LXO7//zzDxISEkz3tVotrly5Uq6Z64xGI7Zs2WLWd+7cObN1g4ODkZ2djfDwcLPl7jfj3r3efvttREZGIi8vz/Qce/bsWeLz27Ztm9loRtHIUlFMjRs3hr+/P9asWWO2Xnx8PI4ePVqueG7cuIF9+/bhlVdegb29PQCgd+/e8PPzM41aAUCNGjWwdOlSxMfHQ6/XQ6/XIz4+HkD5XpuShIaGIjc3F7///jsAQK1WY/369Xj66afRoEED03K9e/fGvn37cPny5VK31bt3b0RHR5su3bOVDRs2FOsrz7FwdHREcHAw1q1bh9TU1FK3f+DAAfzzzz949913TX2jR4+GEAI//vjjfWPr3r07Lly4gFOnTpn1//LLL5BKpabRj6ioKERERJhd/tmkSRM8+eSTZq9xv379EBUVhX/++Qd2dnamFh4eDqPRiK5du5rt5++//0ZmZuZ9Y7RGv379sG/fPiQlJZnFsWPHDgAodpne5s2bSxw5femll3D48GGoVCrTe+2NN96wOl+L3m8rV640uyxZrVZjw4YN6NChQ7FLWjdv3mx2/9y5c3B0dDRdzlr02q1btw6DBg1CrVq1rIqNiCoWiysiqtJu3bpVrM/Z2RmHDh3Ck08+icmTJ6Nr165o164dXnjhBQAo8Xs490pLSyvWp9Vqy7Vubm4utFrtfdf18vJCSkpKsXVL6ivJuHHj8P333+PEiRMYOHAgnnzySbRr1w47duwoMcZ7n0/Rl/SLli36jk9ycnKxdUvqK01YWBi8vb1N30cZOXIkVCoV1q1bBwCQSCTYtWsXXnzxRfzf//0fevTogSeeeML0/a/yHN971a9fH08//TS2bdsGiUQCNzc3uLm54Y8//gAAs0u/atSogZs3b953e+VZxlJqtdrsMjqg/MfCw8MDMpmsXDF9++236NGjBxo1agSZTIY333wTf/zxR5l55eXlVeJ7KSkpyfR4kWXLlqFTp06m75+NHDkSGo3G7IOBmjVrolWrVqaCsajl5ORAKpXC29vbbD8l7dsWatasif79+xeL4+LFiwBQrjheeOEFrF+/HomJiXj11VfRoUMHtGvXDmFhYVblK/Dv8SztmNvZ2cHDw8Os/973cNHfmKIYDh06hAEDBkAmk2HFihVITEzE+fPnMXToUKtiJKKKwe9cEVGVVtJvVHXv3h3+/v4IDg42jVYBKHWa8MqQlpZW4lThvr6+5Vr/1Vdfxb59+/DOO++Y9SuVSqvjKW3/5Y0JAP7880+kp6dj1KhROHDgAPr164cVK1ZArVYDKJgivXXr1hg+fLjZd6Hq169vVdxAQfEklUoxaNAgDBo0qNjjw4cPx+TJk2E0GnHnzh0EBATcd3vlWaZoJjuFQmHWf+/JepGS8rS8xyI9PR16vb7MmABgzZo1mDNnDt59910cP34cfn5+Jc7eeK+0tDT4+fkV6y8a/bh7xOy3337DvHnzMGLECEyaNAmvvfYaNm7caDbylJqairy8vGLfabr78btZ+1tzZUlNTcW5c+cwadKkEh8vKh7vF8err76K69evY8iQIWb99772lih6v5V2zA0GAzIyMize7ubNm7F582bI5XJ06NABEydOxG+//YYbN27g+PHjVsdLRLbDkSsiqnaKTpDuHT16++23KyOcEh04cACurq549tlnzfrL+ymzEKLY82vRogU6duxoVTzR0dFISkrCyy+/bNYfGBiITp06lXs7Wq0Wa9asQa9evfDpp59CLpebXS5m69dGKpVi+PDhiImJQdeuXYu1b775BrVq1ULv3r0BADt27EC3bt3QqFGjUre5Y8cONG7cGN26dSt1mRs3bgAomGjibvfOIHc/5T0WGo0GBw4cwKBBg8qcUVGr1eLHH3/E8OHD8dFHH+HMmTPluqxz7969eOyxx9CmTRuz/tdffx1Go9Hs0tvMzExs3LgRr7/+Ovr161fssk8A2Lp1K+rXr4+0tDRERkYWa3FxcWXGZInSRpW3bt2K5s2b49q1ayXGUZ4RMyFEsenYa9asWeKPBZd3dDs6Oho3b97EsGHDzPqdnJwwcOBAHDt27IGm6s/Pz8fBgwfx6aefAkCx15WIKg9Hroio2jl69CjS09Px/fff44svvoBOp8Mrr7yCVq1aVXZoJr/++ivGjRuHVatWYfLkyYiJiUHv3r3xzDPPAECZs/Nt3boVU6ZMwbRp03DgwAE0btwYU6dORWxsrGkmOksIITBlyhSEhYXhr7/+wk8//QR3d3dMmzbNossCgYJLA9977z189NFHuHTpEo4dO2Z67PLly4iJicHs2bMhkUiQnp6O5557DiEhIRbHDBR8P8rf3x8TJkwoNkMiUPAdoffeew+hoaHYtm0bpk6dit69e+PgwYOYOXMmzp8/D3d3dzz77LOYN28eoqOjsWDBAgwZMgSbNm3C7NmzcfLkSdP3nrZu3Yr9+/cjJSUFu3fvxsSJE5GRkYG4uDj06NEDL774Yrljt+RYFM0geOLECcyePRsxMTGmS97efvtt5OTkmJZdsmQJJkyYgHbt2plmkivL/Pnz8frrr5uOUVxcHPr27Yt33nkHS5cuxdWrV82WX7ZsGYYOHYpFixYhISEBe/bsMXt8wYIFGDhwIA4ePIj58+fj3LlzkEqlCAwMRK9evTB37lyb/gbZ+fPn0bVrV/Tr1w+3bt2CSqXClStXMHXqVISEhODo0aP49ttvER0dDQcHB9SpUwd9+vTB6NGjy/ydu61bt2LgwIFYvHgx/vjjD9SuXRtTpkzBrVu3io0UlxbHvYQQmDBhAtasWYOtW7fihx9+gEKhwCeffAJ3d/cSp9QvyxdffIGAgADs3bsXN2/ehLu7O8aOHYv8/PwS3xtEVHkqfVYNNjY2ttJmC7x31rCi1qFDB3HkyBGRk5MjUlJSxI8//ihat25dbCa30mYL3LJlS7Ft7tu3T+zbt890v7TZAu+Ns7T9BAQEiD/++ENkZ2eLrKwssX79evHss88WmymupGZvby/+7//+TyQkJIjc3FwREREh+vfvL5YvX242s1/RLGjjx48vtg0hhPjf//5n1jdq1CgRHR0tNBqNuHz5shgxYkSxbZanRUZGljjDGQDRpEkTER4eLrKyskRaWppYu3atCAgIKBZPeWYL/PPPP4VGo7nvLHpr1qwR+fn5wsfHRwAQ/v7+4ueffxZJSUlCq9WKmzdvit9//13UqFHDtI6bm5uYP3++uHHjhtBqtSI5OVls2bJFNGrUyLRMzZo1xbp160RqaqrIyMgQK1asEI8//niJswWWlBOWHIuiZdeuXSvu3LkjNBqNuHHjhli2bJmQy+XFtvv333+L1NRU4eDgUO7XrHbt2mLVqlXizp07QqvVikuXLonx48ebzWZX1CQSiYiLixNCCDF9+vQSt+fk5CS+/PJLcenSJaHRaERGRoY4e/asmDt3rum1KMrD7777rtxxlvS+b9mypTh06JDIyckRQgiz96mXl5dYsGCBuHbtmtBqtSI1NVWcOnVKTJ8+XTg5OZX5PgEgJkyYIK5fvy7y8vLEhQsXRGhoaInv6dLiKG12yf79+4tjx46J3NxcoVKpxO7du0XHjh1L/Nvh5eVl1n/v+6NPnz5i27ZtIiEhQWg0GpGcnCy2bt0qnnrqKYveu2xsbBXbJIX/ICKih2DixIn46quvEBgYWOYn6kQlqVGjBuLi4vDdd9+ZLgsjIqKqgZcFEhFVkKIpsy9fvgx7e3t0794dH3zwAVatWsXCiizm7++PevXq4ZNPPoHRaMTChQsrOyQiIroHiysiogqSm5uLcePGoU6dOlAoFIiPj8ecOXPw1VdfVXZoVA298cYbmDp1Km7cuIFXXnml2Ex4RERU+XhZIBERERERkQ1wKnYiIiIiIiIbYHFFRERERERkAyyuiIiIiIiIbIATWpSiVq1aUKlUlR0GERERERFVMqVSWa6JhFhclaBWrVqcJpmIiIiIiEz8/f3LLLBYXJWgaMTK39+/SoxeKZVKJCYmVpl4qHpg3pA1mDdkLeYOWYN5Q9Z42HlTtL/y7IvF1X2oVKoq9UavavFQ9cC8IWswb8hazB2yBvOGrFEV84YTWhAREREREdkAiysiIiIiIiIbqPTiasyYMbh+/Try8vIQERGBzp0733f5YcOG4Z9//oFarUZSUhKWLVsGT09Ps2VefPFFXLhwARqNBhcuXMDzzz9fgc+AiIiIiIiokourwYMHY8GCBZgxYwbatGmDQ4cOYceOHahdu3aJyz/11FNYsWIFwsLC8Nhjj2HQoEF44okn8PPPP5uW6dChA9auXYuVK1eiVatWWLlyJdatW4f27ds/rKdFRERERET/UaKy2vHjx8WSJUvM+i5evChmzpxZ4vLjx48XMTExZn3vvfeeiI+PN93//fffxfbt282W2bFjh1izZk2541IqlUIIIZRKZaUdm6ocD1v1aMwbNmsa84bN2sbcYbOmMW/YrGkPO28s2V+lzRZob2+Ptm3bYvbs2Wb9u3btQqdOnUpc5+jRo5gxYwZ69+6NHTt2wMfHBy+99BK2bdtmWqZjx46YP3++2Xrh4eH48MMPS41FLpdDoVCY7iuVSrPbylbV4qHqgXlD1mDekLWYO2QN5g1Z42HnjSX7qbTiytvbGzKZDCkpKWb9KSkp8PX1LXGdY8eO4ZVXXsHatWvh4OAAe3t7bNq0Ce+//75pGV9fX4u2CQATJ07EtGnTivVXtR8SrmrxUPXAvCFrMG/IWswdsgbzhqxRFfOm0n/nSghhdl8ikRTrK9K0aVN8++23+PLLLxEeHg4/Pz98/fXX+P777/HGG29YtU0AmDVrFubNm2e6X9V+0K6qxUPVA/OGrMG8IWsxd8gazBuyRmX9iHB5VFpxlZqaCr1eX2xEycfHp9jIU5GJEyfiyJEj+OabbwAA58+fh1qtxuHDhzF58mQkJycjOTnZom0CQH5+PvLz84v1V7UfJqtq8VD1wLwhazBvyFrMHbIG84asURXzptJmC9TpdIiMjERISIhZf0hICI4ePVriOk5OTjAajWZ9BoMBQMHoFFBw6eC92+zVq1ep2yQiIiIiIrKVSpvpY/DgwUKr1YqRI0eKJk2aiHnz5gmVSiUCAwMFADFz5kzx66+/mpYfPny4yM/PF6NHjxZ169YVnTp1EidPnhTHjx83LdOxY0eh0+nEhAkTROPGjcWECRNEfn6+aN++fZWdgaS6xcNWPRrzhs2axrxhs7Yxd9isacwbNmtaVZ4tEJV9cMaMGSNiY2OFRqMRERERokuXLqbHli9fLvbt22e2/HvvvSeioqKEWq0WiYmJYuXKlaJWrVpmywwcOFBcunRJaLVacfHiRfHCCy9U6ResusXDVj0a84bNmsa8YbO2MXfYrGnMGzZrWlUuriSF/6C7KJVKZGdnw9XVtUpcx1nV4qHqgXlD1mDekLWYO2QN5g1Z42HnjSX7q/TZAun+Apo1Qd0WzXBdlYFaTRvhdkIicjIyoNNozZZzULqgRmBt1KhTGzWCAuEdVBte/rWQlpiEy4eOIfroCeSkZ1TSsyAiIiIievSxuKriWoZ0Q483XsfGuGi8FbbI1K/NzUVOegbysnPgVrMGlF6eJa4f1Ko5Hu/TC0ajETcvXsblw8dx+fAxxJ+/CHHP5CAVrawp8R8mmUIBe4UcWnUujIWTojwoO5kMssJtPii5owNq1qsL3wZ14Rngj4ykZNy8eBnJ167DqH+weO1kMvR443XUrF8X6sws5GZlF9xmZkGdVXBfq86FMBphNBggjAJGowHCYIRRCOi1WuRlq2zyWjq7u6Fx5w6o06oFDDo98lQq5KlyoFGpkJtd8O+8bBW0ajW06lxoctQw6PVW708qs4PSyxNKLy9oc3Nx50b8Az8HmVwOVx9vuPnUgJOrEnmqHNPxzM3KfqB4S+Ps4Y7m3Z/GY8GdYe/oYDo22tzCW3UutGo1su+k4nZsHFLjb5Y7DhdPD6Rr8+Ds4Y5cjQYGna7UZSVSKZzcXOHi6QEXD3c4KF2g1+YjPy8P+XkaaAtvdRoNtLm5D5y7REREVR2LqyouNf4mrh47hae6dcXVG7Fw8nCDvUIBhZMTFE5OZstm3b6DO3EJSI1LwJ24BGTcSkatxg3RtHNH+DdthMDmzRDYvBl6jR6F3KxsJEVfRU56RkHLyEROWgZy0tORk5GJ27FxUGdkWhWzg4szfOvXQ80GdeFbvx58G9RFzfp14eZTA+rMrML9ZRTuLwPqjEzkZmUDKDhZk0qlkNhJIZFIIbWTQhgFrp/+Bzf+Of9ABaGD0gWPde2CliFd0bjTk7BXKAAA+XkaaIpO3k0n8TnIy85BnkoFjSoHudkqaApP/CVSKdx9a8LDrybcfYuaD5TeXpBKpchMuY1bV2Jw60oMkq5cw60rMbh9I87sxFLh7ARndzc4ubnB2d0NLl6e8K1fBzULj5dXgH+Jz0Gn1SIpOgY3L17GzYvRSLhwCclXr5W70FE4OWH4/Jlo3OlJq48jABj0etNrqU7PNOWNKjUdaTcTkZaQiNSERORlZxdb169RfTTt8hSaBT+FoJaPQWpnZ9G+9fn50OSoTa+VTqOFTquFPj8fOm0+9Pn50GvzodNqoXBygmsNLyi9vaD08oSLp4fZttQZmbjxz3nEnjmL2DPnkXDhUrFiwtHVFd61/eFV2Dxr+cGtZg24+RQ0Zw/3+8aryVEXFFvZ2dAXxloUp06rLShGNBqkJ97C7dg43L5+A5nJKcVeU6W3F1r0CEbLkG6o364N/FyMeNpXjTSNDAeSnWEQklJjMOj1SEtIxO3YG7gdG4eU63HQabXwrOULT/9a8PD3g2etgmbvoMAvV8/ik23rAAA6jRZ5hcWuRpUDvU5XkLOeHnB2d7Po9cvP0yAvW2UqooveX3mqHOi0Whj1ehj0Buh1uoJ/6/Qw6HXQabTIz9MgX6MpuM3LK2xa2CvkcHJ3g7Oba8Ft4fvKyc0V9gp5qbEIIQq3r4dBp7vr1vBvDuXnQ6/VFt4W5pdWWxhHHvJzC28L44IQcPZwh5tPDbj61DDLExdPD+Tn5Zl9mJGblW36QANCwE4mg529/V23drCTyaDN0yA3K8u0Xp4qx6YfjkkkEkik0oK/v3YFkwjrtflV5sMwIqLqhN+5KkFVu/733ngUzk5w8fSEi6c7nNzckH3nDlLjbkKbW/qIidLbC02eehJNOndEo07t4eTqet99Go1G3DhzDuf/PoCovw8i/WZSqct6BwagYYcn0PDJdghq+RjcfWta/VzvJzs1Def37Me53ftwPfKfco04Obu74bFuT6NlSFc07PAEZPb2FRJbWfQ6HTKSkqFwdoKTm2u54lClpSM55jrSEhLhVdsfAU0bw9FVWWy5+PMX8dukL3E7Ns6s/968cfZwxxtL5iKweTNoc3Pxd9hK2MlkZiemBf92g9zRAVI7u4KTLjsppFI7SKQSSKV2sLMv/2cyudnZBYVW/E3k52nQqOMT8PAz/x26xMtXcOXoSRgMBji5KuGodIGDqxJOSiUcXQuawskJckeHcu/3fgw6PXLSMwpOvh0UZo/p8/OREHUJWXdS4RVQC161/ct8rwAFBUjW7TvIzc6Go4sLnNzd4OiqhFRq3a9daHPzcOdGPG7fiENGUjLqtmmJOm1aQiqVQgqBJ31y8YR3LuykBQXVldg0TFtyFBl5Ag7OzlA4O8HBxRkefr7wqRsEBxfncu/baDDAwV4OrV4HSTnjV2dmQZ2RibxsFWQKOeQODpA7OkLuWHBrSc5UZ0aDweIPC6zaj9EITeEIqU6jKXU5iVQKmb09pDJZ4a2d6b6dvQwSiQR2stJfm7s/sCj6IECv0wGlFF1SqRTNW7RA1PnzxX42hag0zBsqy/dvvA91ZpZZX1X+zhWLqxJU9eIKAJydHdCqVV00bVobN2+mIjIyBqmpxUcJSiK1s0PAY03g5V8Lzh7ucPHygIuHh+nSHqW3F7wDA8zWSYq+ivN7D+D83gPISUtHgyfboVGHJ9CwQzvTybKnQo8aDnrcyJEjJSkVKTHXkXwtFslXryP52nVk3EqBk6uy4BNvTw8oPQv26ezhDic3V0AIGI3Gfy9DK7x1cHZG46eeNDvJzUnPQNTfB3H+7wPIz80zbUfp6QEXL084e7jDvaYPajdvanbycOvqNZzfsx9nd+/Dndg400mowtnp35NSZ2coXJzhWHRyr3T591apBCRAZvJtZN5KQcat5IJ/Jycj41YKDDodfOvXg1+jBvBrVB+1GjWAX6MGJZ7c6jTagk+tM7OgzsjC7RtxSC48Zikx14v9IZFIJPAM8EftZo0R0KwJAh5rgsAWj0Hh5AidRottC5fi8Op1pk+b784bmdIZb/+wEDXqBEKdkYmf3hmPhKiL5cqXe9nJZAV5U/j6uXi6Fxb7HnCt4W0a5XGt4V3i+vl5Glw9EYGLB4/g8sGjyEy5Xa79Su3soHAuGLG9+zWzd1BAJpfDXiGHTK6ATCGHfeFln/l5echOTYcqNbXwNg25mVkQhaME/k0boU6blqjbphXqtmlZeHmtgBSAEf+OBGXdvoO0hESk3UxE+s0kZKbcQdbtwpZyp8QROolUCkeli2k0xdFVCXu5vOCSVLncFKdMIYeDsxO8agfAp24QatQJLLX41sRewsAWdmhUp+Ay4L/+OobOnZuhRg03pKerMOzlr7Fr15li67n61EDNukHwqVcHPnWDULNuHcjk9khPuoX0xIKWkXQLaYlJMOTkIjMjA27u7sg3Gkx5X/AeUEImt4c6I9M0+qzOyirzcj+pzM70ujm5usKhcJtOrko4uLqYtmsnk5mN3hQVA/YKxb/FmtO/RZvc0QE6jRa5Wdn/jghl/Xup673fTTV7fSQS2NnfNVIks/v333J7yOwLcqroNZIp5LCXK2DvoIDc0QH2Dg6mOO4uoo1GI3LS0s3yI+v2HeSkpUPu6HjX6Jqr2SgbgLtG0ApH1AqbwsnRtJyj0uW+x5qI6FEzrWtfqNLSzfpYXFUzVa24qlXLBzcTL2LixHfw2GMBePzx+mjSJKDYp+IJCXcQGXkNZ05fQ2RkDE6fvobkZOsmsXCv6YPHuj+NFt2DUa9d6zI+3dQiKD8Oz7d1g9zeDvn5eoSHn8ba3w9i8+aTyMnJK3N/dnZSGAylf2JlJ5OhwZPt0LJnV7ToEVzmpVh3S7x0Bef27MO53fuKje5YqujHqi29XMajli88avkhL1tVeHlPNvTa0k/8ysvd1weD/jcRTTp3AADEnIzE75O/QsatZFMeN2zTCsPmfgU3nxpIT7qFH9/+8L7fNWrduh5q1/bG2bOxiI+/Y3VsckcHeAb4FxRbAf5wcndD7JmziDl5utzPXS6XoU+fdpDLZVCp8pCToym8zYNKVdD09zmxz8+37PtOPfo+hR+XvoWa3kr8teMcFi3ehjPHzhdc8vWQSO3s4BlQy1QMeQX443bsDTxVR4Ypn78IBwc50tKy8c6YpVi//jACAryx/o/P8OSTjWE0GjF1ymrMmrXe6ku6qsLfP39/Lzz+eH20bdsAzVsEIS01G6dPX0Nk5DWcP38DWm3p3wMr8jC/4ymTyyF3dICdvT3UmZkV+t0yqcyuoDBzKxhplsnvc+mj0VhywabTwag3wGg0/vtBlsEIYTTAaDBCIpFAJrcvKCrlisIPLgo/wFAoSt2fk6MjNm3ejAH9+yM3r+y/+0QA84bKdj3yn2KX7LO4qmaqwslFkYUL38L7HzxX4mOJiWm4eDEegYE10LhxQInLXLmSiG1bT2Hr1lM4fPgidDrLv1zv5OaKx7p2RvMewWjc8UnYye2RePkKYo5HIOXCeUx6Lxj9n2tvisnf38u0bl6eFlu3nsLa3w9h796zqFXLE40a+aNRo1po1MgfDRrWQqNGteDn5wmdTm92Aq1S5SInR4OsrFxcuhiP06ev4fTpa7iZmI767dqgRc+uaPzUkxAGI3LSM6Aq/P6WJisTSpkOHo4SXPnnMg7tPlmuk7GaNd0RHNwcTz/dHEF1fODi4gil0hEuLg5QKov+7Yjs7Fzs2nUG27aewo4dkbh9O9PiY3oviUQCLy8latXyhJ+fJ/z8PFCrlhf8/DzgU9Mdbm7OJcaiUNjj8uWbOHM1E6JBO9wxOCM3Jxcb58zH5b0HceHWTaw8fwoOLs64dfUafhw9Dtm3Sy6YnnqqGaZMHYpevdqY+lILT2pPFxbrp09fw/XryQ/8fMtzPIYNC8b0r15FnTrWX2Z67lwsJk9aia1bT913OZnMDpMmDcakyUMgk/17WZfRaMSmTScwf95GHD5c9kifXC5DvXq+Jea4t7crNm8+ifnzNuLYscvlfg6BgTWw/JcP0a1bSwDA9u0RePON73Dr1r+f4snlMnz77dt46+1nAQAbNx7HiOHzkZ1t+eQqpf39c3FxxIgRPdDl6cdKvdxRCIGcHA3UhcXv3cVwTo6m1Et+5HJ7PPZYIB5vWx+PP14fPj7upcan0+lx8WKCKSe1Wp3pfeN71/umZk136HQGXL2ahCtXEhFzNQlXrhT8+8qVJKhUufD19TB7zxXdOjopkJKciVu30nHrVgaSktJw61YGbt1KR2amutzH0sFBbtqut7crMjJyTNtUqx9ewf6wVKX/O6n6YN6QNVhcVTNV6Y0+YcJAzJ4zAoAjtmw5iJMnLptOclNSMk3LKZWOaN26Hh5/vD4eb9ugcHTLH3Z3Xf+fnZ2L8PDTpqIgLU0FHx+3YicWfn6eSEnJwPr1R3DpUoJZPPYOCtjJZNDkqNGpU1Os+e0TBAbWgFarwycfL8OiRVvRtGltDBnSBUNffhqNGpU8McODKDrhP3P6Gs6ejYWHhwsaNaqFho380bBhLdStW9PsBFmvN+DChXjTyVhkZAzOnr0BDw9nBAe3QHBwcwR3bV5qgVqWEyeisX1bBLZuPYUzZ67B1dXJ7FgWnLx5oIaPu1mBdHfx5urqZBaztfLyjUjIc0CsSo4DR67At3krGITA9ch/sOyDCcjLLp7PwcHNMWXqUHTv3gpAwclrdHQiGjf2h30J35XRaPJNo0b3jiLl5mpL+zoG8rU6HDwYhZ07TyM9vfT3Va9ebTB7zgi0bl0PAJCUlIbo6ESzY1Z03Mr7naaDB6Pw6YRfcOJEdLHHmjQJwIqVH6Fdu4YAgN9+O4DffzuI0WP6oHfvtqblIiKuYsH8Tdiw4Sj8/DwLcq5hQQHVsLCQCgqqYfaeK82JE9GmbZU08lajhht6926Lvv2eQJ8+7eDs7ICcnDyM/ygMP/0UXup2R40KwaLFo+HgIEd09E38b+pqyGR2ZgV50bFLT8/Bjh2ROHr0klkM9/79q127Bt5/vx/eeLMX3N0fziVppvfs6Ws4dzYWNWq44fG2BSNZNWq4PZQYSqPV6orlfVERmZ+vg4+Pu+m97+FR+vHKzs41FVrJyRnQaEr/AEiryS/cR+5dBWvB/fuNzioU9sU+JCq6L1eU/r1PYTQWGyUuup+bqy21SHZycsKff/2JF194Ebn3+Q4w0d2YN1SW/fvPF/tbx+KqmqlKxZWnpxKurkrExiZaHI9S6YiQkDaFJ2htUbPmvzOlGY3Ggu+dlHEiePZsLNb+fhBr1x5CbGwKgIJRhc8+ewlffPkKZDI7XL2ahKFD/g9nzlwrtn6bNvUxdGgXDBn6NAIDayArS2369PjqlURcvXoLV64kIi7uttmJwN0nA15ermjVqg7aPF4fzZsHlXjCf6+cnDxcv54MPz/PEk/GjEZjsRNzo9GIs2djcfBAFM6fj0N2dm6xUTSVKg9BQT7o27cd+vZ7wnRCXkSn05crvtLcvp1Z+El5OpILT7yKPi0v6eRKp9Pjqaeaom+/9ujTp63ZJ/5CABn5dki4lYW9f/2N6Evxpk/tb91KR48erTBl6lA8/XRzAEB+vg7Ll+3B7Nl/IC7uNuRyGVq0qGO6PKvN4/XRsmUdKO5zUlYeBoMBx45FY9vWU9i27RSiogou1Xz88fqYPWcEevZsDQDIylJjzuw/sHDhFuTllXwZoZOTAnZ2JRdYTk4KjB3bH2M/7A9Hx4JLmTZsOIpJn6/AlSuJkEgkeP/9fpg1ezgcHRVIT1fh3XeWYu3aQ6ZtNG1aG2PH9sdrr3czbaMs2dm5ptGSq0W5fjUJBoMRY8b0wSuvdoWDQ8GlXPHxd7Douy34+eddqFOnJvr1ewJ9+rZD+/aNzPLzyJGLGP76/HKNGrZt2wAb/vwcgYE1yhVvZmYOdu4s+NBl587TyM8XyM7ORrfubfDWWyF46aWnTIV/dPRNLF+2B1lZJY/e2NlJ4ex8z4cHhe9lFxdHSEqZ0NBoFIi5mmT68OP8+ThoNPklLhsQ4G3KydZtCgrwW0nppkLl7lsHB7lpBLFhw1p3FcE+AAoKpX9Hp/59z+XmauHr6w6/wlGwog9LPD2LTyhTlrw8LW7dykBqajbc3Z1Rq5YnXFwcLd4OEdF/lZ/va2YDCgCLq2qnKhVXtopHIpGgXbsG6NevPfr0bYe2bRsAKDjRvX07C0lJhZ+g3kpHcnIGWraqi2effRxy+b8n0idORGPd2kN4tndbhIQUXDq2atU+vDNmaZnfq5JIJHBzc7LokpqSKBT2aN48yHRy9VjzQKSlqUwnsXcXD0X8/b3QtnA0r2BUrx5q1fKCwWDA6dPXcfBAFA4cOI/Dhy9aHJ+vrwf69CkotEJCWptOmrKy1IXHtOi4ZiAlJQPZ2XklfhqsUuXi9u2s+35/qCwSiQRPPNEQ/fo9gQEvPoUWj9Uuddm8PK2pWNBqdfj5p3DMmbMBN2+m3ncf9vYy+Pl5lDgSolQ6wsmp9AKkRg03PPPs42jZsq5Zf1zcbURHJ5ouR9RqdViyeBtmzlyPtLTyTdJyP/7+Xvjii2EYPqIH7OzsoNcbsCxsNxo09DON1u3cGYk3Qr9FUlJ6idvw8nLF6NHP4p13+8LPzxNarQ4xMbeKfUhw9WpSmd9zrFHDDWPG9MaYd/qYPvAoqdiPjIwxFaARETEWfX/I29sVX38zCo0a+ZvlWs5dl+g1aFgLffq0g7f3vxPFGAwGnDoVgw4dOgD493ns2fMPFszfhB07Ih+J6bkdHORwdJQjIyPH4vVq1HArdnlu0XvAwUGOO3eyzAq2kgpRFxdHs5HtmjXdYW9f8gddEokEDg5y0z5c7tlvaesBgE5nMBtlVt812qbV6kp9LWUyO7i43DXaddf+nJ1Lf4/bSe3QslVLnDt7DgYjf9OMyod5Q2XpFTK12PkAi6tq5lEsru7l7e0KmcwOt29nlXqJh4eHC154oSOGDO2C7t1bmo1yqdUavP/e9/jll702iedh8/FxR16eFiqV7b48K5fL4Ofnidu3s0odaXmY6tcPwNWYM/ho3FsIDPQyfWpfdNlkXp4WP/6wE19//WepRUVFqF27hmnkr3v3lqYiz2g0YvXqA5g6ZRXi4so3g6AlmjULxMxZr6N//39/40ut1uDj8WH44Yed5dqGTGYHHx83JCdnPvCUwQqFPYYNC8aH4wagRYs6yMnJw+7d/2D7tghs3x5h9gFBRZFKpWjfvqHpQ5eiSzGBgiJ3zZoDWLhgE86du1HhsVD1V9X+76TqgXlD1qjKxRVQUFyx3dWUSqUQQgilUlnpsVSVeHx83MU77/QR+w/MEgcOzhZNmgRU+nFhu38rLW9kMjvRoIGfcHd3rvQYHR0Vom/fJ8TEiYNEq1Z1H8o+O3duJnbv+UrsDP9SNGjgV+nHAICoW7emUCjsKz2OgABv8cEHA4RRXBP16/M9zmZZqwr/V7FVv8a8YbOmPey8sWR/HLkqQVX7FKWqxUPVA/OGrMG8IWsxd8gazBuyRlUeuSrfVFtERERERER0XyyuiIiIiIiIbIDFFRERERERkQ2wuCIiIiIiIrIBFldEREREREQ2wOKKiIiIiIjIBlhcERERERER2QCLKyIiIiIiIhtgcUVERERERGQDLK6IiIiIiIhsgMUVERERERGRDbC4IiIiIiIisgEWV0RERERERDbA4oqIiIiIiMgGWFwRERERERHZAIsrIiIiIiIiG2BxRUREREREZAMsroiIiIiIiGyAxRUREREREZENsLgiIiIiIiKyARZXRERERERENsDiioiIiIiIyAZYXBEREREREdkAiysiIiIiIiIbYHFFRERERERkAyyuiIiIiIiIbIDFFRERERERkQ2wuCIiIiIiIrIBFldEREREREQ2wOKKiIiIiIjIBlhcERERERER2QCLKyIiIiIiIhtgcUVERERERGQDLK6IiIiIiIhsgMUVERERERGRDbC4IiIiIiIisoFKL67GjBmD69evIy8vDxEREejcuXOpyy5fvhxCiGItKirKbLmxY8fi8uXLyM3NRXx8PObNmweFQlHRT4WIiIiIiP7DKrW4Gjx4MBYsWIAZM2agTZs2OHToEHbs2IHatWuXuPzYsWPh6+tragEBAUhLS8P69etNywwbNgyzZ8/GF198gaZNmyI0NBRDhgzBrFmzHtbTIiIiIiKi/yhRWe348eNiyZIlZn0XL14UM2fOLNf6AwYMEAaDQQQGBpr6vvvuO7Fnzx6z5b755htx8ODBcselVCqFEEIolcpKOzZVOR626tGYN2zWNOYNm7WNucNmTWPesFnTHnbeWLI/GSqJvb092rZti9mzZ5v179q1C506dSrXNkJDQ7Fnzx7Ex8eb+g4fPoxXX30VTzzxBE6dOoW6deuiT58++PXXX0vdjlwuN7tsUKlUmt1WtqoWD1UPzBuyBvOGrMXcIWswb8gaDztvLNlPpRVX3t7ekMlkSElJMetPSUmBr69vmev7+vqid+/eGDZsmFn/2rVrUaNGDRw+fBgSiQT29vZYsmQJ5syZU+q2Jk6ciGnTphXrT0xMLN+TeUiqWjxUPTBvyBrMG7IWc4eswbwha1TFvKm04qqIEMLsvkQiKdZXkhEjRiAzMxMbN2406w8ODsakSZPwzjvv4MSJE2jQoAEWLlyIW7du4auvvipxW7NmzcK8efNM95VKJRITE+Hv7w+VSmX5k7KxqhYPVQ/MG7IG84asxdwhazBvyBoPO2+K9lcelVZcpaamQq/XFxul8vHxKTaaVZJRo0Zh5cqV0Ol0Zv3Tp0/HypUrERYWBgCIioqCs7MzfvzxR8yYMaPEwi0/Px/5+fnF+lUqVZV6o1e1eKh6YN6QNZg3ZC3mDlmDeUPWqIp5U2mzBep0OkRGRiIkJMSsPyQkBEePHr3vusHBwWjYsKGpgLqbk5MTjEajWZ/BYIBEIoFEInnwwImIiIiIiEpQqZcFzps3DytXrkRERASOHTuGt956C4GBgfj+++8BADNnzoS/vz+GDx9utl5oaCiOHz+OCxcuFNvmli1b8NFHH+HMmTOmywKnT5+OzZs3Fyu6iIiIiIiIbKVSi6t169bBy8sLU6dOhZ+fH6KiotCnTx/T7H9+fn4IDAw0W8fV1RUDBw7E2LFjS9zmV199BSEEvvrqK/j7++POnTvYsmULJk2aVOHPh4iIiIiI/rskKJiTne6iVCqRnZ0NV1fXKnEdZ1WLh6oH5g1Zg3lD1mLukDWYN2SNh503luyv0r5zRURERERE9ChhcUVERERERGQDLK6IiIiIiIhsgMUVERERERGRDbC4IiIiIiIisgEWV0RERERERDbA4oqIiIiIiMgGWFwRERERERHZAIsrIiIiIiIiG2BxRUREREREZAMsroiIiIiIiGyAxRUREREREZENsLgiIiIiIiKyARZXRERERERENsDiioiIiIiIyAZYXBEREREREdkAiysiIiIiIiIbYHFFRERERERkAyyuiIiIiIiIbIDFFRERERERkQ2wuCIiIiIiIrIBFldEREREREQ2wOKKiIiIiIjIBlhcERERERER2QCLKyIiIiIiIhtgcUVERERERGQDLK6IiIiIiIhsgMUVERERERGRDbC4IiIiIiIisgEWV0RERERERDbA4oqIiIiIiMgGWFwRERERERHZAIsrIiIiIiIiG2BxRUREREREZAMsroiIiIiIiGyAxRUREREREZENsLgiIiIiIiKyARZXRERERERENsDiioiIiIiIyAZYXBEREREREdkAiysiIiIiIiIbYHFFRERERERkAyyuiIiIiIiIbIDFFRERERERkQ2wuCIiIiIiIrIBFldEREREREQ2wOKKiIiIiIjIBlhcERERERER2QCLKyIiIiIiIhtgcUVERERERGQDlV5cjRkzBtevX0deXh4iIiLQuXPnUpddvnw5hBDFWlRUlNlybm5uWLRoEZKSkpCXl4eLFy+id+/eFf1UiIiIiIjoP6xSi6vBgwdjwYIFmDFjBtq0aYNDhw5hx44dqF27donLjx07Fr6+vqYWEBCAtLQ0rF+/3rSMvb09du/ejTp16uCll15C48aN8eabbyIxMfFhPS0iIiIiIvqPEpXVjh8/LpYsWWLWd/HiRTFz5sxyrT9gwABhMBhEYGCgqe/tt98WMTExQiaTWR2XUqkUQgihVCor7dhU5XjYqkdj3rBZ05g3bNY25g6bNY15w2ZNe9h5Y8n+ZKgk9vb2aNu2LWbPnm3Wv2vXLnTq1Klc2wgNDcWePXsQHx9v6uvfvz+OHTuGxYsXY8CAAbhz5w7WrFmDOXPmwGg0lrgduVwOhUJhuq9UKs1uK1tVi4eqB+YNWYN5Q9Zi7pA1mDdkjYedN5bsp9KKK29vb8hkMqSkpJj1p6SkwNfXt8z1fX190bt3bwwbNsysv169eujevTtWr16NPn36oGHDhli8eDFkMhmmT59e4rYmTpyIadOmFeuvapcSVrV4qHpg3pA1mDdkLeYOWYN5Q9aoinlTacVVESGE2X2JRFKsryQjRoxAZmYmNm7caNYvlUpx+/ZtvPXWWzAajTh9+jRq1aqFTz75pNTiatasWZg3b57pvlKpRGJiIvz9/aFSqSx/UjZW1eKh6oF5Q9Zg3pC1mDtkDeYNWeNh503R/sqj0oqr1NRU6PX6YqNUPj4+xUazSjJq1CisXLkSOp3OrP/WrVvQ6XRmlwBeunQJfn5+sLe3L7Y8AOTn5yM/P79Yv0qlqlJv9KoWD1UPzBuyBvOGrMXcIWswb8gaVTFvKm22QJ1Oh8jISISEhJj1h4SE4OjRo/ddNzg4GA0bNkRYWFixx44cOYIGDRpAIpGY+ho1aoSkpKQSCysiIiIiIiJbqNSp2OfNm4c33ngDI0eORJMmTTBv3jwEBgbi+++/BwDMnDkTv/76a7H1QkNDcfz4cVy4cKHYY0uXLoWXlxcWLlyIhg0bok+fPvj888+xePHiCn8+RERERET031Wp37lat24dvLy8MHXqVPj5+SEqKgp9+vQxzf7n5+eHwMBAs3VcXV0xcOBAjB07tsRt3rx5E7169cL8+fNx7tw5JCYmYuHChZgzZ06FPx8iIiIiIvrvkqBgTna6i1KpRHZ2NlxdXavEdZxVLR6qHpg3ZA3mDVmLuUPWYN6QNR523liyP4svCwwICIC/v7/p/hNPPIH58+fjzTfftDxSIiIiIiKiR4TFxdWaNWvQrVs3AEDNmjWxe/dutG/fHjNnzsSUKVNsHiAREREREVF1YHFx1bx5c5w8eRIAMHjwYERFReGpp57CsGHDMGLECFvHR0REREREVC1YXFzZ29tDq9UCAHr27InNmzcDAC5fvgw/Pz/bRkdERERERFRNWFxcXbhwAaNHj0bnzp0REhKCnTt3AgBq1aqFtLQ0mwdIRERERERUHVhcXH366ad4++23sX//fvz22284d+4cAKB///6mywWJiIiIiIj+ayz+nasDBw7A29sbrq6uyMzMNPX/+OOPyM3NtWVsRERERERE1YbFI1cODg5QKBSmwiowMBBjx45F48aNcefOHVvHR0REREREVC1YXFxt2rQJr7/+OgDAzc0NJ06cwPjx47Fx40aMHj3a5gESERERERFVBxYXV48//jgOHToEAHjppZeQkpKCoKAgvP766/jggw9sHiAREREREVF1YPF3rpycnKBSqQAAvXr1wp9//gkhBI4fP46goCCbB0hERERE1ZeTkxO8vb0hkUiKPebs7AyNRoPatWtDrVZXQnRUHdk6b4xGI27dugW9Xv/A27K4uIqJicHzzz+Pv/76C8888wzmz58PAPDx8UF2dvYDB0RERERE1Z9EIsHIkSPRtWvXUpeRSqU4efIkPv/8cxiNxocXHFVrFZE3Go0GkyZNeuA5JCwurr788kusWbMG8+fPx99//43jx48DKBjFOnPmzAMFQ0RERESPhpEjRyI4OBhr167F5cuXSxwVkEqlaNq0KS5dusTiisrN1nmjUCgwevRovPnmm5g1axaEEFZvy+LiasOGDQgMDISfnx/Onj1r6t+7dy/++usvqwMhIiIiokeDs7MzunbtirVr12Lbtm2lLieVSuHp6Ym4uDgWV1RuFZE369atwzvvvAM3Nzezn5uylMXFFQCkpKQgJSUF/v7+EEIgKSkJp06dsjoIIiIiInp0eHl5AQAuX75cyZEQlc/t27cBoNhv+VrK4tkCJRIJpkyZgszMTMTFxSE+Ph4ZGRmYPHlyiV9UJCIiIqL/lqJzQltMEED0MBgMBgB44HrG4pGrGTNmIDQ0FJ999hmOHDkCiUSCp556CtOmTYODgwMmT578QAERERERERFVRxaPXA0fPhxvvPEGvv/+e5w/fx7nzp3D0qVL8eabb2LEiBEVECIRERERUfW1b98+0wzb5REUFAQhBFq1alWBUVFFsLi48vT0LPH62cuXL8PT09MmQRERERERPWxCiPu25cuXW7XdF198EVOmTCn38gkJCfD19UVUVJRV+7NGeHg49Ho9nnzyyYe2z0eRxcXV2bNn8d577xXrf++998xmDyQiIiIiqk58fX1NbezYscjKyirWdzeZrHzfsMnIyEBOTk654zAajUhJSTF9D6ii1a5dGx07dsSiRYsQGhr6UPZ5P+U9rlWRxcXVhAkTMGrUKFy4cAE///wzfvrpJ1y4cAEjRozAJ598UhExEhERERFVuKIZsVNSUpCVlQUhhOm+g4MDsrKyMGjQIOzbtw95eXl49dVX4enpiTVr1iAhIQFqtRrnzp3D0KFDzbZ772WBsbGxmDhxIsLCwpCdnY24uDi8+eabpsfvvSwwODgYQgh0794dp06dglqtxpEjR9CoUSOz/UyaNAkpKSnIzs7GTz/9hFmzZpXrd2hHjhyJrVu3YunSpRgyZAicnJzMHndzc8MPP/yA5ORk5OXl4fz58+jbt6/p8U6dOmH//v1Qq9VIT0/Hzp074e7ubnqu9xalZ86cwf/+9z/TfSEE3n77bWzcuBE5OTmYPHkypFIpfv75Z1y/fh25ubm4fPkyPvjggxJjj4qKgkajQVJSEr777jsAQFhYGLZs2WK2rJ2dHW7duoWRI0eWeUysZXFxdfDgQTRq1Ah//fUX3N3d4enpiT///BONGzfG4cOHKyJGIiIiInoEyB0dzJq9owPs5HLY39Nv62ZLc+bMwbfffoumTZsiPDwcDg4OiIyMRL9+/dC8eXP8+OOPWLlyJdq3b3/f7YwfPx4RERFo06YNlixZgqVLl6Jx48b3XWfGjBkYP3482rVrB71ej2XLlpkeGzZsGCZNmoRPP/0Ubdu2RXx8PMaMGVOu5zRy5EisWrUK0dHRuHLlCgYPHmx6TCKRYMeOHejUqRNeffVVNGvWDJ999plpVK1Vq1bYu3cvLly4gI4dO6Jz587YsmUL7OzsyrXvIl988QU2bdqEFi1aYNmyZZBKpbh58yYGDx6MZs2a4csvv8TMmTMxaNAg0zqjR4/G4sWL8eOPP6JFixbo378/YmJiAAA///wznn32Wfj6+pqW79OnD1xcXLBu3TqLYrOEVWNut27dKjYrYEBAAMLCwqrEUCIRERERVS1yRwfMOrmvxMeGVPC+J7bvhvw8jU22tWDBAvz1119mfXPnzjX9e9GiRXj22WcxaNAgnDx5stTtbN++HUuXLgVQULCNGzcOXbt2RXR0dKnrTJo0CQcPHgQAzJ49G9u3b4dCoYBWq8X777+PsLAw/PLLLwCA6dOno1evXnBxcbnv8+nZsyecnJwQHh4OAFi1ahVCQ0NN2+nZsyfat2+Ppk2b4urVqwAKRqOKTJgwAREREXj33XdNfRcvXrzvPkuyZs2aYt9pmzZtmunfN27cQKdOnTB48GBs2LABAPD5559j7ty5+Pbbb03LRUREAACOHTuG6OhovPbaa/j6668BFBSR69evh1qttji+8rJ45Ko0np6eGD58uK02R0RERERU5RSdvBeRSqX4/PPPcfbsWaSmpkKlUqFXr14IDAy873bOnTtndj85ORk+Pj7lXufWrVsAYFqncePGxYq5+xV3RUJDQ7F27VrTSNRvv/2GJ5980nTJYevWrXHz5k1TYXWv1q1bY+/evWXupyz3HlcAePvtt3Hq1Cncvn0bKpUKb775pum4enh4wN/f/777/vnnn02XANaoUQN9+/Y1G+2rCNX322JEREREVG3k52kwsX03sz6JVIpWLVvh7LmzEEZjhe7bVu4d9Rg/fjzGjRuHDz/8EOfPn4darcaCBQsgl8vvux2dTmd2XwgBqfT+4x53ryOEAACzdYr6ipT1g7geHh54/vnnYW9vb3YJoUwmw6hRo/DZZ58hLy/vvtso63Gj0VgsDnt7+2LL3XtcBw0ahPnz52P8+PE4duwYVCoVPvnkE9Nshlqt9r77BYAVK1Zg9uzZ6NChAzp27IgbN25U+NeYWFwRERER0UNxb5EjlUphyM+HLk8DYwUWVxWpS5cu2LRpE1avXg2goKBp2LAhLl269FDjiI6ORvv27bFq1SpTX7t27e67ziuvvIKbN2/i+eefN+vv0aMHJk6ciEmTJuHcuXMICAhAw4YNSxy9OnfuHHr06GF2Cd/d7ty5Az8/P9N9pVKJunXrlvl8unTpgqNHj5ounQSA+vXrm/6dm5uL2NhY9OjRA/v37y9xG+np6di4cSNGjhyJjh07Wj2VviVYXBERERERWSkmJgYDBw5Ex44dkZGRgY8++gi+vr4Pvbj67rvv8NNPPyEiIgJHjx7FkCFD0LJlS1y/fr3UdUJDQ/HHH3/gwoULZv1xcXGYM2cO+vbti82bN+PgwYPYsGEDPvroI8TExKBJkyYQQiA8PByzZs3C+fPnsXjxYnz//ffIz89Ht27dsH79eqSlpeHvv//GiBEjsGXLFmRkZGD69OnlmmI+JiYGr7/+Onr16oXY2Fi89tpreOKJJ8y+7/Xll19iyZIluH37Nnbs2AGlUomnnnoKixYtMi3z888/Y+vWrbCzs8Ovv/5qxZG1TLmLq6IvjpWmaLpFIiIiIqL/iunTp6Nu3boIDw9Hbm4ufvzxR2zcuBFubm4PNY41a9agXr16+Oabb+Dg4IB169bhl19+KXXWwscffxytW7c2mwK+SE5ODnbt2oXQ0FBs3rwZAwcOxDfffIPffvsNzs7OiImJwWeffQYAuHr1Knr16oWZM2fi5MmTyMvLw4kTJ/Dbb78BAGbNmoV69eph69atyMrKwpQpU8o1cvX999+jdevWWLt2LYQQ+O2337BkyRL07t3btMyKFSsgl8sxbtw4fPPNN0hNTcUff/xhtp09e/bg1q1buHDhgul7ahVJAkCUuRRQ7i9/jRo16kHiqRKUSiWys7Ph6uoKlUpV2eFUuXioemDekDWYN2Qt5g7dLSgoCNOnT8eUKVMQFxdX6nJSqRRt2rTBmTNnqu1lgVXZrl27kJycjNdff72yQ7EpS/LG0dERSUlJGDVqVLFZHu92v5y15O9buUeuHoWiiYiIiIjoUeTo6IjRo0cjPDwcBoMBL7/8MkJCQtCzZ8/KDq1SSCQS+Pr6Yvz48cjKysLmzZsfyn75nSsiIiIiompOCIE+ffpg8uTJUCgUiI6OxosvvmiTadKro8DAQNy4cQMJCQkYMWJEub7nZQssroiIiIiIqjmNRoOQkJDKDqPKiIuLK3Mq+opgsx8RJiIiIiIi+i9jcUVERERERGQDNi2uyvolaiIiIiIiokeV1cXVxo0bMX78ePj6+gIAvL29sW/fPpsFRkREREREVJ1YXVzFx8ejb9++uHbtGubNm4fjx4/D0dHRlrERERERERFVG1bPFvjBBx8AAIYMGYI1a9YgJycH7dq1s1lgRERERERE1Um5R66+++47hIaGmvXVq1cP8+fPR1hYGC5duoT333/f5gESEREREVUn+/btw/z58ys7DKoE5S6uBgwYgJMnT5ru+/r6Yvfu3fj999/x1ltvYfLkyXjttdcqJEgiIiIiooq2efNm7N69u8THOnToACEE2rRpY7P9OTg4ID09HWlpaXBwcLDZdqnylLu48vLyQk5ODgDA3d0d4eHhWLlyJT766CMAwLVr1+Dv718xURIRERERVbCwsDB0794dgYGBxR4bNWoUzpw5gzNnzthsfwMHDkRUVBQuXryIF1980WbbtZadnV1lh1Dtlbu4unz5MiZPnowePXpg79692LhxI6ZNm2Z6/KmnnkJcXFxFxEhEREREVOG2bt2K27dvY8SIEWb9jo6OGDJkCMLCwuDp6Yk1a9YgISEBarUa586dw9ChQ63aX2hoKFatWoVVq1YV+/oNADRr1gxbt25FVlYWsrOzcfDgQdSrV8/0+MiRIxEVFQWNRoOkpCR89913AICgoCAIIdCqVSvTsm5ubhBCIDg4GAAQHBwMIQR69eqFU6dOQavVokuXLqhXrx42btyI5ORkqFQqnDx5Ej169DCLSy6XY86cOYiPj4dGo8GVK1cwatQoAMDVq1cxfvx4s+Ufe+wxGAwGs9gfVeUurj7//HMMGTIEGzZswLVr1/Dyyy+jV69e8PHxwUsvvYS5c+dixYoVFRkrEREREVVjTk6KYs3Bwb7Eflu28jIYDFixYkWx4mrQoEGQy+VYvXo1HBwcEBkZiX79+qF58+b48ccfsXLlSrRv396iY1GvXj107NgR69atw7p169CpUyfUrVvX9HitWrVw8OBBaDQadO/eHW3btsWyZcsgkxXMRzd69GgsXrwYP/74I1q0aIH+/fsjJibGohgA4P/+7/8wceJENG3aFOfOnYOLiwu2b9+Onj17ok2bNggPD8eWLVtQu3Zt0zorVqzA0KFD8cEHH6Bp06YYPXq06Qq3ZcuWYeTIkWb7GDVqFA4dOoTr169bHF91JMrb5HK5kMvlAoCYOnWqyM3NFXq9XhgMBrF69WphZ2dX7m1V5aZUKoUQQiiVykqPpSrGw1Y9GvOGzZrGvGGztjF32O5uQUFBYsWKFSIoKMjU5+SkEEaxpVKak5Oi3LE3btxYCCFE165dTX379+8Xq1evLnWdrVu3iq+//tp0f9++fWL+/Pn33c9XX30l/vzzT9P9v/76S0yfPt10f8aMGeLatWtCJpOVuP7NmzfNlr/3+AshRKtWrUx9bm5uQgghgoODBQARHBwshBCif//+ZR6TqKgo8e677woAomHDhkIIIXr06FHisr6+vkKn04knnnhCABAymUykpKSI119/3Wb5JZVKRdu2bYVUKq3QnC1qlvx9s+h3rvLz85Gfnw8A+PLLL+Hn54dOnTohMDAQr7zyCgwGgyWbIyIiIiKqUqKjo3HkyBHTZW716tVDly5dsGzZMgCAVCrF559/jrNnzyI1NRUqlQq9evUq8XtapZFKpRg+fDhWrVpl6lu1ahWGDx8OqbTg9Lx169Y4dOgQ9Hp9sfVr1KgBf39/7N2790GeKgAgIiLC7L6TkxPmzJmDCxcuICMjAyqVCk2aNDE9v9atW0Ov1+PAgQMlbi85ORnbtm0zHb9+/frBwcEB69evf+BYqwOrf+cKALKyssxmECQiIiIiKklurhYuzi+Z9UmlUrRq1Qpnz56F0Wis0H1bIiwsDIsWLcK7776LkSNHIi4uzlTIjB8/HuPGjcOHH36I8+fPQ61WY8GCBZDL5eXe/jPPPIOAgACsXbvWrF8mk6FXr17YuXMn8vLySl3/fo8BMB1LiURi6rO3ty9xWbVabXb/66+/xjPPPIOPP/4YMTExyMvLwx9//GF6fmXtGwB+/vlnrFy5EuPGjcPIkSOxdu3acq33KHig4oqIiIiIqLzuLXKkUik0Gh1yc7UVWlxZat26dVi4cCGGDRuG4cOH46effjI91qVLF2zatAmrV68GUFDANGzYEJcuXSr39kNDQ/Hbb79hxowZZv2fffYZQkNDsXPnTpw7dw7Dhw+HTCYrNnqVk5OD2NhY9OjRA/v37y+2/Tt37gAA/Pz88M8//wAoGHEqjy5duuCXX37Bxo0bAQDOzs6oU6eO6fHz589DKpUiODi41JGz7du3Q61WY8yYMejduzeefvrpcu37UWDRZYFERERERI86tVqNtWvXYubMmahVqxZ++eUX02MxMTEICQlBx44d0aRJE/zwww/w9fUt97a9vb3x3HPP4ddff8WFCxfM2q+//or+/fvD29sbixYtgqurK37//Xe0bdsWDRo0wKuvvopGjRoBAKZNm4bx48fj/fffR4MGDdCmTRu89957AACNRoNjx47hs88+Q9OmTdGlSxd89dVX5YovJiYGL774Ilq1aoWWLVtizZo1pksVASAuLg6//vorli1bhgEDBqBOnToIDg7GoEGDTMsYjUb88ssvmDVrFmJiYnD8+PFyH5/qjsUVEREREdE9iqZd37NnDxISEkz906dPx+nTpxEeHo79+/cjOTnZNMpTHq+//jrUanWJoz779u2DSqXCa6+9hvT0dHTv3h0uLi44cOAAIiMj8eabb0Kn0wEomLHvww8/xDvvvIMLFy5g69ataNiwoWlbo0aNgr29PSIiIrBw4UJMnjy5XPGNGzcOGRkZOHr0KLZs2YLw8HCcPn3abJkxY8bgjz/+wJIlS3D58mX89NNPcHZ2NlsmLCwMCoXC9F21/xKbzg5jaRszZoy4fv26yMvLExEREaJz586lLrt8+XJRkqioqBKXHzJkiBBCiL/++suimKrajEdVLR626tGYN2zWNOYNm7WNucN2d7vfzGt3t4qY9Y2tarROnTqJ/Px84ePjY/NtPzKzBQJAbGwspkyZYjbXvbUGDx6MBQsWYMaMGWjTpg0OHTqEHTt2lLrtsWPHwtfX19QCAgKQlpZW4uwjgYGB+Oabb3Dw4MEHjpOIiIiIiMoml8tRv359TJ8+HevWrcPt27crO6SHyuLiau7cuRgwYACuX7+OXbt2YciQIRbNjnK3jz76CGFhYQgLC8Ply5cxbtw4JCQkYMyYMSUun52djZSUFFNr164dPDw8sHz5cvMnJZVi9erV+N///vef+bEyIiIiIqLK9vLLLyM6Ohpubm6YMGFCZYfz0Fk8W+CiRYuwaNEitGzZEqNGjcK3336LJUuWYM2aNVi2bBnOnDlTru3Y29ujbdu2mD17tln/rl270KlTp3JtIzQ0FHv27EF8fLxZ/9SpU3Hnzh0sW7YMXbp0KXM7crkcCsW/v96tVCrNbitbVYuHqgfmDVmDeUPWYu7Q3ZydnSGVSk2tNHZ2dma3VP2tXLkSK1euNN2/3+tvrYrIm6JcdXZ2LvZ3zJK/a1ZPxX7u3Dl8+OGH+Pjjj/HOO+9gzpw5GDNmDKKiorBw4cJio0n38vb2hkwmQ0pKill/SkpKuWZc8fX1Re/evTFs2DCz/k6dOiE0NLTc000CwMSJEzFt2rRi/YmJieXexsNQ1eKh6oF5Q9Zg3pC1mDsEFMxWd/LkSTRt2hSenp5lLt+yZcuHEBU9amyZNzVr1kTt2rURGRkJBwcHq7djdXElk8nwwgsvYOTIkQgJCcHx48cRFhaGWrVqYcaMGejZsydeeeWVMrcjhDC7L5FIivWVZMSIEcjMzDSbncXFxQWrVq3Cm2++ibS0tHI/l1mzZmHevHmm+0qlEomJifD394dKpSr3dipKVYuHqgfmDVmDeUPWYu7Q3WrXro3PP/8cly5dQlxcXKnL2dnZoWXLljh37hwMBsNDjJCqs4rIm6CgINPXk+6eHRL49+9beVhcXLVp0wYjR47Eyy+/DIPBYPr15ejoaNMyu3btKnMiidTUVOj1+mKjVD4+PsVGs0oyatQorFy50jQdJQDUr18fdevWxZYtW0x9RUOROp0OjRs3LvE7WPn5+cjPzy/Wr1KpqtR/EFUtHqoemDdkDeYNWYu5Q0DB70QZjUZTK4vBYKhSPyJM1YMt86YoV9Vq9QP9DbO4uDp16hR2796NMWPGYOPGjcV+MRoALl68iN9///2+29HpdIiMjERISIjZ6FNISAg2bdp033WDg4PRsGFDhIWFmfVfvnwZzZs3N+v76quvoFQqMXbs2GJVKBERERERka1YXFzVq1ev2AQS98rNzcWoUaPK3Na8efOwcuVKRERE4NixY3jrrbcQGBiI77//HgAwc+ZM+Pv7Y/jw4WbrhYaG4vjx47hw4YJZv1arLdaXmZkJAMX6iYiIiIiIbMni4srHxwe+vr44efKkWX/79u1hMBgQGRlZ7m2tW7cOXl5emDp1Kvz8/BAVFYU+ffqYijc/Pz8EBgaarePq6oqBAwdi7NixloZORERERERUYSyeG3Hx4sUl/sivv78/Fi9ebHEAS5cuRd26deHg4IB27drh0KFDpsdGjhyJbt26mS2fnZ0NZ2dn/Pzzz+Xa/siRI/HCCy9YHBcRERERkS3s27cP8+fPL/fyQUFBEEKgVatWFRgVVQSLi6tmzZrh9OnTxfrPnDmDZs2a2SQoIiIiIqKHTQhx31bWTw2V5sUXX8SUKVPKvXxCQgJ8fX0RFRVl1f7Ki0Wc7Vl8WaBWq0XNmjURGxtr1u/n51fi5BZERERERNXB3bNYDxkyBF9++SUaN25s6svLyzNbXiaTlev8NyMjw6I4jEZjuWbPpqrH4pGr3bt3Y9asWXB1dTX1ubm5YebMmdi9e7dNgyMiIiIielhSUlJMLSsrC0II030HBwdkZWVh0KBB2LdvH/Ly8vDqq6/C09MTa9asQUJCAtRqNc6dO4ehQ4eabffeywJjY2MxceJEhIWFITs7G3FxcXjzzTdNj987ohQcHAwhBLp3745Tp05BrVbjyJEjaNSokdl+Jk2ahJSUFGRnZ+Onn37CrFmzcObMGauPh1wux8KFC5GSkoK8vDwcOnQI7dq1Mz3u7u6OVatW4fbt28jNzcWVK1cwYsQIAIC9vT2+++47JCUlIS8vD7Gxsfjss8+sjqW6sLi4Gj9+PGrXro24uDj8/fff+PvvvxEbGwtfX1+MHz++ImIkIiIiokeAg4OjeVM4Qm6vgIPCsfhjNmy2NGfOHHz77bdo2rQpwsPD4eDggMjISPTr1w/NmzfHjz/+iJUrV6J9+/b33c748eMRERGBNm3aYMmSJVi6dKnZKFlJZsyYgfHjx6Ndu3bQ6/VYtmyZ6bFhw4Zh0qRJ+PTTT9G2bVvEx8djzJgxD/Rc/+///g8DBw7E8OHD8fjjjyMmJgbh4eHw8PAAAEyfPh3NmjVD79690bRpU4wZMwapqakAgA8++AD9+/fH4MGD0bhxY7z66qu4cePGA8VTHVh8WWBSUhJatmyJV155Ba1atUJeXh6WL1+O3377jZcFEhEREVGJHBwcsWPLP5Wy797PtYZGk1f2guWwYMEC/PXXX2Z9c+fONf170aJFePbZZzFo0KBis2vfbfv27Vi6dCmAgoJt3Lhx6Nq1K6Kjo0tdZ9KkSTh48CAAYPbs2di+fTsUCgW0Wi3ef/99hIWF4ZdffgFQUPj06tULLi4uVj1PJycnjBkzBiNGjMDOnTsBAG+++SZCQkIQGhqKb775BoGBgThz5oxptvC4uDjT+oGBgbh69SoOHz4MAGX+lNOjwuLiCij4HauffvrJ1rEQEREREVVpERERZvelUik+++wzDBkyBP7+/lAoFFAoFFCr1ffdzrlz58zuJycnw8fHp9zr3Lp1C0DBzyQlJCSgcePGWLJkidnyJ0+eRPfu3ct8TiWpX78+5HI5jhw5YurT6/U4efIkmjZtCqBg1u8NGzbg8ccfx65du7Bx40YcO3YMAPDLL79g9+7diI6Oxs6dO7F169b/xFeIrCquAKBp06YIDAyEXC4369+yZcsDB0VEREREjxaNJg+9n2tt1ieVSNGqVSucPXsWRmGs0H3byr1F0/jx4zFu3Dh8+OGHOH/+PNRqNRYsWFDsHPleOp3O7L4QAlLp/b+xc/c6QggAMFunqK+IRCK57/bup2jdkrZZ1Ldz504EBQWhb9++6NmzJ/bu3YvFixfjk08+wZkzZ1C3bl307t0bPXv2xLp167Bnzx4MGjTI6piqA4uLq7p16+Kvv/5CixYtIIQoduBlMqvrNSIiIiJ6hN1b5EilUuTrtNBo82A0VlxxVZG6dOmCTZs2YfXq1QAKio+GDRvi0qVLDzWO6OhotG/fHqtWrTL13T35hKViYmKg1WrRuXNn/PbbbwAKzvPbtWuHBQsWmJZLTU3Fr7/+il9//RWHDh3C119/jU8++QQAoFKpsG7dOqxbtw5//PGH6ftals6eWJ1YXAktXLgQsbGx6NmzJ65fv4727dvDy8sLc+fOxccff1wRMRIRERERVUkxMTEYOHAgOnbsiIyMDHz00Ufw9fV96MXVd999h59++gkRERE4evQohgwZgpYtW+L69etlrlvSRBoXL17E0qVL8fXXXyM9PR3x8fGYMGECnJycEBYWBgD44osvEBkZiQsXLkChUKBfv36m5/3hhx/i1q1b+Oeff2A0GjFo0CDcunULmZmZNn3eVY3FxVXHjh3RvXt3pKamwmg0wmg04siRI5g4cSK+/fZbPP744xURJxERERFRlTN9+nTUrVsX4eHhyM3NxY8//oiNGzfCzc3tocaxZs0a1KtXD9988w0cHBywbt06/PLLL2XOWggAa9euLdZXp04dfPbZZ5BKpVi5ciWUSiUiIiLwzDPPmAqk/Px8zJo1C3Xq1DFN1V40DX1OTg4+/fRTNGzYEAaDAadOnUKfPn2KXWb4KBKWtPT0dFG3bl0BQMTExIiuXbsKAKJevXpCrVZbtK2q2pRKpRBCCKVSWemxVMV42KpHY96wWdOYN2zWNuYO290tKChIrFixQgQFBd13OalUKtq2bSukUmmlx/wotl27dokVK1ZUehy2bhWRN/fLWUv+vlk8chUVFYWWLVsiNjYWJ06cwIQJE5Cfn4+33nqrXMOORERERERkW46Ojhg9ejTCw8NhMBjw8ssvIyQkBD179qzs0P5TLC6uvvrqKzg7OwMAJk+ejK1bt+LQoUNIS0vDkCFDbB4gERERERHdnxACffr0weTJk6FQKBAdHY0XX3wRe/furezQ/lMsLq527dpl+ndsbCwee+yxR37WDyIiIiKiqkyj0SAkJKSyw/jPu/9k+vews7ODTqfDY489ZtbPwoqIiIiIiP7rLCquDAYD4uLiYGdnV1HxEBERERERVUsWFVdAwXeuZs2aBQ8Pj4qIh4iIiIiIqFqy+DtXH3zwARo0aICkpCTExcVBrVabPd62bVubBUdERERERFRdWFxcbdy4sQLCICIiIiIiqt4sLq6+/PLLioiDiIiIiIioWrP4O1dERERERFS6ffv2Yf78+ZUdBlUCi4srg8EAvV5faiMiIiIiqo42b96M3bt3l/hYhw4dIIRAmzZtHng/w4cP508ZPaIsvizwhRdeMLtvb2+PNm3aYPjw4fjf//5ns8CIiIiIiB6msLAw/PnnnwgMDER8fLzZY6NGjcKZM2dw5syZSoqOqgOLR642b95s1jZs2IDJkydjwoQJ6N+/f0XESERERERU4bZu3Yrbt29jxIgRZv2Ojo4YMmQIwsLC4OnpiTVr1iAhIQFqtRrnzp3D0KFDbRpH7dq1sXHjRqhUKmRlZWHt2rXw8fExPd6yZUv8/fffyM7ORlZWFiIiIkwzdgcGBmLz5s1IT09HTk4OoqKi0Lt3b5vGR6WzeOSqNCdOnMBPP/1kq80RERER0SPGyd7e7L5UKoGDnRRO9jIYjaLC9pur05VrOYPBgBUrVmDEiBFmk7gNGjQIcrkcq1evhpOTEyIjIzFnzhxkZ2ejb9++WLlyJa5fv46TJ0/aJN6NGzdCrVYjODgYMpkMS5Yswdq1a9GtWzcAwOrVq3HmzBmMGTMGBoMBrVu3hq7wOS5evBhyuRxPP/001Go1mjVrhpycHJvERWWzSXHl4OCA999/Hzdv3rTF5oiIiIjoEeNkb4/MyWNLfrBvcIXu2/2rheUusJYtW4YJEyaga9eu2L9/P4CCSwL//PNPZGZmIjMzE3PnzjUtv2jRIjz77LMYNGiQTYqrnj17omXLlqhbt67p3Pq1117DxYsX0a5dO0RERCAwMBBff/01oqOjAQAxMTGm9QMDA7FhwwZERUUBAGJjYx84Jio/i4ur9PR0CPHvJwsSiQRKpRK5ubl49dVXbRocEREREdHDFB0djSNHjmDUqFHYv38/6tWrhy5duqBXr14AAKlUis8++wxDhgyBv78/FAoFFAoF1Gq1TfbftGlTJCQkmA1aXLp0CRkZGWjatCkiIiIwb948/Pzzz3jttdewZ88erF+/HtevXwcAfPvtt1i6dCl69eqFPXv2YMOGDTh//rxNYqOyWVxcjRs3zqy4MhqNuHPnDk6cOIHMzExbxkZEREREj4hcnQ7uXy0065NKJWjVqhXOnj1bJS4LLBIWFoZFixbh3XffxciRIxEXF4e9e/cCAMaPH49x48bhww8/xPnz56FWq7FgwQLI5XKbxCqRSMzOtUvq/+KLL7BmzRr07dsXvXv3xhdffIGhQ4di48aNCAsLQ3h4OPr27YtevXph4sSJGD9+PBYtWmST+Oj+LC6ufv3114qIg4iIiIgecfcWOVKpFBqDEbk6PYxGYyVFVdy6deuwcOFCDBs2DMOHDzebV6BLly7YtGkTVq9eDaCg6GnYsCEuXbpkk31fvHgRgYGBCAgIMI1eNW3aFO7u7mb7uHr1KhYsWIAFCxZgzZo1GDlyJDZu3AgAuHnzJn744Qf88MMPmDlzJt58800WVw+JxcXViBEjkJOTgz/++MOs/6WXXoKTkxNWrFhhs+CIiIiIiB42tVqNtWvXYubMmXBzc8Mvv/xieiwmJgYDBw5Ex44dkZGRgY8++gi+vr4WF1d2dnZo1aqVWV9+fj727NmDc+fOYfXq1fjwww9NE1rs378fkZGRcHBwwNdff40//vgDsbGxCAgIwBNPPIENGzYAAObPn48dO3bgypUr8PDwQPfu3W1W+FHZLJ6K/bPPPkNqamqx/tu3b+Pzzz+3SVBERERERJWpaNr1PXv2ICEhwdQ/ffp0nD59GuHh4di/fz+Sk5NNI0aWUCqV+Oeff8za9u3bAQDPP/88MjIycPDgQezZswfXr1/HkCFDABTMaOjl5YUVK1bgypUrWLduHXbs2GH6vVk7OzssXrwYly5dws6dOxEdHY133nnnwQ8IlYvFI1dBQUElzjoSFxeHwMBAmwRFRERERFSZjh8/DolEUqw/IyMDL7zwwn3XLZoyvTS//vrrfb9qk5CQgOeff77Ex3Q6HYYNG1bquh988MF9900Vy+KRq9u3b6Nly5bF+lu1aoW0tDSbBEVERERERFTdWFxc/f777/j222/RtWtXSKVSSKVSdOvWDQsXLsTvv/9eETESERERERFVeRZfFjh58mQEBQVh79690Ov1AApmelmxYgW/c0VERERERP9ZFhdXOp0OQ4cOxeTJk9G6dWvk5eXh/PnziI+Pr4j4iIiIiIiIqgWLi6siMTExiImJsWUsRERERPQIKPqxW5nM6lNNoofKzs4OAEr8AWdLWPydq/Xr1+PTTz8t1v/xxx9j3bp1DxQMEREREVV/RZOcNWnSpJIjISofHx8fAEB2dvYDbcfijxOCg4PxxRdfFOvfuXMnPv744wcKhoiIiIiqP7Vajf3792Pw4MEAgMuXL5u+q383qVSKmjVrIigoCEaj8WGHSdWUrfNGoVBg8ODBuHz5MrKysh5oWxYXVy4uLsjPzy/Wr9Pp4Orq+kDBEBEREdGjYfny5QBg+vHbkkilUtSuXRsJCQksrqjcKiJvNBoNZs2a9cCXBVpcXEVFRWHIkCGYPn26Wf/QoUNx8eLFBwqGiIiIiB4NQggsW7YMv//+O7y9vUv8QV5nZ2dERkZizJgxUKvVlRAlVUe2zhuDwYDk5OQSR1ctZXFxNX36dGzYsAH169fH33//DQDo0aMHXn75ZQwaNOiBAyIiIiKiR0dubm6ps0orlUo4ODggISEBKpXqIUdG1VVVzhuLi6stW7bg+eefx+eff46XXnoJeXl5OHfuHHr27ImDBw9WRIxERERERERVnlXzY27fvh3bt28v1t+qVSucPXv2gYMiIiIiIiKqbiyeiv1erq6uGDNmDCIjIxEZGWmLmIiIiIiIiKodq4urbt26YdWqVbh16xbef/99bN++He3atbNlbERERERERNWGRZcF+vv7Y8SIERg1ahScnZ2xbt062NvbY+DAgbh06VJFxUhERERERFTllXvkatu2bbh48SKaNWuG999/H7Vq1cIHH3xQkbERERERERFVG+UeuerVqxe+/fZbLF26FDExMRUZExERERERUbVT7pGrLl26QKlUIiIiAsePH8e7774Lb2/vBw5gzJgxuH79OvLy8hAREYHOnTuXuuzy5cshhCjWoqKiTMu88cYbOHjwINLT05Geno7du3fjiSeeeOA4iYiIiIiI7qfcxdXx48fx1ltvwc/PDz/88AOGDh2KxMRESKVShISEwMXFxeKdDx48GAsWLMCMGTPQpk0bHDp0CDt27EDt2rVLXH7s2LHw9fU1tYCAAKSlpWH9+vWmZbp27YrffvsN3bp1Q8eOHREfH49du3ahVq1aFsdHRERERERkCWFta9SokZgzZ45ISkoSubm5YtOmTRatf/z4cbFkyRKzvosXL4qZM2eWa/0BAwYIg8EgAgMDS11GKpWKrKws8dprr5U7LqVSKYQQQqlUWn1sbNmqWjxs1aMxb9isacwbNmsbc4fNmsa8YbOmPey8sWR/Vv2IcJErV67g008/xcSJE/Hcc89h1KhR5V7X3t4ebdu2xezZs836d+3ahU6dOpVrG6GhodizZw/i4+NLXcbJyQn29vZIT08vdRm5XA6FQmG6r1QqzW4rW1WLh6oH5g1Zg3lD1mLukDWYN2SNh503luzngYqrIkajEZs2bcKmTZvKvY63tzdkMhlSUlLM+lNSUuDr61vm+r6+vujduzeGDRt23+Vmz56NxMRE7Nmzp9RlJk6ciGnTphXrT0xMLDOOh6mqxUPVA/OGrMG8IWsxd8gazBuyRlXMG5sUVw9CCGF2XyKRFOsryYgRI5CZmYmNGzeWuswnn3yCl19+GV27doVWqy11uVmzZmHevHmm+0qlEomJifD394dKpSr7SVSwqhYPVQ/MG7IG84asxdwhazBvyBoPO2+K9lcelVZcpaamQq/XFxul8vHxKTaaVZJRo0Zh5cqV0Ol0JT4+fvx4fP755+jZsyfOnz9/323l5+cjPz+/WL9KpapSb/SqFg9VD8wbsgbzhqzF3CFrMG/IGlUxb8o9W6Ct6XQ6REZGIiQkxKw/JCQER48eve+6wcHBaNiwIcLCwkp8/OOPP8aUKVPw7LPPIjIy0mYxExERERERlaZSLwucN28eVq5ciYiICBw7dgxvvfUWAgMD8f333wMAZs6cCX9/fwwfPtxsvdDQUBw/fhwXLlwots1PPvkE06dPx7Bhw3Djxg3UrFkTAJCTkwO1Wl3xT4qIiIiIiP6TKrW4WrduHby8vDB16lT4+fkhKioKffr0Mc3+5+fnh8DAQLN1XF1dMXDgQIwdO7bEbb7zzjtQKBTYsGGDWf+0adPwxRdfVMwTISIiIiKi/7xKn9Bi6dKlWLp0aYmPjRw5slhfdnY2nJ2dS91e3bp1bRYbERERERFReVXad66IiIiIiIgeJSyuiIiIiIiIbIDFFRERERERkQ2wuCIiIiIiIrIBFldEREREREQ2wOKKiIiIiIjIBlhcERERERER2QCLKyIiIiIiIhtgcUVERERERGQDLK6IiIiIiIhsgMUVERERERGRDbC4IiIiIiIisgEWV0RERERERDbA4oqIiIiIiMgGWFwRERERERHZAIsrIiIiIiIiG2BxRUREREREZAMsroiIiIiIiGyAxRUREREREZENsLgiIiIiIiKyARZXRERERERENsDiioiIiIiIyAZYXBEREREREdkAiysiIiIiIiIbYHFFRERERERkAyyuiIiIiIiIbIDFFRERERERkQ2wuCIiIiIiIrIBFldEREREREQ2wOKKiIiIiIjIBlhcERERERER2QCLKyIiIiIiIhtgcUVERERERGQDLK6IiIiIiIhsgMUVERERERGRDbC4IiIiIiIisgEWV0RERERERDbA4oqIiIiIiMgGWFwRERERERHZAIsrIiIiIiIiG2BxRUREREREZAMsroiIiIiIiGyAxRUREREREZENsLgiIiIiIiKyARZXRERERERENsDiioiIiIiIyAZYXBEREREREdkAiysiIiIiIiIbYHFFRERERERkA5VeXI0ZMwbXr19HXl4eIiIi0Llz51KXXb58OYQQxVpUVJTZci+++CIuXLgAjUaDCxcu4Pnnn6/gZ0FERERERP91lVpcDR48GAsWLMCMGTPQpk0bHDp0CDt27EDt2rVLXH7s2LHw9fU1tYCAAKSlpWH9+vWmZTp06IC1a9di5cqVaNWqFVauXIl169ahffv2D+tpERERERHRf5SorHb8+HGxZMkSs76LFy+KmTNnlmv9AQMGCIPBIAIDA019v//+u9i+fbvZcjt27BBr1qwpd1xKpVIIIYRSqay0Y1OV42GrHo15w2ZNY96wWduYO2zWNOYNmzXtYeeNJfuToZLY29ujbdu2mD17tln/rl270KlTp3JtIzQ0FHv27EF8fLypr2PHjpg/f77ZcuHh4fjwww9L3Y5cLodCoTDdVyqVZreVrarFQ9UD84aswbwhazF3yBrMG7LGw84bS/ZTacWVt7c3ZDIZUlJSzPpTUlLg6+tb5vq+vr7o3bs3hg0bVqzf0m1OnDgR06ZNK9afmJhYZhwPU1WLh6oH5g1Zg3lD1mLukDWYN2SNqpg3lVZcFRFCmN2XSCTF+koyYsQIZGZmYuPGjQ+8zVmzZmHevHmm+0qlEomJifD394dKpSozlopW1eKh6oF5Q9Zg3pC1mDtkDeYNWeNh503R/sqj0oqr1NRU6PX6YiNKPj4+xUaeSjJq1CisXLkSOp3OrD85Odnibebn5yM/P79Yv0qlqlJv9KoWD1UPzBuyBvOGrMXcIWswb8gaVTFvKm22QJ1Oh8jISISEhJj1h4SE4OjRo/ddNzg4GA0bNkRYWFixx44dO1Zsm7169Spzm0RERERERA+iUi8LnDdvHlauXImIiAgcO3YMb731FgIDA/H9998DAGbOnAl/f38MHz7cbL3Q0FAcP34cFy5cKLbNhQsX4uDBg5gwYQI2bdqEAQMGoGfPnvf9/SwiIiIiIqIHVanF1bp16+Dl5YWpU6fCz88PUVFR6NOnj2n2Pz8/PwQGBpqt4+rqioEDB2Ls2LElbvPYsWMYOnQovvrqK0yfPh3Xrl3DkCFDcPLkyQp/PkRERERE9N8lQcGc7HQXpVKJ7OxsuLq6VonrOKtaPFQ9MG/IGswbshZzh6zBvCFrPOy8sWR/lfadKyIiIiIiokcJiysiIiIiIiIbYHFFRERERERkAyyuiIiIiIiIbIDFFRERERERkQ2wuCIiIiIiIrIBFldEREREREQ2wOKKiIiIiIjIBlhcERERERER2QCLKyIiIiIiIhtgcUVERERERGQDLK6IiIiIiIhsgMUVERERERGRDbC4IiIiIiIisgEWV0RERERERDbA4oqIiIiIiMgGWFwRERERERHZAIsrIiIiIiIiG2BxRUREREREZAMsroiIiIiIiGyAxRUREREREZENsLgiIiIiIiKyARZXRERERERENsDiioiIiIiIyAZYXBEREREREdkAiysiIiIiIiIbYHFFRERERERkAyyuiIiIiIiIbIDFFRERERERkQ2wuCIiIiIiIrIBFldEj6DabkocHzkY+r/WVHYoRERERP8ZLK6IHjFSiQTLX+yDhl4eEOfPYFjzxpUdEhEREdF/AosrokfMx52fwNN1apvuf9W1I2opXSoxIiIiIqL/BhZXRI+QtrV88b9uTwEAPti5H5JateHmoMDi50IqOTIiIiKiRx+LK6JHhLPcHite6gt7Ozusj7qM1VHRsOs/GFq9AX0b18ewlk0rO0QiIiKiRxqLK6JHxNxnu6GhlwcSsrLx7pbdAACJjy++ORYJAJjXuztqujhVZohEREREjzQWV0SPgBeaNsSoti1hNAqM/HMHMjVa02PfnjqLM0kp8HRyxHd9e1ZilERERESPNhZXZDGJpLIjoLv5u7pgaf9eAIBvjpzEwRsJZo/rjUa8uXEndAYDnm/WCC89xtkDiYiIiCqCrLIDoKrPx9kJvRrUwTMN66Jn/TpwkMnw9/U47Lh6HTuvxOJmtqrSYqvh7IQsjRb5BkOlxVCZJBJg2Qt94OnkiMjEZHyx7wgAQCq1w5BBb+DO7YLX5lzKHcw5dAKTu3bCwr49sD82Hqm5eZUZeqWSFn5CYBSikiMhIiKiRwmLq2pCCAGpRAKFzA4yqRQyqRT2Uins7aRwkcvhIpdDqZBDKbeHUiGHi0IOZ3t75On1yMzTICNPiwyNpuDfGi0yNRoYjAUnlhJJwcmmnURacCuVoLWvD55pWBfPNKiLNrVqFovnuSYN8FyTBgCA88l3sPPqdey4GovjCUmwk0rgIJNBYWdXcCuzg4PMDjKpHYQQMAgjDEYBoxAwCAGD0QijgKn/3selEgnqerihkZcHGnl7opGXJxp6eaChlwdcFHIYjQI3s1WIzchCbEam6fZ6RhbU+TpI8O9omwQSs5E3IQABUXhbcJyBgpPuoibuui8EYG8nhatCATcHOdwUCrg6KODmoICbQgFHexnyDQbkGwzQ6g2F/zYi32CA3mAs9tyMdz1/ndEAvdEIncEIndEIvdEIfeG/i7Z59/byDQZ80KEtutULhDpfh9c3bIPOYAQAvDzkDbzy8mhcOH8LjRo+hsjTxzHr4HEMaNIQLXxrYEGfHnj1j60l5ppCZgdPRwc4yGSm17HgNSx4LaUSCXJ1eqjzdcjV6aDO10FdeKs16KGwk8GhcPmCVvBvmZ0U6nwdVNp8qPLzodLml1rcOMvtoZTL4SK3h4tcDqBgBE5vNMIgxL//viuHi17bolupRIIazk6o6+6GOh5uCHJ3RR0PN9Rxd0OgmyvspBLcVuciJUeNWyo1knPUSFblIDknF5l5GhS88sUZhTB7De5+nfVGg+n1NW8F67rI7eGikENZ+H4teN/aw1luX/gcC/Kh6DkWvR8cZDLT8XC+67g4y+2hMxiQodEiI0+DTE3Be73gfa5BTr6uIDa9AVqDAVq9HvkGI7QGg80+lJBKJHCW28PZ3h6O9rLC99u/b7Kif0nKGPLO0miRnqeB3mi0Kg5nuT3cC9+Hbg4KuDs4QCaVQFP43DV6PfL1BbcafcF7rei9D8D0ehfdl0r+zaeif0vveQ5Ffz/uXs9a9+bb3duz5LHK5OLsBKHKgq+zE1xg3etI/z3MGypLSk5utfowVAJUob/MVYRSqUR2djZcXV2hUlXeqAwAfNWzCz7s1A5yOzubb9toFJBKy3eN3+mkZIRfjUV4zA3k5uvwbKO6eLZhPTwZ4Ac7Ka8urWxvbwrH8tPnAQBBgfXx49KNkBcWJcnJNxH6dn/k5qrRxq8mjrz5CmR2Unwavh/Z2nzUcXdFkHtB8RHk7oZarg/vN7GKii21TgdHmQzKwg8FypuX9GASs1WIy8xGXGYW4jKzcSMzC3e0OmzcsRNDn+sHVzsparo4wcfZGb4uzvBxcYKXo2NBMVVYUDnY2/YzuiyNFmm5eQUtT4OMvDxIIIGjvaygyWRwKizkHO3toZTbFxRSdvw7RET0KKr99RKk5OSa9T3sc3VL9sfiqgRVqbia0bMLPunyZKmP6w1GqHUFJ6g5haMBOfk65OQX3HeUyeDu6AAPB4fC24KRlrKkqnOx51ocwq/GYve1G7itzi1xOU9HB4TUr4PejeqhV4M68Hb+dzY6o1FAayj4lFirN0BnNBQbIbOTSAr/LYWdqU9a7OQ6WaXG1bR0XEnLwJXUdFwtvI3NzIK7gwPqerihnocb6nq4o+5dtw6yghO/ez+hFqLk0Y6ivRZ8Ul0Qm1QigaSwTyqRQG80IkurRbYmH1laLbI0WmQX3ubq9LC3k0JuZ1fY/v23vZ3U7LkXHIuCW9NopJ3U7N/2UrvC24LtlHQiu/b8Jbz2x7aCuKVSfLfgNzRr2hpn/jmODh06Q6vRY/eezZg55xMAwPQenfHp0x3u+/rrDcbCT/j1pk/+tXo9tHoDBASc7O3hZH//E2yD0Yg8nd40aqA3Cjjby+CqUEAuK/vDAqNRFOaxDgBgJy04TnaFx6voPnDvCOS/I5FpuXm4UVQ4ZGQVtMyCpjMY4eviDF9lQfNzcUFNF2f4KZ2hVMhLjctOUvDaKEyvsZ3Za16QJ4CdVGrKmaIcuve9ml34b7XpOUohK3wP3P188/T6f9/Xpvd4wX0HmQwejoq73uMOcHNQwMNRAWd7e8gLRx/ldlIoiv5djuNvqaLXu+jTxbv/YxFlfOIolUjK9XepLDqDAZkaLTI1WmRrtNAbjaZRV7mdnWkkVSGTwb4wd+4e1S4ikcA0Ul0wel0w+ijEv+NEd4/QSe5az5oPV+8d1Ls3lvI+Vmy7uP8C1ox6SSC573r29vbQ6XQWb9caZT0/wPrnSA+RBJDZyaA36HlGSiWqO+97FlfVXVUqrtwcFKjp4Y7LV64iqF49ZGZnmy4dMwijVf+R20klpktmjIUnDwWXpv17CVOeXmfxtqUSCTwcHQpOwg0G0yVq1ioqQiSQ/Ge/U1USO6nEdCIvk0qRdtd3pwa/NApj3v4UOWoV3v9wCP45cx4RJ27Azs4OM2Z/gj17N0Mhs8Nvg55DPU93xGb8O2IRl5GFG4WjGOl5GotikkokcLKXQSGTmYqyokv2SiK3syu8jFUOV4UcTnJ75OkKCoaiDwhyH9IJ2n+RRAJ4OjoWXCp516hlkLsr6nl5oGn9ejh9+QpuZauQkqMuaOpc3M7JxR11run1KbokNCc/H1r9g71Hi/5+eDk6wNPJEV6ODvBycoKnkwOMQiBXp4NGp0euTo88nR65Oh3y9HqotPnIKiyomDOVqyr930nVB/OGrFGViyug8KsmbP82pVIphBBCqVRWeixVMR62qtkC/OuInVvPin27o0WfZ18y5c0bo8aJfbujxbZNp0Utv9qVHidb1W78e8NmbWPusFnTmDds1rSHnTeW7I8XqRM9AiQSCT4ZPwMKhQNORR7G9p1/mB5bv2EZzp47BScnZ0yeOBd2dpzHhoiIiKgisLgiegS8MOBVtGzRDrm5asydN8XsMaPRiJmzP4FKlYWmTVth5PAPKilKIiIiokcbi6sqTi5XwK4CZgq0hrOzEn16v4SBLwxHzZr+lR1OlWRvb//Q9+nnG4A3Rn0EAPjhp6+Rcjup2DK379zCN/MmAwBeHvIm2rS+/4QWjzIHByd079YXIT0HwFXpXtnhEBER0SOE1wdVcX16v4S3Qj/G2dM3MWjgSJw8dRiXo89Dr39IszFJJHi8TUf0fuZFdH4qBAqFAwDgvXc+R9SF0/h73zbsP7ADGZlpDyWeIrUD6qJN6w5o2rQl0tJu48LFf3Dx0j/Iysp4qHHY2cnQqmU7dH4qBJ079YSnZw1EXzmPiMijiIg8jIuXzsJg0FfY/iUSCT7+aAYcHZ1w5p8T2LLt91KXPXh4F7ZuW4t+fYfg88++Ruhb/ZGdXfHHSyq1Q926DeHnG4CbN28gPiEWRuPDnaBEIpGgdasn8UzI83i6Sy84OjoDAAwGPc6eO4VDh3fh8JE9SE27/VDjAgBXpTsCA+sjMzMNt5JvVmi+lIdMZg/9A05OYSt+vgFo2KAZsrIzERNzEercnMoOiYiI6L44W2AJqtLMNZ99MhvP9HrBrE+jycPFS//g7LlTOHc+AukZd6DVapGf/2/T6fIfaL+1/GrjmV4v4plez6OmTy1Tf2zsFWRmZaBVyycgLZzK2GAw4PQ/x/D3vm04fmI/cnPV0Ot1MFr5Y6AlqVnTH21aP4k2rTugTesOqOFd/IeNASAxMQ4XL53Fxcv/4OLFf3D7zi1otVpotRqbndArFA5o1/YpdHkqBB07dIOrq3upy+bmqnHm7AlERh7BufOnoFJlI19X9DrlP3CR/Fy/ofho7BfIy8vFG2/3R9KtBNNjJeWxg4Mjvl+8AUGB9REXfw1XrlxAWtptpKbdLrxNQWrabaiyM6E36KHX6y0+2a9VKxBNGrdAk8Yt0bRJSzSo3xQODo6mxzWaPFyPjcbVmEuIibmIqzGXcD02+oFztiT+/kHo1fN59AoZAN+7RltvJt6ARpOHBvWbmi1/4eIZHDq8G/+cPQm1WgWNJhd5mjzk5eXaJH+USjc0avgYGjdqjkYNH0Ojhs3h5xdgetxg0CM5ORE3E+OQmHgDiUnxuJkYB1VOFrQaDbT5Gmi1GuRrtdDma5Cfry1zmvPSSCQS+Nb0R726jVGnbkPUq9MI9eo2QkBAXchkMmRkpOJG3DXExccgLv4a4uOvIS7+OtIqqAB1dnJB48Yt0LRpKzRr0gpNm7SCh4eX2TI3E2/gypULuHL136ZWc3axqqIq/d9J1QfzhqxRlWcLrPTiasyYMfjkk0/g5+eHCxcu4MMPP8Thw4dLXV4ul2Pq1Kl49dVX4evri5s3b2LGjBlYvny5aZmxY8dizJgxCAwMRGpqKv744w9MnDgRWq22XDFVpTe6RCJB88daY/u2vfj119/RrEnrYiccpcnP18Jg0MNgNEIYjTAajTAYDTAW3RfGghMzcffvAwlIJBLU8qtt2o5KlYW/923DjvA/EX2l4Idqvbx80PXp3ujRrS+aNm1V4v4NBj10Oh10unzodPnQ6/Wmfdy7TxT+lgwAs5NFIQBHB0fUqOFb7LlFXTiDqAun4e3lg2bNWqNOUIP7Hg+dLh/afC20mjxo87XQ6/WmnZjtWxSP426+vgFwdPz397wyMtJw9PjfOHx4N+Lir6FVq/Zo93gntH38Kbi7e943JqPRaCqGjYWvkRDGu14zQ+Hv7fx7jEThsYMQ8PX1h1yuwKIlM7DhrxVm2y4tj+vXa4xFC9eaFTxl0et10Ov10Bv0MOj1pjiNQsBoMBTkklHA2dmlxGIzR61CUmIcAgLqwsnJucR95OfnF+SrQQ+DwQC9Xldwa9D/+1qYfkNJmPqKvUyFHXZ2dvD3D/o3hpxs7Nu/HeG7N+LCxf9v796DmrrTPoB/c5KTcFUrFLkZKqjl4qusgDuvoiiK27GOl3ZHZ60dpltnu7izWt33pV7q0h1cq60Lq65sx1mlK+tanL6jlWm3tTr0ImhXUOsiWEWCYkQKLUXugeT3/gGeEgKCMZLQfj8zz5D88kvOk5OHTJ6ck3MuAOjaMhIfn4RZ8fMxKWrqfdeByWRCa1szTCYThMXSlYPF0n0uJIvV62OTlxDQublZfVHRU83XtzHCe5RVXQ3WvfXUFZ3KOjObOyG6v+DoeY63rusCj43y6fe1uB+TqR2mjq7XymLuek+5t1yLxdzv8++5/O+Hu67LGhkBAWOVL2zu6egwwWC4ihEjH7NqjntqbW1Wnn/PmjGbO5UveGzqp598rHMbxMogK2pJQtSkKFwuuQyzA79cox821g0NZP3/JtvsacPmqh/Lli1DTk4OVq9ejYKCArz00ktYtWoVIiMjUVVV1ed9jh07hjFjxuDVV19FeXk5/Pz8oNFocObMGQDAihUrsH//fvzyl79EYWEhJk6ciLfffhu5ublYv379oPJypeaqr3z0+lBMmTwNUybHITI8Gh6entDKOuh0bjYfTuxlsVhQVFyADz/6P5wuPHXfrQqBAWMxZ87TmDdnIZ54YoJDlt+b2dyJsiuXcOHiF7hw8Swul16AyWTdLHt6eiMifDIiI6IRGRGN8PD/wsgRjz2SfO7cuYXPC07idMHHKLl8vs+tdCqVCmGh4YiNjUfs1Ol4cuIkaLVu0Gr7P0GtPb68dA7r/ud5m2bwfnU8xi8Qk6KmwsfHD74+fvDpDl8fP/j6jlF2/7SHyWRC+fVSXPnqP11x5RJuGSuVxj0oMAQTxkdg/PhITJgQiQlhkQM2ofYym80oKi7ARx8fRUHhKZua6cnHxw8z/nsuZsYnISRkPNzd3OHu7uHwoyv23Pry1dUSXCsvVba++Pj4ITgoBEFBIQgOegJBQSEICtDDw8MLOp0OWp0bdFodZNkxNWQymXCz6joqDFdhMFxFheEqvq414tq1q5g2bToe9/GHXh+GEH0Y9PowBAWOfaRHm7xdXYWyK1+irOwSSq9cRHl5mfLeM2LEY5g4IbJ7i5/tVj8iIvphembZDNTX11mNsbnqx9mzZ3H+/HmsXr1aGSstLcWxY8ewadMmm/k/+9nP8M477yA0NBT19X3/VmTPnj2IiIjAvHnzlLGdO3di2rRpmDVr1qDycvXm6n40GhlarRY6rZtyMAxJUkMlSVBLUvdlFdSSGlB1naBXpepqBL6/rsKdGqNdu/9oNDJkWQtZI0PWarvykbXd4/J9lwl0j+He5a7HtFgsqDBcRWtr8wPno1KpIMtauOncoXNzg07rBp2bG9x07pAkqddy0WPZqn4eEWhoqIeh8uoD59Izp67XSQetrO36q9VBJakgSWpIKkl5jVQqCZJaUtbRvfWjUgGSJMFiseBaeSna2lptlvMwdSzLMtRqGRqNpjvkrlB3XYdKBUklQZKk7vUoQZJUMHWYcOPG9Qfe3XHkyMe661UDjVoDtVrddVmjgVrT9WHeeh1AWQ+9123PyzerDDZvyA9KlmW4u3nCrbvZ0mp13XlISh13Xe47t3tjZrMZlTfKHbIbmySpodXqoNPpoNHIUEvqrnWlrDs11BrZ+n+tKxmoumu8ubkRt4w3bHb7vF/dyLKM0aP9lNdHWda9y5Lm3mIUtv9jtoQQqKoyPPBvN728RsDLa4RSM9brQIYkqfr9375fPve5yQlcKpn78vDwwHvvvYfFixejpaXF2enQMMG6oYH8p6QIHb1OEu/KzZXTDmghyzJiYmKwfft2q/ETJ05g+vTpfd5n0aJFKCoqQmpqKp5//nk0Nzfj+PHj2LJlC9ra2gAAp0+fxsqVKxEXF4dz585h3LhxWLBgAf7+97/3m4tWq4VOp1Oue3t7W/11Nnvy6TSb0Nn6cL9heZjnL2CGydQKk6kVjnir1Gikh86nra0ZbW3NwN2Hz8dRtXHvdWpptf+NQZY1kGXbfBxTxwJmcwfM5g4Mcq9auLu7AXiwLV8WSyfa2h7NgRwc8VoJmNHa1oTWtoc7oIIkOfZ9xWLphMlk/3rz8LDdNXSgumlpccA/UD8efN0INDc3PJJc6MF5e3tjtI8nKgxlLvHFJA0PrBsaiJubG9zcrD9XDPVn9QdZjtOaK19fX2g0GtTU1FiN19TUwN/fv8/7hIaGIj4+Hm1tbVi6dCl8fX2RlZWF0aNH48UXXwQA5Obm4vHHH8fp06e7t1rIyMrKwo4dO/rNZePGjXjttddsxo1Go/1P8BFwtXxoeGDdkD1YN2Qv1g7Zg3VD9nDFunH6odh7/05EpVL1eyABSZIghMBzzz2Hu3e7vj1dv3493n33XfzmN79BW1sbEhISsHnzZqxevRpffPEFxo8fj127dqG6uhpbt27t83Fff/11ZGRkKNe9vb1hNBoRFBTkEt+iuFo+NDywbsgerBuyF2uH7MG6IXsMdd3cW95gOK25qqurQ2dnp81WKj8/P5utWfdUV1fDaDQqjRUAlJWVQZIkBAcHo7y8HOnp6cjJycH+/fsBACUlJfD09MS+ffvwxz/+sc/GzWQywWSy3YWusbHRpf7RXS0fGh5YN2QP1g3Zi7VD9mDdkD1csW4cc2g5O3R0dKC4uBhJSUlW40lJSSgsLOzzPgUFBQgMDISn5/eHD544cSLMZjNu3boFoOuHkb2P3GY2m3v92JyIiIiIiMixnNZcAUBGRgZWrVqFF154AeHh4cjIyIBer8dbb70FANi2bZvVgSj++c9/4ptvvkF2djYiIiIwc+ZMvPnmmzhw4IByQIu8vDykpKRg+fLleOKJJzBv3jykp6fj+PHjDj2pLRERERERUU9O/c3VkSNH4OPjg9///vcICAhASUkJFixYgJs3bwIAAgICoNfrlfnNzc1ISkrCnj17UFRUhG+++QZHjhzBq6++qszZunUrhBDYunUrgoKCUFtbi7y8PGzevHnInx8REREREf14OPU8V65qOJ/niuge1g3Zg3VD9mLtkD1YN2QPVz7PlVN3CyQiIiIiIvqhYHNFRERERETkAGyuiIiIiIiIHIDNFRERERERkQOwuSIiIiIiInIANldEREREREQOwOaKiIiIiIjIAZx6EmFX5+3t7ewUAHyfh6vkQ8MD64bswbohe7F2yB6sG7LHUNfNgyyHJxHuQ2BgIIxGo7PTICIiIiIiFxEUFITbt2/fdw6bq34EBga6zJnCvb29YTQaERQU5DI5ketj3ZA9WDdkL9YO2YN1Q/ZwRt14e3sP2FgB3C2wX4NZeUOtsbGRbzz0wFg3ZA/WDdmLtUP2YN2QPYaybga7HB7QgoiIiIiIyAHYXBERERERETkAm6thoL29Ha+99hra29udnQoNI6wbsgfrhuzF2iF7sG7IHq5cNzygBRERERERkQNwyxUREREREZEDsLkiIiIiIiJyADZXREREREREDsDmioiIiIiIyAHYXLm4lJQUVFRUoLW1FUVFRYiPj3d2SuRCNmzYgH//+9+4e/cuampqcPToUUycONFmXlpaGoxGI1paWpCfn4/IyEgnZEuuasOGDRBCIDMz02qcdUN9CQwMRE5ODurq6tDc3IwLFy5g6tSpVnNYO9STWq1Geno6Kioq0NLSguvXr2PLli1QqVRW81g3P24zZ87E8ePHYTQaIYTA4sWLbeYMVCNarRa7d+9GbW0tmpqa8N577yEoKGionoJCMFwzli1bJtrb28WLL74owsPDRWZmpmhsbBRjx451em4M14h//etfIjk5WURGRorJkyeLvLw8UVlZKTw8PJQ5qampoqGhQSxdulRERUWJw4cPC6PRKLy8vJyeP8P5ERsbKyoqKsTFixdFZmamMs66YfQVo0aNEgaDQRw4cEDExcWJkJAQkZiYKEJDQ5U5rB1G79i0aZOora0VCxYsECEhIeLZZ58Vd+/eFWvWrGHdMJR46qmnRHp6uli6dKkQQojFixdb3T6YGsnKyhJVVVVi7ty5Ijo6Wpw6dUpcuHBBSJI0lM/F+SuT0XecPXtWZGVlWY2VlpaKbdu2OT03hmuGr6+vEEKImTNnKmO3b98WqampynWtVivq6+vFr371K6fny3BueHp6iq+++krMnTtX5OfnWzVXrBtGX/H666+Lzz777L5zWDuM3pGXlyf+9re/WY29++674uDBg8p11g2jZ/TVXA1UIyNGjBDt7e1i2bJlypyAgADR2dkp5s+fP2S5c7dAFyXLMmJiYnDixAmr8RMnTmD69OlOyopc3ciRIwEA3377LQBg3LhxCAgIsKojk8mETz/9lHVE2Lt3L95//32cOnXKapx1Q/1ZtGgRioqKcOTIEdTU1OD8+fNYtWqVcjtrh/py+vRpzJ07FxMmTAAATJ48GfHx8fjggw8AsG5oYIOpkZiYGGi1Wqs51dXVKCkpGdI60gzZkuiB+Pr6QqPRoKamxmq8pqYG/v7+TsqKXF1GRgY+//xzXL58GQCUWumrjkJCQoY8P3Idy5cvx9SpUxEXF2dzG+uG+hMaGoqUlBRkZGRg27ZtmDZtGnbv3o329nbk5OSwdqhPO3bswMiRI3HlyhWYzWao1Wps3rwZ77zzDgC+59DABlMj/v7+aG9vx3fffWczZyg/O7O5cnFCCKvrKpXKZowIAP7yl78o3wb2xjqinoKDg7Fr1y7Mnz8f7e3t/c5j3VBvkiShqKgImzdvBgBcvHgRUVFRSElJQU5OjjKPtUM9LV++HCtXrsSKFStw+fJlREdH489//jNu376NgwcPKvNYNzQQe2pkqOuIuwW6qLq6OnR2dtp02n5+fjZdO9Hu3buxaNEizJkzB0ajURm/c+cOALCOyEpMTAzGjBmD4uJidHR0oKOjA7Nnz8aaNWvQ0dGh1Abrhnqrrq5GaWmp1VhZWRn0ej0AvudQ3958801s374dubm5KCkpwT/+8Q9kZmZi48aNAFg3NLDB1MidO3eg0+kwatSofucMBTZXLqqjowPFxcVISkqyGk9KSkJhYaGTsiJXtGfPHjzzzDNITExEZWWl1W0GgwHV1dVWdSTLMhISElhHP2KnTp3CpEmTEB0drcS5c+dw6NAhREdHo6KignVDfSooKMCTTz5pNTZx4kTcuHEDAN9zqG8eHh6wWCxWY2azGZLU9TGUdUMDGUyNFBcXw2QyWc3x9/fHpEmThryOnH5EEEbfce9Q7C+88IIIDw8XGRkZorGxUej1eqfnxnCN2Lt3r6ivrxezZs0SY8aMUcLNzU2Zk5qaKurr68WSJUtEVFSUOHToEA9vy7CJ3kcLZN0w+orY2FhhMpnExo0bRVhYmPjFL34hmpqaxIoVK5Q5rB1G78jOzhZVVVXKodiXLFkivv76a7F9+3bWDUMJT09PMWXKFDFlyhQhhBAvv/yymDJlinIKosHUSFZWlrh586ZITEwU0dHR4uTJkzwUO8M6UlJShMFgEG1tbaKoqMjqENsMRn+Sk5Ot5qWlpYnbt2+L1tZW8cknn4ioqCin585wrejdXAGsG0bf8fTTT4tLly6J1tZWUVpaKlatWmUzh7XD6BleXl4iMzNTVFZWipaWFlFeXi7S09OFLMtW81g3P+5ISEjo8zNNdnb2oGtEp9OJ3bt3i7q6OtHc3CyOHz8ugoODh/R5qLovEBERERER0UPgb66IiIiIiIgcgM0VERERERGRA7C5IiIiIiIicgA2V0RERERERA7A5oqIiIiIiMgB2FwRERERERE5AJsrIiIiIiIiB2BzRURERERE5ABsroiIiB6SwWDA2rVrnZ0GERE5GZsrIiIaVrKzs3H06FEAQH5+PjIzM4ds2cnJyaivr7cZj4uLw759+4YsDyIick0aZydARETkbLIso6Ojw+7719XVOTAbIiIarrjlioiIhqXs7GzMnj0bL7/8MoQQEEIgJCQEABAREYH3338fjY2NuHPnDg4ePAgfHx/lvvn5+dizZw/+9Kc/oba2Fh9//DEAYN26dbh06RKamppw8+ZN7N27F56engCAhIQEvP322xg1apSyvLS0NAC2uwWOHTsWx44dQ2NjIxoaGpCbmws/Pz/l9rS0NFy4cAErV66EwWDAd999h8OHD8PLy+uRrzciInp02FwREdGwtHbtWhQWFmLfvn3w9/eHv78/qqqq4O/vj08//RQXL15EbGwsnnrqKYwZMwZHjhyxun9ycjI6OzsxY8YMvPTSSwAAi8WCNWvWYNKkSUhOTkZiYiLeeOMNAEBhYSHWrl2LhoYGZXk7d+7sM7djx45h9OjRSEhIQFJSEsLCwpCbm2s1JywsDEuWLMHChQuxcOFCJCQkYMOGDY9gTRER0VASDAaDwWAMl8jOzhZHjx4VAER+fr7IzMy0uv0Pf/iD+PDDD63GgoKChBBCTJgwQbnf+fPnB1zWz3/+c1FbW6tcT05OFvX19TbzDAaDWLt2rQAg5s2bJzo6OkRwcLBye0REhBBCiNjYWAFApKWliaamJuHl5aXM2bFjhzhz5ozT1y+DwWAw7A/+5oqIiH5QYmJiMGfOHDQ2NtrcFhYWhmvXrgEAioqKbG6fPXs2Nm3ahMjISIwYMQIajQbu7u7w8PBAS0vLoJYfERGBqqoq3Lp1SxkrKytDfX09IiIilOVWVlaiqalJmVNdXW216yAREQ0/bK6IiOgHRZIk5OXl4ZVXXrG5rbq6Wrnc3NxsdZter8cHH3yAt956C1u2bMG3336L+Ph4HDhwALIsD3r5KpUKQogBx3sfQEMIAUni3vpERMMZmysiIhq2TCYT1Gq11dj58+fx7LPPorKyEmazedCPFRsbC41Gg9/97ndKE7Rs2bIBl9dbaWkp9Ho9goODla1XERERGDVqFMrKygadDxERDT/8ioyIiIatyspK/PSnP0VISAh8fHygUqmwd+9ejB49GocPH0ZcXBzGjRuHpKQk7N+//75bhq5fvw5ZlvHb3/4W48aNw8qVK/HrX//aZnne3t5ITEyEj48P3N3dbR7n5MmTuHTpEg4dOoSf/OQniIuLw8GDB/HJJ5+guLjY4euAiIhcB5srIiIatnbu3Amz2YzS0lLU1dVBr9ejuroaM2bMgFqtxkcffYSSkhLs2rULDQ0NsFgs/T7Wl19+iXXr1uGVV15BSUkJnnvuOWzcuNFqzpkzZ/DXv/4Vubm5qKurQ2pqap+PtWTJEtTX1+Ozzz7DyZMnUVFRgeXLlzv0uRMRketRoevIFkRERERERPQQuOWKiIiIiIjIAdhcEREREREROQCbKyIiIiIiIgdgc0VEREREROQAbK6IiIiIiIgcgM0VERERERGRA7C5IiIiIiIicgA2V0RERERERA7A5oqIiIiIiMgB2FwRERERERE5AJsrIiIiIiIiB/h/VB2/ypPtrkIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Learning curve based on ACC and LOSS\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results[\"train_acc\"], label='Training Accuracy')\n",
    "plt.plot(results[\"test_acc\"], label='Val Accuracy')\n",
    "plt.plot(results[\"train_loss\"], label='Training Loss')\n",
    "plt.plot(results[\"test_loss\"], label='Val Loss')\n",
    "plt.title('Training and Val Accuracy over Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy & Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN Regression: 0.829523643343221\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy of KNN Regression:\",accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries to Build Ensemble Model : Random Forest Classifier \n",
    "# Create the parameter grid based on the results of random search \n",
    "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid=[{&#x27;C&#x27;: [1, 10, 100, 1000], &#x27;gamma&#x27;: [0.001, 0.0001],\n",
       "                          &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "                         {&#x27;C&#x27;: [1, 10, 100, 1000], &#x27;kernel&#x27;: [&#x27;linear&#x27;]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid=[{&#x27;C&#x27;: [1, 10, 100, 1000], &#x27;gamma&#x27;: [0.001, 0.0001],\n",
       "                          &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "                         {&#x27;C&#x27;: [1, 10, 100, 1000], &#x27;kernel&#x27;: [&#x27;linear&#x27;]}])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: SVC</label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [1, 10, 100, 1000], 'kernel': ['linear']}])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "# Performing CV to tune parameters for best SVM fit \n",
    "svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for training data: 0.8009292227746212 \n",
      "\n",
      "Best C: 100 \n",
      "\n",
      "Best Kernel: rbf \n",
      "\n",
      "Best Gamma: 0.001 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the accuracy score\n",
    "print('Best score for training data:', svm_model.best_score_,\"\\n\") \n",
    "\n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
    "print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
    "print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_test = encoder.transform(y_train)\n",
    "\n",
    "final_model = svm_model.best_estimator_\n",
    "Y_pred = final_model.predict(X_test)\n",
    "Y_pred_label = list(encoder.inverse_transform(Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create the SVM model with the best parameters\n",
    "svm_model = SVC(C=100, kernel='rbf', gamma=0.001)\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, cohen_kappa_score, roc_curve\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define confidence interval function\n",
    "def confidence_interval(data):\n",
    "    return np.percentile(data, 97.5), np.percentile(data, 2.5)\n",
    "\n",
    "# Define the Keras MLP model function\n",
    "def create_mlp(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, input_dim=input_dim, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(5, activation='softmax')  # 5 output units for the 5 classes\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class KANWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_dims, grid, k, steps=100):\n",
    "        self.input_dims = input_dims\n",
    "        self.grid = grid\n",
    "        self.k = k\n",
    "        self.steps = steps\n",
    "        self.kan_model = KAN(input_dims, grid=grid, k=k)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.to_numpy()\n",
    "        \n",
    "        train_input = torch.tensor(X, dtype=torch.float32)\n",
    "        train_label = torch.tensor(y, dtype=torch.long)\n",
    "        val_input = train_input  # Assuming using same data for simplicity, modify as needed\n",
    "        val_label = train_label  # Assuming using same data for simplicity, modify as needed\n",
    "        \n",
    "        # Functions for getting accuracy scores while training\n",
    "        def train_acc():\n",
    "            preds = torch.argmax(self.kan_model(train_input), dim=1)\n",
    "            return torch.mean((preds == train_label).float())\n",
    "\n",
    "        def test_acc():\n",
    "            preds = torch.argmax(self.kan_model(val_input), dim=1)\n",
    "            return torch.mean((preds == val_label).float())\n",
    "\n",
    "        # KAN model training\n",
    "        self.kan_model.train({'train_input': train_input, 'train_label': train_label, \n",
    "                              'test_input': val_input, 'test_label': val_label},\n",
    "                             metrics=(train_acc, test_acc),\n",
    "                             opt=\"LBFGS\", steps=self.steps, loss_fn=torch.nn.CrossEntropyLoss())\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        test_input = torch.tensor(X, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            preds = torch.argmax(self.kan_model(test_input), dim=1)\n",
    "        return preds.numpy()\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        test_input = torch.tensor(X, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            output = self.kan_model(test_input)\n",
    "        return torch.nn.functional.softmax(output, dim=1).numpy()\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        return accuracy_score(y, preds)\n",
    "\n",
    "\n",
    "\n",
    "question_numbers = [1, 2, 3, 4, 5, 6, 7, 8]         # Numbers of questions from DASS to run through\n",
    "target = \"Anxiety_Level\"\n",
    "models_to_train = 10        # Number of models for each number of questions from DASS\n",
    "models_per_question = 50    # Number of ensembles per model\n",
    "test_split = 0.1\n",
    "model_type = \"lr\"     # Specify model type (xgb, rf, lr, svm, mlp)\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "questions = [40, 28, 20, 36, 9, 2, 25, 30, 7, 4]\n",
    "\n",
    "\n",
    "ACCS = []\n",
    "AUCS = []\n",
    "PRES = []\n",
    "RECS = []\n",
    "F1S = []\n",
    "AUC_STDEV = []\n",
    "F1_STDEV = []\n",
    "AUC_95CI_U = []\n",
    "AUC_95CI_D = []\n",
    "F1_95CI_U = []\n",
    "F1_95CI_D = []\n",
    "\n",
    "features_df = pd.read_csv(os.path.join(data_folder, \"features.csv\"))\n",
    "labels_df = pd.read_csv(os.path.join(data_folder, \"labels.csv\"))\n",
    "questions = [40, 28, 20, 36, 9, 2, 25, 30, 7, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inner Loop Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  10%|█         | 1/10 [01:17<11:41, 77.98s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  20%|██        | 2/10 [02:35<10:19, 77.43s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  30%|███       | 3/10 [03:51<08:58, 77.00s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  40%|████      | 4/10 [05:09<07:45, 77.59s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  50%|█████     | 5/10 [06:29<06:31, 78.39s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  60%|██████    | 6/10 [07:45<05:10, 77.61s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  70%|███████   | 7/10 [09:04<03:53, 77.91s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  80%|████████  | 8/10 [10:22<02:35, 77.93s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  90%|█████████ | 9/10 [11:42<01:18, 78.57s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inner Loop Progress:   0%|          | 0/10 [00:00<?, ?it/s]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inner Loop Progress:  10%|█         | 1/10 [01:19<11:57, 79.67s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  20%|██        | 2/10 [02:38<10:34, 79.29s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  30%|███       | 3/10 [03:52<08:56, 76.69s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  40%|████      | 4/10 [05:07<07:37, 76.18s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  50%|█████     | 5/10 [06:22<06:18, 75.65s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  60%|██████    | 6/10 [07:35<04:58, 74.69s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  70%|███████   | 7/10 [08:47<03:42, 74.05s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  80%|████████  | 8/10 [10:02<02:28, 74.33s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Inner Loop Progress:  90%|█████████ | 9/10 [11:17<01:14, 74.42s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inner Loop Progress:   0%|          | 0/10 [00:00<?, ?it/s]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inner Loop Progress:  10%|█         | 1/10 [01:15<11:22, 75.87s/it]/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-07-19 15:32:59.755885: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Expected begin, end, and strides to be 1D equal size tensors, but got shapes [0], [1], and [1] instead.\n",
      "                                                                   2024-07-19 15:32:59.755929: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Expected begin, end, and strides to be 1D equal size tensors, but got shapes [0], [1], and [1] instead.\n",
      "\t [[{{function_node __inference_one_step_on_data_219671842}}{{node strided_slice}}]]\n",
      "\r"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node strided_slice defined at (most recent call last):\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n\n  File \"/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/3999284932.py\", line 106, in <module>\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py\", line 1501, in fit\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py\", line 770, in fit\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py\", line 938, in _fit\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py\", line 535, in _fit_keras_model\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 314, in fit\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 117, in one_step_on_iterator\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 104, in one_step_on_data\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\nExpected begin, end, and strides to be 1D equal size tensors, but got shapes [0], [1], and [1] instead.\n\t [[{{node strided_slice}}]] [Op:__inference_one_step_on_iterator_219671911]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 106\u001b[0m\n\u001b[1;32m     90\u001b[0m mlp \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39mcreate_mlp, input_dim\u001b[38;5;241m=\u001b[39mdf_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# svm = SVC(C=100, kernel='rbf', gamma=0.001, probability=True)\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# kan = KANWrapper(input_dims=[10, 7, 5], grid=10, k=3)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# clf.fit(df_train, gt_train.values.ravel())\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m \u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m xgbpprist \u001b[38;5;241m=\u001b[39m mlp\u001b[38;5;241m.\u001b[39mpredict(df_prist)\n\u001b[1;32m    109\u001b[0m xgbpprist \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(xgbpprist)\n",
      "File \u001b[0;32m~/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:1501\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[1;32m   1500\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m-> 1501\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:770\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m    767\u001b[0m )\n\u001b[1;32m    768\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:938\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 938\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_keras_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py:535\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m initial_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_ \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node strided_slice defined at (most recent call last):\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n\n  File \"/var/folders/ck/2s74pj3s3_n1wnn8jc86lr3r0000gn/T/ipykernel_64809/3999284932.py\", line 106, in <module>\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py\", line 1501, in fit\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py\", line 770, in fit\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py\", line 938, in _fit\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/scikeras/wrappers.py\", line 535, in _fit_keras_model\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 314, in fit\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 117, in one_step_on_iterator\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 104, in one_step_on_data\n\n  File \"/Users/rogersyang/Documents/SUDSCodeBase/long_to_short_dass/long-to-short/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\nExpected begin, end, and strides to be 1D equal size tensors, but got shapes [0], [1], and [1] instead.\n\t [[{{node strided_slice}}]] [Op:__inference_one_step_on_iterator_219671911]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For different numbers of questions from DASS-42\n",
    "for num_questions in range(8, 11):\n",
    "    models_info = {}\n",
    "\n",
    "    accs = []\n",
    "    aucs = []\n",
    "    pres = []\n",
    "    recs = []\n",
    "    f1s = []\n",
    "    auc_stdev = []\n",
    "    f1_stdev = []\n",
    "    auc_95ci_u = []\n",
    "    auc_95ci_d = []\n",
    "    f1_95ci_u = []\n",
    "    f1_95ci_d = []\n",
    "    lst_comb = []\n",
    "\n",
    "    model_num = 0\n",
    "    for a in range(10):  # Adjust the number of models to train as needed\n",
    "        model = {}\n",
    "\n",
    "        print(\"Training model\", a)\n",
    "        cols = [\"gender_m\", \"gender_f\", \"region_other\", \n",
    "                \"region_east\", \"region_west\", \"age_norm\"]\n",
    "\n",
    "        if num_questions == 1:\n",
    "            if a >= len(questions):\n",
    "                break\n",
    "            question_nums = [questions[a]]\n",
    "        else:\n",
    "            question_nums = random.sample(questions, num_questions)\n",
    "            question_nums.sort()\n",
    "            while question_nums in lst_comb:\n",
    "                question_nums = random.sample(questions, num_questions)\n",
    "            lst_comb.append(question_nums)\n",
    "\n",
    "        for q in question_nums:\n",
    "            for j in range(4):\n",
    "                col_name = f\"Q{q}A_{j}\"  # Adjust column name formatting as necessary\n",
    "                if col_name in features_df.columns:\n",
    "                    cols.append(col_name)\n",
    "                else:\n",
    "                    print(f\"Warning: Column {col_name} not found in features_df. Skipping this column.\")\n",
    "\n",
    "        features = features_df[cols]\n",
    "\n",
    "        labels = labels_df.copy()\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        shufId = np.random.permutation(len(labels))\n",
    "        index = int(test_split * len(labels))\n",
    "\n",
    "        df_prist = features.iloc[shufId[0:index]]\n",
    "        df_trainvalid = features.iloc[shufId[index:]]\n",
    "\n",
    "        gt_prist = labels.iloc[shufId[0:index]]\n",
    "        gt_trainvalid = labels.iloc[shufId[index:]]\n",
    "\n",
    "        df_prist.to_csv(os.path.join(data_folder, \"prist_features.csv\"), index=False)\n",
    "        gt_prist.to_csv(os.path.join(data_folder, \"prist_labels.csv\"), index=False)\n",
    "\n",
    "        accs1 = []\n",
    "        aucs1 = []\n",
    "        pres1 = []\n",
    "        recs1 = []\n",
    "        f1s1 = []\n",
    "        ensemble_models = []\n",
    "\n",
    "        for b in tqdm(range(10), desc=\"Inner Loop Progress\", leave=False):  # Adjust the number of iterations as needed\n",
    "            if b % 10 == 0:\n",
    "                print(\"Training iteration\", b)\n",
    "\n",
    "            np.random.seed(b)\n",
    "            shufId = np.random.permutation(len(gt_trainvalid))\n",
    "            index = int((1/9) * len(gt_trainvalid))\n",
    "\n",
    "            df_valid = df_trainvalid.iloc[shufId[0:index]]\n",
    "            df_train = df_trainvalid.iloc[shufId[index:]]\n",
    "\n",
    "            gt_valid = gt_trainvalid.iloc[shufId[0:index]]\n",
    "            gt_train = gt_trainvalid.iloc[shufId[index:]]\n",
    "\n",
    "            df_valid = df_valid.reset_index(drop=True)\n",
    "            df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "            gt_valid = gt_valid.reset_index(drop=True)\n",
    "            gt_train = gt_train.reset_index(drop=True)\n",
    "\n",
    "            # Define the individual models\n",
    "            mlp = KerasClassifier(build_fn=create_mlp, input_dim=df_train.shape[1], epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "            # knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "            # svm = SVC(C=100, kernel='rbf', gamma=0.001, probability=True)\n",
    "            # kan = KANWrapper(input_dims=[10, 7, 5], grid=10, k=3)\n",
    "\n",
    "            # Define the stacking classifier\n",
    "            # estimators = [\n",
    "            #     ('mlp', mlp),\n",
    "            #     ('knn', knn),\n",
    "            #     ('svm', svm),\n",
    "            #     ('kan', kan)\n",
    "            # ]\n",
    "\n",
    "            # clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "            # clf.fit(df_train, gt_train.values.ravel())\n",
    "            mlp.fit(df_train, gt_train.values.ravel())\n",
    "\n",
    "            xgbpprist = mlp.predict(df_prist)\n",
    "            xgbpprist = pd.DataFrame(xgbpprist)\n",
    "\n",
    "            # Evaluation\n",
    "            target_names = ['class1', 'class2', 'class3', 'class4', 'class5']  # Adjust class names as needed\n",
    "            cr = classification_report(gt_prist, xgbpprist, target_names=target_names, output_dict=True)\n",
    "            precision = cr[\"weighted avg\"][\"precision\"]\n",
    "            recall = cr[\"weighted avg\"][\"recall\"]\n",
    "            f1score = cr[\"weighted avg\"][\"f1-score\"]\n",
    "\n",
    "            acc_score = accuracy_score(gt_prist, xgbpprist)\n",
    "            auc_score = roc_auc_score(label_binarize(gt_prist, classes=[0, 1, 2, 3, 4]), label_binarize(xgbpprist, classes=[0, 1, 2, 3, 4]), multi_class='ovr')\n",
    "            fpr, tpr, thresh = roc_curve(label_binarize(gt_prist, classes=[0, 1, 2, 3, 4]).ravel(), label_binarize(xgbpprist, classes=[0, 1, 2, 3, 4]).ravel())\n",
    "            plt.plot(fpr, tpr)           \n",
    "\n",
    "            accs1.append(acc_score)\n",
    "            aucs1.append(auc_score)\n",
    "            pres1.append(precision)\n",
    "            recs1.append(recall)\n",
    "            f1s1.append(f1score)\n",
    "            ensemble_models.append(mlp)\n",
    "\n",
    "        mean_acc1 = np.mean(accs1)\n",
    "        mean_auc1 = np.mean(aucs1)\n",
    "        stdev_auc1 = np.std(aucs1)\n",
    "        ci_auc1_u, ci_auc1_d = confidence_interval(aucs1)\n",
    "        mean_pre1 = np.mean(pres1)\n",
    "        mean_rec1 = np.mean(recs1)\n",
    "        mean_f11 = np.mean(f1s1)\n",
    "        stdev_f11 = np.std(f1s1)\n",
    "        ci_f11_u, ci_f11_d = confidence_interval(f1s1)\n",
    "\n",
    "        accs.append(mean_acc1)\n",
    "        aucs.append(mean_auc1)\n",
    "        auc_stdev.append(stdev_auc1)\n",
    "        auc_95ci_u.append(ci_auc1_u)\n",
    "        auc_95ci_d.append(ci_auc1_d)\n",
    "        pres.append(mean_pre1)\n",
    "        recs.append(mean_rec1)\n",
    "        f1s.append(mean_f11)\n",
    "        f1_stdev.append(stdev_f11)\n",
    "        f1_95ci_u.append(ci_f11_u)\n",
    "        f1_95ci_d.append(ci_f11_d)\n",
    "\n",
    "        model[\"questions\"] = question_nums\n",
    "        model[\"knn_params\"] = mlp.get_params()\n",
    "        model[\"acc_score\"] = acc_score\n",
    "        model[\"auc_score\"] = mean_auc1\n",
    "        model[\"f1_score\"] = mean_f11\n",
    "\n",
    "        models_info[model_num] = model\n",
    "        model_num += 1\n",
    "\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_auc = np.mean(aucs)\n",
    "    stdev_auc = np.mean(auc_stdev)\n",
    "    ci_auc_u = np.mean(auc_95ci_u)\n",
    "    ci_auc_d = np.mean(auc_95ci_d)\n",
    "    mean_pre = np.mean(pres)\n",
    "    mean_rec = np.mean(recs)\n",
    "    mean_f1  = np.mean(f1s)\n",
    "    stdev_f1 = np.mean(f1_stdev)\n",
    "    ci_f1_u = np.mean(f1_95ci_u)\n",
    "    ci_f1_d = np.mean(f1_95ci_d)\n",
    "\n",
    "    percentile_list = pd.DataFrame(\n",
    "    {\n",
    "        'accuracy': accs,\n",
    "        'auc_roc': aucs,\n",
    "        'auc_stdev': auc_stdev,\n",
    "        'auc_95ci_u': auc_95ci_u,\n",
    "        'auc_95ci_d': auc_95ci_d,\n",
    "        'precision': pres,\n",
    "        'recall': recs,\n",
    "        'f1_score': f1s,\n",
    "        'f1_stdev': f1_stdev,\n",
    "        'f1_95ci_u': f1_95ci_u,\n",
    "        'f1_95ci_d': f1_95ci_d,\n",
    "    })\n",
    "    percentile_list.to_csv('./data/results_{}.csv'.format(model_type), mode='a', header=True)\n",
    "\n",
    "    print(\"\\nNumber of questions:\", num_questions)\n",
    "    print(\"Mean AUC      :\", mean_auc)\n",
    "    print(\"Stdev AUC     :\", stdev_auc)\n",
    "    print(\"95th CI AUC   :\", ci_auc_u, ci_auc_d)\n",
    "    print(\"Mean F1-Score :\", mean_f1)\n",
    "    print(\"Stdev F1      :\", stdev_f1)\n",
    "    print(\"95th CI F1    :\", ci_f1_u, ci_f1_d)\n",
    "\n",
    "    ACCS.append(mean_acc)\n",
    "    AUCS.append(mean_auc)\n",
    "    AUC_STDEV.append(stdev_auc)\n",
    "    AUC_95CI_U.append(ci_auc_u)\n",
    "    AUC_95CI_D.append(ci_auc_d)\n",
    "    PRES.append(mean_pre)\n",
    "    RECS.append(mean_rec)\n",
    "    F1S.append(mean_f1)\n",
    "    F1_STDEV.append(stdev_f1)\n",
    "    F1_95CI_U.append(ci_f1_u)\n",
    "    F1_95CI_D.append(ci_f1_d)\n",
    "\n",
    "    with open(\"./data/models_{}.bin\".format(model_type), \"wb\") as f:\n",
    "        # pickle.dump(models, f)\n",
    "        pickle.dump(models_info, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
